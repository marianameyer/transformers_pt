{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/jsansao/transformers_pt/blob/main/XLM_Roberta_Fine_tuning_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","_kg_hide-output":false}},{"cell_type":"markdown","source":"# Inferência usando transformers pré-treinados do HuggingFace ","metadata":{"id":"hV_s2jhFIGRV"}},{"cell_type":"markdown","source":"xlm RoBERTa\n\nNOBREAK - Machado\n\nBatch size = 16\n\nGPU T4x2","metadata":{}},{"cell_type":"code","source":"#@title Passo 1:Instalando Hugging Face Transformers\n# We won't need TensorFlow here\n!pip uninstall -y tensorflow\n# Install `transformers` from master\n!pip install transformers datasets\n!pip list | grep -E 'transformers|tokenizers'\n# transformers version at notebook update --- 2.9.1\n# tokenizers version at notebook update --- 0.7.0","metadata":{"id":"LhI1tJBGBd3r","outputId":"25209cd0-8888-4a16-d475-2f68a5fe1ce4","execution":{"iopub.status.busy":"2022-10-31T14:42:30.069780Z","iopub.execute_input":"2022-10-31T14:42:30.070542Z","iopub.status.idle":"2022-10-31T14:43:06.237143Z","shell.execute_reply.started":"2022-10-31T14:42:30.070451Z","shell.execute_reply":"2022-10-31T14:43:06.235899Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Found existing installation: tensorflow 2.6.4\nUninstalling tensorflow-2.6.4:\n  Successfully uninstalled tensorflow-2.6.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.5.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.13)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.8.2)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\nRequirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.1.1)\nRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.1.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.4.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mtokenizers                            0.12.1\ntransformers                          4.20.1\n","output_type":"stream"}]},{"cell_type":"code","source":"#@title Step 1: Loading the Dataset\n#1.Load kant.txt using the Colab file manager\n#2.Downloading the file from GitHub\n!curl -L https://raw.githubusercontent.com/jsansao/corpus_ptbr/main/dump_Machado_Nobreak.txt --output \"dump.txt\"\n#!curl -L https://raw.githubusercontent.com/jsansao/corpus_ptbr/main/Lyrics_ChicoBuarque.txt --output \"kant.txt\"\n#!curl -L https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_aa --output \"dump.txt\"\n    \n!awk NF < dump.txt > kant.txt","metadata":{"id":"KAl5BxxOgk35","outputId":"987e5df1-904a-4a45-c6a3-83b9bcd0c063","execution":{"iopub.status.busy":"2022-10-31T14:43:06.240581Z","iopub.execute_input":"2022-10-31T14:43:06.241452Z","iopub.status.idle":"2022-10-31T14:43:09.179238Z","shell.execute_reply.started":"2022-10-31T14:43:06.241422Z","shell.execute_reply":"2022-10-31T14:43:09.177788Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 1739k  100 1739k    0     0  2696k      0 --:--:-- --:--:-- --:--:-- 2692k\n","output_type":"stream"}]},{"cell_type":"code","source":"#@title Passo 2:Baixando e salvando BR_BERTo\n#https://huggingface.co/rdenadai/BR_BERTo\n\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM\n\n#tokenizer = AutoTokenizer.from_pretrained(\"rdenadai/BR_BERTo\")\n#model = AutoModelForMaskedLM.from_pretrained(\"rdenadai/BR_BERTo\")\n\n#tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n#model = AutoModelForMaskedLM.from_pretrained('neuralmind/bert-base-portuguese-cased')\n\ntokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\nmodel = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-base\")\n","metadata":{"id":"h2L_Put8Cn8S","outputId":"02ba61f1-5b49-468a-ebbd-653a7381e76e","execution":{"iopub.status.busy":"2022-10-31T14:43:09.185027Z","iopub.execute_input":"2022-10-31T14:43:09.187188Z","iopub.status.idle":"2022-10-31T14:44:01.024446Z","shell.execute_reply.started":"2022-10-31T14:43:09.187132Z","shell.execute_reply":"2022-10-31T14:44:01.023108Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91edee0053714052b4b53ec7ec7f9c29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f983b8a3d71a42fd93f43d131f7f08bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cd7af84b7d641839953a94773a74d1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a55f57965db8429ca1a274db96ed45a0"}},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset\n#datasets = load_dataset(\"text\", data_files={\"train\": \"kant.txt\", \"validation\": \"kant_teste.txt\"})\n#datasets = load_dataset(\"text\", data_files={\"train\": \"kant.txt\"}, split='train[:90%]')\nds = load_dataset(\"text\", data_files={\"train\": \"kant.txt\"})\n\ndatasets = ds[\"train\"].train_test_split()","metadata":{"id":"SNVK5YGsZ6eb","execution":{"iopub.status.busy":"2022-10-31T14:44:01.028325Z","iopub.execute_input":"2022-10-31T14:44:01.029138Z","iopub.status.idle":"2022-10-31T14:44:01.980936Z","shell.execute_reply.started":"2022-10-31T14:44:01.029103Z","shell.execute_reply":"2022-10-31T14:44:01.979842Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-02212350d3c18f88/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72a7b7c7fd93478196d0dcf4deeefb43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74cc097e081c45448825d741d02a06ba"}},"metadata":{}},{"name":"stdout","text":"Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-02212350d3c18f88/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c2bad9b7cf842d4b23d7123312e91a1"}},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(examples[\"text\"])","metadata":{"execution":{"iopub.status.busy":"2022-10-31T14:44:01.985380Z","iopub.execute_input":"2022-10-31T14:44:01.988707Z","iopub.status.idle":"2022-10-31T14:44:01.995920Z","shell.execute_reply.started":"2022-10-31T14:44:01.988667Z","shell.execute_reply":"2022-10-31T14:44:01.995014Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])","metadata":{"id":"J1oYngljZeZT","outputId":"afba384e-bfb3-4ffc-baaa-0aa244aaff54","execution":{"iopub.status.busy":"2022-10-31T14:44:02.000665Z","iopub.execute_input":"2022-10-31T14:44:02.001693Z","iopub.status.idle":"2022-10-31T14:44:05.562574Z","shell.execute_reply.started":"2022-10-31T14:44:02.001656Z","shell.execute_reply":"2022-10-31T14:44:05.561464Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"      ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21a55f5e9304499dbeae0eb50d6ec92a"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fabe1a0a153a4865a06ab7594d601dca"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2613f16340f541239c7455a5d9ecf3a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bbf2135c9864fdcad8b034948f415ec"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\nToken indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\nToken indices sequence length is longer than the specified maximum sequence length for this model (774 > 512). Running this sequence through the model will result in indexing errors\nToken indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"      ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"715b10b50cfa4bb88dfc1fe2ff37d021"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eba17831058e41558ca2160add0da224"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a4f9ae2a71d4dd790a85a0963cc727f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c35602c048ba409eadadbd85d75d8931"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets[\"train\"][4]","metadata":{"id":"7JiCdblobSdn","execution":{"iopub.status.busy":"2022-10-31T14:44:05.565206Z","iopub.execute_input":"2022-10-31T14:44:05.566326Z","iopub.status.idle":"2022-10-31T14:44:05.577240Z","shell.execute_reply.started":"2022-10-31T14:44:05.566274Z","shell.execute_reply":"2022-10-31T14:44:05.576075Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [0, 292, 27974, 11927, 32, 2],\n 'attention_mask': [1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"#block_size = tokenizer.model_max_length\nblock_size = 32","metadata":{"id":"QT8eOoqmbYV2","outputId":"5c35b945-2236-41a1-9c6f-c6a4785ef551","execution":{"iopub.status.busy":"2022-10-31T14:44:05.579014Z","iopub.execute_input":"2022-10-31T14:44:05.579451Z","iopub.status.idle":"2022-10-31T14:44:05.593646Z","shell.execute_reply.started":"2022-10-31T14:44:05.579416Z","shell.execute_reply":"2022-10-31T14:44:05.592482Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"exemplo de entrada","metadata":{"id":"ETLIt8siKjWC"}},{"cell_type":"code","source":"def group_texts(examples):\n    # Concatenate all texts.\n    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n    total_length = len(concatenated_examples[list(examples.keys())[0]])\n    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n        # customize this part to your needs.\n    total_length = (total_length // block_size) * block_size\n    # Split by chunks of max_len.\n    result = {\n        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n        for k, t in concatenated_examples.items()\n    }\n    result[\"labels\"] = result[\"input_ids\"].copy()\n    return result","metadata":{"id":"zif6EA4VcCk0","execution":{"iopub.status.busy":"2022-10-31T14:44:05.597184Z","iopub.execute_input":"2022-10-31T14:44:05.597440Z","iopub.status.idle":"2022-10-31T14:44:05.607238Z","shell.execute_reply.started":"2022-10-31T14:44:05.597416Z","shell.execute_reply":"2022-10-31T14:44:05.606242Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"lm_datasets = tokenized_datasets.map(\n    group_texts,\n    batched=True,\n    batch_size=1000,\n    num_proc=4,\n)","metadata":{"id":"4Xb0RzHtb2RJ","outputId":"4aa85205-48b6-457c-bb4c-95aea9b1aee6","execution":{"iopub.status.busy":"2022-10-31T14:44:05.611913Z","iopub.execute_input":"2022-10-31T14:44:05.612222Z","iopub.status.idle":"2022-10-31T14:44:08.839362Z","shell.execute_reply.started":"2022-10-31T14:44:05.612194Z","shell.execute_reply":"2022-10-31T14:44:08.838125Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"     ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a900415403a45d4b3a497dcaedad0e7"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5f4d7bacbd24c0f9338856427383501"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92dae73b3d504e0fad5dc45c7098505e"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67971ef55c874ef2aaa9d306e2c2363b"}},"metadata":{}},{"name":"stdout","text":"      ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e61c49c8ba3d462abf72850b0f2913fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7914606821b9438881a1d19a7267a2bb"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cef2a7c42a5499f99fb4a8c1653a41e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"163adef2a7cb4c259364cf47a45711e3"}},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 11: Defining a Data Collator\nfrom transformers import DataCollatorForLanguageModeling\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n)","metadata":{"id":"19hRhnHFf7FF","execution":{"iopub.status.busy":"2022-10-31T14:44:08.841450Z","iopub.execute_input":"2022-10-31T14:44:08.841875Z","iopub.status.idle":"2022-10-31T14:44:09.469827Z","shell.execute_reply.started":"2022-10-31T14:44:08.841813Z","shell.execute_reply":"2022-10-31T14:44:09.468507Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric\n\nmetric = load_metric(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return {metric.compute(predictions=predictions, references=labels)}","metadata":{"id":"_cDyvFrNfa31","outputId":"cbc8f54a-5908-4774-d51b-7f5cdc619fac","execution":{"iopub.status.busy":"2022-10-31T14:44:09.471430Z","iopub.execute_input":"2022-10-31T14:44:09.471801Z","iopub.status.idle":"2022-10-31T14:44:09.970396Z","shell.execute_reply.started":"2022-10-31T14:44:09.471764Z","shell.execute_reply":"2022-10-31T14:44:09.969369Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.41k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e555e34df1c4c6f9ad38213075a317e"}},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 12: Initializing the Trainer\nfrom transformers import Trainer, TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./xlm_RoBERTa-Machado_Nobreak\",\n    overwrite_output_dir=True,\n    num_train_epochs=10,\n    per_device_train_batch_size=16,\n    save_steps=10_000,\n    save_total_limit=2,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=lm_datasets[\"train\"],\n    eval_dataset=lm_datasets[\"test\"],    \n)","metadata":{"id":"MH2dsTzhfgqI","outputId":"2104faba-c770-43c3-dbf5-61a6b0fbca90","execution":{"iopub.status.busy":"2022-10-31T14:44:09.971948Z","iopub.execute_input":"2022-10-31T14:44:09.972361Z","iopub.status.idle":"2022-10-31T14:44:14.016613Z","shell.execute_reply.started":"2022-10-31T14:44:09.972320Z","shell.execute_reply":"2022-10-31T14:44:14.015180Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#@title Step 13: Pre-training the Model\ntrainer.train()","metadata":{"id":"EZxksqadfv6l","outputId":"ef83bfc0-2021-41e0-ef94-1ef54c0245d4","execution":{"iopub.status.busy":"2022-10-31T14:44:14.018494Z","iopub.execute_input":"2022-10-31T14:44:14.019308Z","iopub.status.idle":"2022-10-31T15:23:42.367318Z","shell.execute_reply.started":"2022-10-31T14:44:14.019263Z","shell.execute_reply":"2022-10-31T15:23:42.366289Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 11412\n  Num Epochs = 10\n  Instantaneous batch size per device = 16\n  Total train batch size (w. parallel, distributed & accumulation) = 32\n  Gradient Accumulation steps = 1\n  Total optimization steps = 3570\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20221031_144629-1p3njmvu</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/tccii/huggingface/runs/1p3njmvu\" target=\"_blank\">./xlm_RoBERTa-Machado_Nobreak</a></strong> to <a href=\"https://wandb.ai/tccii/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3570' max='3570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3570/3570 36:57, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>2.770200</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>2.465700</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>2.309100</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>2.200800</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>2.103800</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>2.046600</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>2.015900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3570, training_loss=2.268316945308397, metrics={'train_runtime': 2368.3087, 'train_samples_per_second': 48.186, 'train_steps_per_second': 1.507, 'total_flos': 1882117362355200.0, 'train_loss': 2.268316945308397, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"code","source":"import math\neval_results = trainer.evaluate()\nprint(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")","metadata":{"id":"p9rpjGVyj68j","outputId":"95e0857d-473f-4ac9-da04-72ecdf74da94","execution":{"iopub.status.busy":"2022-10-31T15:23:42.368760Z","iopub.execute_input":"2022-10-31T15:23:42.373780Z","iopub.status.idle":"2022-10-31T15:24:23.348494Z","shell.execute_reply.started":"2022-10-31T15:23:42.373738Z","shell.execute_reply":"2022-10-31T15:24:23.347491Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 3918\n  Batch size = 16\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [245/245 00:40]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Perplexity: 8.29\n","output_type":"stream"}]},{"cell_type":"code","source":"eval_results","metadata":{"id":"Ihaz7TAMAF4l","outputId":"0c37b9c1-92ba-49e9-fc62-6c74c0c7b70b","execution":{"iopub.status.busy":"2022-10-31T15:24:23.353614Z","iopub.execute_input":"2022-10-31T15:24:23.356483Z","iopub.status.idle":"2022-10-31T15:24:23.370348Z","shell.execute_reply.started":"2022-10-31T15:24:23.356432Z","shell.execute_reply":"2022-10-31T15:24:23.369170Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 2.115046739578247,\n 'eval_runtime': 40.9529,\n 'eval_samples_per_second': 95.671,\n 'eval_steps_per_second': 5.982,\n 'epoch': 10.0}"},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 14: Saving the Final Model(+tokenizer + config) to disk\ntrainer.save_model(\"./xlm_RoBERTa-Machado_Nobreak\")","metadata":{"id":"xusSgo3unkRI","outputId":"ae42d9c0-1dac-4a09-e30c-d7a62dd814f3","execution":{"iopub.status.busy":"2022-10-31T15:24:23.375532Z","iopub.execute_input":"2022-10-31T15:24:23.377810Z","iopub.status.idle":"2022-10-31T15:24:26.332890Z","shell.execute_reply.started":"2022-10-31T15:24:23.377760Z","shell.execute_reply":"2022-10-31T15:24:26.331896Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Saving model checkpoint to ./xlm_RoBERTa-Machado_Nobreak\nConfiguration saved in ./xlm_RoBERTa-Machado_Nobreak/config.json\nModel weights saved in ./xlm_RoBERTa-Machado_Nobreak/pytorch_model.bin\n","output_type":"stream"}]},{"cell_type":"code","source":"# Saving model on Wandb\nimport wandb\nwandb.save('xlm_RoBERTa-Machado_Nobreak.h5')","metadata":{"execution":{"iopub.status.busy":"2022-10-31T15:24:26.334595Z","iopub.execute_input":"2022-10-31T15:24:26.335072Z","iopub.status.idle":"2022-10-31T15:24:26.350707Z","shell.execute_reply.started":"2022-10-31T15:24:26.335031Z","shell.execute_reply":"2022-10-31T15:24:26.348799Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 3: Configurando o pipeline fill-mask\n#@title Step 15: Language Modeling with the FillMaskPipeline\nfrom transformers import pipeline\n\nfill_mask = pipeline(\n    \"fill-mask\",\n    model=\"./xlm_RoBERTa-Machado_Nobreak\",\n    tokenizer=tokenizer\n)","metadata":{"id":"pqy7oTgYFb9Y","outputId":"e680b0aa-fd51-410f-85c7-abc56e5a220d","execution":{"iopub.status.busy":"2022-10-31T15:24:26.353296Z","iopub.execute_input":"2022-10-31T15:24:26.354747Z","iopub.status.idle":"2022-10-31T15:24:33.299687Z","shell.execute_reply.started":"2022-10-31T15:24:26.354687Z","shell.execute_reply":"2022-10-31T15:24:33.298612Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"loading configuration file ./xlm_RoBERTa-Machado_Nobreak/config.json\nModel config XLMRobertaConfig {\n  \"_name_or_path\": \"./xlm_RoBERTa-Machado_Nobreak\",\n  \"architectures\": [\n    \"XLMRobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"xlm-roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 250002\n}\n\nloading configuration file ./xlm_RoBERTa-Machado_Nobreak/config.json\nModel config XLMRobertaConfig {\n  \"_name_or_path\": \"./xlm_RoBERTa-Machado_Nobreak\",\n  \"architectures\": [\n    \"XLMRobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"xlm-roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 250002\n}\n\nloading weights file ./xlm_RoBERTa-Machado_Nobreak/pytorch_model.bin\nAll model checkpoint weights were used when initializing XLMRobertaForMaskedLM.\n\nAll the weights of XLMRobertaForMaskedLM were initialized from the model checkpoint at ./xlm_RoBERTa-Machado_Nobreak.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForMaskedLM for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"fill_mask(\"O rapaz olhou para o <mask> \")","metadata":{"id":"RRrtRPA6GRF8","outputId":"b1883a25-35b0-42ad-e7a6-7f9c21a6565a","execution":{"iopub.status.busy":"2022-10-31T15:24:33.301353Z","iopub.execute_input":"2022-10-31T15:24:33.302020Z","iopub.status.idle":"2022-10-31T15:24:33.936644Z","shell.execute_reply.started":"2022-10-31T15:24:33.301976Z","shell.execute_reply":"2022-10-31T15:24:33.935442Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.12774516642093658,\n  'token': 13343,\n  'token_str': 'outro',\n  'sequence': 'O rapaz olhou para o outro'},\n {'score': 0.0785096064209938,\n  'token': 118427,\n  'token_str': 'marido',\n  'sequence': 'O rapaz olhou para o marido'},\n {'score': 0.0752451941370964,\n  'token': 5,\n  'token_str': '.',\n  'sequence': 'O rapaz olhou para o.'},\n {'score': 0.07046205550432205,\n  'token': 48682,\n  'token_str': 'médico',\n  'sequence': 'O rapaz olhou para o médico'},\n {'score': 0.061107899993658066,\n  'token': 177122,\n  'token_str': 'chão',\n  'sequence': 'O rapaz olhou para o chão'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"A moça olhou para o <mask> \")","metadata":{"id":"56WEAY40asDv","outputId":"c1440b14-b1b4-4beb-8a1c-c58d2e688fca","execution":{"iopub.status.busy":"2022-10-31T15:24:33.938104Z","iopub.execute_input":"2022-10-31T15:24:33.939223Z","iopub.status.idle":"2022-10-31T15:24:34.431949Z","shell.execute_reply.started":"2022-10-31T15:24:33.939179Z","shell.execute_reply":"2022-10-31T15:24:34.430876Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.20976918935775757,\n  'token': 118427,\n  'token_str': 'marido',\n  'sequence': 'A moça olhou para o marido'},\n {'score': 0.11062201112508774,\n  'token': 48682,\n  'token_str': 'médico',\n  'sequence': 'A moça olhou para o médico'},\n {'score': 0.09720515459775925,\n  'token': 13343,\n  'token_str': 'outro',\n  'sequence': 'A moça olhou para o outro'},\n {'score': 0.06236657500267029,\n  'token': 175194,\n  'token_str': 'céu',\n  'sequence': 'A moça olhou para o céu'},\n {'score': 0.04451904073357582,\n  'token': 5,\n  'token_str': '.',\n  'sequence': 'A moça olhou para o.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Comprou uma <mask> na loja. \")","metadata":{"id":"HiDV-v5rTyJt","outputId":"6b090bca-896a-4edc-9690-2c7a6d59465f","execution":{"iopub.status.busy":"2022-10-31T15:24:34.433500Z","iopub.execute_input":"2022-10-31T15:24:34.434631Z","iopub.status.idle":"2022-10-31T15:24:35.816161Z","shell.execute_reply.started":"2022-10-31T15:24:34.434588Z","shell.execute_reply":"2022-10-31T15:24:35.815077Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.3083058297634125,\n  'token': 185350,\n  'token_str': 'cadeira',\n  'sequence': 'Comprou uma cadeira na loja.'},\n {'score': 0.13047072291374207,\n  'token': 20533,\n  'token_str': 'carta',\n  'sequence': 'Comprou uma carta na loja.'},\n {'score': 0.10865946859121323,\n  'token': 2349,\n  'token_str': 'casa',\n  'sequence': 'Comprou uma casa na loja.'},\n {'score': 0.03926897421479225,\n  'token': 30092,\n  'token_str': 'coisa',\n  'sequence': 'Comprou uma coisa na loja.'},\n {'score': 0.0240776427090168,\n  'token': 128869,\n  'token_str': 'cousa',\n  'sequence': 'Comprou uma cousa na loja.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"A mulher não é <mask>. \")","metadata":{"id":"gVnhg1bxT-wK","outputId":"4c9c8bc8-e2ae-4446-83a3-f4400e6540e6","execution":{"iopub.status.busy":"2022-10-31T15:24:35.817643Z","iopub.execute_input":"2022-10-31T15:24:35.824142Z","iopub.status.idle":"2022-10-31T15:24:37.686027Z","shell.execute_reply.started":"2022-10-31T15:24:35.824100Z","shell.execute_reply":"2022-10-31T15:24:37.684902Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.2285887449979782,\n  'token': 91276,\n  'token_str': 'bonita',\n  'sequence': 'A mulher não é bonita.'},\n {'score': 0.048108577728271484,\n  'token': 19328,\n  'token_str': 'boa',\n  'sequence': 'A mulher não é boa.'},\n {'score': 0.0342043898999691,\n  'token': 96394,\n  'token_str': 'rara',\n  'sequence': 'A mulher não é rara.'},\n {'score': 0.02655733935534954,\n  'token': 1646,\n  'token_str': 'sua',\n  'sequence': 'A mulher não é sua.'},\n {'score': 0.02627628669142723,\n  'token': 55998,\n  'token_str': 'linda',\n  'sequence': 'A mulher não é linda.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"O homem não é <mask>. \")","metadata":{"id":"l486NETHUFw6","outputId":"c71eeedc-0460-4c4a-a8fe-64e0850f8022","execution":{"iopub.status.busy":"2022-10-31T15:24:37.687700Z","iopub.execute_input":"2022-10-31T15:24:37.688423Z","iopub.status.idle":"2022-10-31T15:24:38.094084Z","shell.execute_reply.started":"2022-10-31T15:24:37.688378Z","shell.execute_reply":"2022-10-31T15:24:38.092912Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.08954934775829315,\n  'token': 44277,\n  'token_str': 'homem',\n  'sequence': 'O homem não é homem.'},\n {'score': 0.032654717564582825,\n  'token': 8634,\n  'token_str': 'bom',\n  'sequence': 'O homem não é bom.'},\n {'score': 0.027262814342975616,\n  'token': 47100,\n  'token_str': 'poeta',\n  'sequence': 'O homem não é poeta.'},\n {'score': 0.025749171152710915,\n  'token': 44053,\n  'token_str': 'padre',\n  'sequence': 'O homem não é padre.'},\n {'score': 0.022515011951327324,\n  'token': 135671,\n  'token_str': 'raro',\n  'sequence': 'O homem não é raro.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Ele é um bom <mask>. \")","metadata":{"id":"XBxjvRGYVAxC","outputId":"9c52531b-848e-4e4a-f62a-000c3da2ac0c","execution":{"iopub.status.busy":"2022-10-31T15:24:38.095668Z","iopub.execute_input":"2022-10-31T15:24:38.096517Z","iopub.status.idle":"2022-10-31T15:24:38.514000Z","shell.execute_reply.started":"2022-10-31T15:24:38.096482Z","shell.execute_reply":"2022-10-31T15:24:38.512794Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.3058183491230011,\n  'token': 38260,\n  'token_str': 'amigo',\n  'sequence': 'Ele é um bom amigo.'},\n {'score': 0.2646445333957672,\n  'token': 44277,\n  'token_str': 'homem',\n  'sequence': 'Ele é um bom homem.'},\n {'score': 0.08024843782186508,\n  'token': 114789,\n  'token_str': 'rapaz',\n  'sequence': 'Ele é um bom rapaz.'},\n {'score': 0.02895958721637726,\n  'token': 131187,\n  'token_str': 'senhor',\n  'sequence': 'Ele é um bom senhor.'},\n {'score': 0.021274592727422714,\n  'token': 187397,\n  'token_str': 'menino',\n  'sequence': 'Ele é um bom menino.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Ela é uma boa <mask>. \")","metadata":{"id":"PBQ5HugqVPF4","outputId":"681dbab4-c57f-4ae8-e4c4-580b6f1a01f6","execution":{"iopub.status.busy":"2022-10-31T15:24:38.515727Z","iopub.execute_input":"2022-10-31T15:24:38.516737Z","iopub.status.idle":"2022-10-31T15:24:38.924417Z","shell.execute_reply.started":"2022-10-31T15:24:38.516694Z","shell.execute_reply":"2022-10-31T15:24:38.923273Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.3547772765159607,\n  'token': 55207,\n  'token_str': 'amiga',\n  'sequence': 'Ela é uma boa amiga.'},\n {'score': 0.1365812122821808,\n  'token': 52636,\n  'token_str': 'mulher',\n  'sequence': 'Ela é uma boa mulher.'},\n {'score': 0.09741304069757462,\n  'token': 29956,\n  'token_str': 'pessoa',\n  'sequence': 'Ela é uma boa pessoa.'},\n {'score': 0.06621638685464859,\n  'token': 51047,\n  'token_str': 'dama',\n  'sequence': 'Ela é uma boa dama.'},\n {'score': 0.0393059141933918,\n  'token': 179879,\n  'token_str': 'criatura',\n  'sequence': 'Ela é uma boa criatura.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Faz de conta que ainda é <mask>. \")","metadata":{"id":"qUBfuZBNa4_2","outputId":"458430a2-55ab-495b-c372-d93243f81a23","execution":{"iopub.status.busy":"2022-10-31T15:24:38.926079Z","iopub.execute_input":"2022-10-31T15:24:38.927145Z","iopub.status.idle":"2022-10-31T15:24:39.423179Z","shell.execute_reply.started":"2022-10-31T15:24:38.927098Z","shell.execute_reply":"2022-10-31T15:24:39.421921Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.25703299045562744,\n  'token': 15234,\n  'token_str': 'tarde',\n  'sequence': 'Faz de conta que ainda é tarde.'},\n {'score': 0.23700043559074402,\n  'token': 79426,\n  'token_str': 'criança',\n  'sequence': 'Faz de conta que ainda é criança.'},\n {'score': 0.078849196434021,\n  'token': 96872,\n  'token_str': 'jovem',\n  'sequence': 'Faz de conta que ainda é jovem.'},\n {'score': 0.051295626908540726,\n  'token': 187397,\n  'token_str': 'menino',\n  'sequence': 'Faz de conta que ainda é menino.'},\n {'score': 0.027760937809944153,\n  'token': 65312,\n  'token_str': 'pequena',\n  'sequence': 'Faz de conta que ainda é pequena.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Depois da tempestade vem a <mask>. \")","metadata":{"id":"u4E4MHWmbBsH","outputId":"4cdfca63-dc0b-47d4-f67b-097bf1713a15","execution":{"iopub.status.busy":"2022-10-31T15:24:39.430052Z","iopub.execute_input":"2022-10-31T15:24:39.430371Z","iopub.status.idle":"2022-10-31T15:24:39.917827Z","shell.execute_reply.started":"2022-10-31T15:24:39.430341Z","shell.execute_reply":"2022-10-31T15:24:39.916416Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.21876192092895508,\n  'token': 146672,\n  'token_str': 'chuva',\n  'sequence': 'Depois da tempestade vem a chuva.'},\n {'score': 0.13171151280403137,\n  'token': 27761,\n  'token_str': 'lua',\n  'sequence': 'Depois da tempestade vem a lua.'},\n {'score': 0.05547480285167694,\n  'token': 23291,\n  'token_str': 'noite',\n  'sequence': 'Depois da tempestade vem a noite.'},\n {'score': 0.03295222669839859,\n  'token': 15234,\n  'token_str': 'tarde',\n  'sequence': 'Depois da tempestade vem a tarde.'},\n {'score': 0.028334297239780426,\n  'token': 2436,\n  'token_str': 'vida',\n  'sequence': 'Depois da tempestade vem a vida.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Mais vale um pássaro na mão do que <mask> voando. \")","metadata":{"id":"8bd3GbaabIn7","outputId":"84096a89-0b04-48d5-bb3e-4bf7a06dec30","execution":{"iopub.status.busy":"2022-10-31T15:24:39.919747Z","iopub.execute_input":"2022-10-31T15:24:39.920159Z","iopub.status.idle":"2022-10-31T15:24:40.218532Z","shell.execute_reply.started":"2022-10-31T15:24:39.920118Z","shell.execute_reply":"2022-10-31T15:24:40.217538Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.28452759981155396,\n  'token': 193,\n  'token_str': 'ir',\n  'sequence': 'Mais vale um pássaro na mão do que ir voando.'},\n {'score': 0.17927347123622894,\n  'token': 25629,\n  'token_str': 'ficar',\n  'sequence': 'Mais vale um pássaro na mão do que ficar voando.'},\n {'score': 0.07381939142942429,\n  'token': 78038,\n  'token_str': 'andar',\n  'sequence': 'Mais vale um pássaro na mão do que andar voando.'},\n {'score': 0.06585749983787537,\n  'token': 68378,\n  'token_str': 'sair',\n  'sequence': 'Mais vale um pássaro na mão do que sair voando.'},\n {'score': 0.06499272584915161,\n  'token': 5747,\n  'token_str': 'estar',\n  'sequence': 'Mais vale um pássaro na mão do que estar voando.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Não tinha <mask>, mas almoçou mesmo assim. \")","metadata":{"id":"bhep3pt3bUkJ","outputId":"79b4127e-cf4e-4048-d07c-b7b2cad88f77","execution":{"iopub.status.busy":"2022-10-31T15:24:40.220273Z","iopub.execute_input":"2022-10-31T15:24:40.221290Z","iopub.status.idle":"2022-10-31T15:24:40.802402Z","shell.execute_reply.started":"2022-10-31T15:24:40.221245Z","shell.execute_reply":"2022-10-31T15:24:40.801171Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.12600962817668915,\n  'token': 5799,\n  'token_str': 'nada',\n  'sequence': 'Não tinha nada, mas almoçou mesmo assim.'},\n {'score': 0.07373160868883133,\n  'token': 204382,\n  'token_str': 'almoço',\n  'sequence': 'Não tinha almoço, mas almoçou mesmo assim.'},\n {'score': 0.02894417941570282,\n  'token': 40454,\n  'token_str': 'chá',\n  'sequence': 'Não tinha chá, mas almoçou mesmo assim.'},\n {'score': 0.027864348143339157,\n  'token': 26216,\n  'token_str': 'café',\n  'sequence': 'Não tinha café, mas almoçou mesmo assim.'},\n {'score': 0.025886669754981995,\n  'token': 123299,\n  'token_str': 'medo',\n  'sequence': 'Não tinha medo, mas almoçou mesmo assim.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Bebeu um copo d'água, pois tinha <mask>. \")","metadata":{"id":"Vpn7cJREbj_Y","outputId":"a2afee0d-8998-4df9-8ce8-99c203e716bf","execution":{"iopub.status.busy":"2022-10-31T15:24:40.804093Z","iopub.execute_input":"2022-10-31T15:24:40.804774Z","iopub.status.idle":"2022-10-31T15:24:41.121446Z","shell.execute_reply.started":"2022-10-31T15:24:40.804727Z","shell.execute_reply":"2022-10-31T15:24:41.120316Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.09760361164808273,\n  'token': 123299,\n  'token_str': 'medo',\n  'sequence': \"Bebeu um copo d'água, pois tinha medo.\"},\n {'score': 0.0451083667576313,\n  'token': 31201,\n  'token_str': 'água',\n  'sequence': \"Bebeu um copo d'água, pois tinha água.\"},\n {'score': 0.042474593967199326,\n  'token': 54998,\n  'token_str': 'vontade',\n  'sequence': \"Bebeu um copo d'água, pois tinha vontade.\"},\n {'score': 0.036253057420253754,\n  'token': 11721,\n  'token_str': 'pouco',\n  'sequence': \"Bebeu um copo d'água, pois tinha pouco.\"},\n {'score': 0.02871454320847988,\n  'token': 128909,\n  'token_str': 'razão',\n  'sequence': \"Bebeu um copo d'água, pois tinha razão.\"}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Sem saber, ele descobriu um <mask>. \")","metadata":{"id":"9KrDcsT2bzkl","outputId":"5cc08968-240e-4e3c-ba85-9e7f4bcf46f6","execution":{"iopub.status.busy":"2022-10-31T15:24:41.123083Z","iopub.execute_input":"2022-10-31T15:24:41.123807Z","iopub.status.idle":"2022-10-31T15:24:41.651424Z","shell.execute_reply.started":"2022-10-31T15:24:41.123762Z","shell.execute_reply":"2022-10-31T15:24:41.650189Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.10955964028835297,\n  'token': 165801,\n  'token_str': 'segredo',\n  'sequence': 'Sem saber, ele descobriu um segredo.'},\n {'score': 0.04084990173578262,\n  'token': 196545,\n  'token_str': 'estranho',\n  'sequence': 'Sem saber, ele descobriu um estranho.'},\n {'score': 0.04083447903394699,\n  'token': 26018,\n  'token_str': 'livro',\n  'sequence': 'Sem saber, ele descobriu um livro.'},\n {'score': 0.022593477740883827,\n  'token': 7766,\n  'token_str': 'nome',\n  'sequence': 'Sem saber, ele descobriu um nome.'},\n {'score': 0.019689474254846573,\n  'token': 11721,\n  'token_str': 'pouco',\n  'sequence': 'Sem saber, ele descobriu um pouco.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Pedro fez fortuna vendendo <mask>. \")","metadata":{"id":"FzIuM2mFb6tc","outputId":"5811459d-3230-4247-df61-baf7ff1e67f8","execution":{"iopub.status.busy":"2022-10-31T15:24:41.652887Z","iopub.execute_input":"2022-10-31T15:24:41.653587Z","iopub.status.idle":"2022-10-31T15:24:42.118957Z","shell.execute_reply.started":"2022-10-31T15:24:41.653546Z","shell.execute_reply":"2022-10-31T15:24:42.117872Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.16004246473312378,\n  'token': 27,\n  'token_str': '...',\n  'sequence': 'Pedro fez fortuna vendendo....'},\n {'score': 0.08328715711832047,\n  'token': 36,\n  'token_str': 'o',\n  'sequence': 'Pedro fez fortuna vendendo o.'},\n {'score': 0.07162977010011673,\n  'token': 5,\n  'token_str': '.',\n  'sequence': 'Pedro fez fortuna vendendo..'},\n {'score': 0.04892539605498314,\n  'token': 10964,\n  'token_str': 'tudo',\n  'sequence': 'Pedro fez fortuna vendendo tudo.'},\n {'score': 0.04600413143634796,\n  'token': 10,\n  'token_str': 'a',\n  'sequence': 'Pedro fez fortuna vendendo a.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Sem medo de ser <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-10-31T15:24:42.120785Z","iopub.execute_input":"2022-10-31T15:24:42.121228Z","iopub.status.idle":"2022-10-31T15:24:42.531037Z","shell.execute_reply.started":"2022-10-31T15:24:42.121179Z","shell.execute_reply":"2022-10-31T15:24:42.529909Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.1286020129919052,\n  'token': 33587,\n  'token_str': 'feliz',\n  'sequence': 'Sem medo de ser feliz.'},\n {'score': 0.09224138408899307,\n  'token': 44053,\n  'token_str': 'padre',\n  'sequence': 'Sem medo de ser padre.'},\n {'score': 0.02730511873960495,\n  'token': 57873,\n  'token_str': 'mãe',\n  'sequence': 'Sem medo de ser mãe.'},\n {'score': 0.025949090719223022,\n  'token': 44277,\n  'token_str': 'homem',\n  'sequence': 'Sem medo de ser homem.'},\n {'score': 0.023238174617290497,\n  'token': 22733,\n  'token_str': 'pai',\n  'sequence': 'Sem medo de ser pai.'}]"},"metadata":{}}]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2022-10-31T15:24:42.532744Z","iopub.execute_input":"2022-10-31T15:24:42.533136Z","iopub.status.idle":"2022-10-31T15:24:48.344951Z","shell.execute_reply.started":"2022-10-31T15:24:42.533106Z","shell.execute_reply":"2022-10-31T15:24:48.343925Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▃▄▆▇███</td></tr><tr><td>train/global_step</td><td>▁▂▃▄▆▇███</td></tr><tr><td>train/learning_rate</td><td>█▇▆▄▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▄▃▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.11505</td></tr><tr><td>eval/runtime</td><td>40.9529</td></tr><tr><td>eval/samples_per_second</td><td>95.671</td></tr><tr><td>eval/steps_per_second</td><td>5.982</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>3570</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.0159</td></tr><tr><td>train/total_flos</td><td>1882117362355200.0</td></tr><tr><td>train/train_loss</td><td>2.26832</td></tr><tr><td>train/train_runtime</td><td>2368.3087</td></tr><tr><td>train/train_samples_per_second</td><td>48.186</td></tr><tr><td>train/train_steps_per_second</td><td>1.507</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Synced <strong style=\"color:#cdcd00\">./xlm_RoBERTa-Machado_Nobreak</strong>: <a href=\"https://wandb.ai/tccii/huggingface/runs/1p3njmvu\" target=\"_blank\">https://wandb.ai/tccii/huggingface/runs/1p3njmvu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20221031_144629-1p3njmvu/logs</code>"},"metadata":{}}]}]}