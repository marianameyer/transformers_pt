{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/jsansao/transformers_pt/blob/main/BERTimbau_Fine_tuning_CETENFolha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"# Inferência usando transformers pré-treinados do HuggingFace ","metadata":{"id":"hV_s2jhFIGRV"}},{"cell_type":"markdown","source":"BERTimbau\n\nNOBREAK - Machado\n\nBatch size = 16\n\nGPU T4x2","metadata":{}},{"cell_type":"code","source":"#@title Passo 1:Instalando Hugging Face Transformers\n# We won't need TensorFlow here\n!pip uninstall -y tensorflow\n# Install `transformers` from master\n!pip install transformers datasets\n!pip list | grep -E 'transformers|tokenizers'\n# transformers version at notebook update --- 2.9.1\n# tokenizers version at notebook update --- 0.7.0","metadata":{"id":"LhI1tJBGBd3r","outputId":"6992ec79-0f86-4f41-ec7a-6d3b9e7f1848","execution":{"iopub.status.busy":"2022-10-31T15:42:01.705046Z","iopub.execute_input":"2022-10-31T15:42:01.705521Z","iopub.status.idle":"2022-10-31T15:42:42.722630Z","shell.execute_reply.started":"2022-10-31T15:42:01.705423Z","shell.execute_reply":"2022-10-31T15:42:42.721168Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Found existing installation: tensorflow 2.6.4\nUninstalling tensorflow-2.6.4:\n  Successfully uninstalled tensorflow-2.6.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.13)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.8.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.5.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.4.0)\nRequirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.1.1)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mtokenizers                            0.12.1\ntransformers                          4.20.1\n","output_type":"stream"}]},{"cell_type":"code","source":"#@title Step 1: Loading the Dataset\n#1.Load kant.txt using the Colab file manager\n#2.Downloading the file from GitHub\n!curl -L  https://raw.githubusercontent.com/jsansao/corpus_ptbr/main/dump_Machado_Nobreak.txt --output \"dump.txt\"\n#!curl -L https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_aa --output \"dump.txt\"\n#!curl -L https://raw.githubusercontent.com/jsansao/corpus_ptbr/main/Lyrics_ChicoBuarque.txt --output \"kant.txt\"\n\n!awk NF < dump.txt > kant.txt","metadata":{"id":"KAl5BxxOgk35","outputId":"bab59eaa-60cf-462b-d681-2c89b64978e8","execution":{"iopub.status.busy":"2022-10-31T15:42:42.725948Z","iopub.execute_input":"2022-10-31T15:42:42.726462Z","iopub.status.idle":"2022-10-31T15:42:45.677115Z","shell.execute_reply.started":"2022-10-31T15:42:42.726410Z","shell.execute_reply":"2022-10-31T15:42:45.675268Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 1739k  100 1739k    0     0      0      0 --:--:-- --:--:-- --:--:--     0   0  3989k      0 --:--:-- --:--:-- --:--:-- 3989k\n","output_type":"stream"}]},{"cell_type":"code","source":"#@title Passo 2:Baixando e salvando BR_BERTo\n#https://huggingface.co/rdenadai/BR_BERTo\n\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM\n\n#tokenizer = AutoTokenizer.from_pretrained(\"rdenadai/BR_BERTo\")\n#model = AutoModelForMaskedLM.from_pretrained(\"rdenadai/BR_BERTo\")\n\ntokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\nmodel = AutoModelForMaskedLM.from_pretrained('neuralmind/bert-base-portuguese-cased')","metadata":{"id":"h2L_Put8Cn8S","outputId":"0e90b320-f004-490b-a683-2ef33b3dc60a","execution":{"iopub.status.busy":"2022-10-31T15:42:45.680685Z","iopub.execute_input":"2022-10-31T15:42:45.681730Z","iopub.status.idle":"2022-10-31T15:43:11.631526Z","shell.execute_reply.started":"2022-10-31T15:42:45.681674Z","shell.execute_reply":"2022-10-31T15:43:11.630049Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/43.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ff2d1a6e397478b980d9211aa6de573"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/647 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52952cfc4888468ebd79d41b7f9816c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/205k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cfd04386d9e4616bd933b7ee71c2f4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f132ecf4e77740bfa79d6678e0f7b6d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5850ffee47946e2ae5e1ae809252fdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/418M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b97cd374cb04ef99f49311667c246b1"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n#datasets = load_dataset(\"text\", data_files={\"train\": \"kant.txt\", \"validation\": \"kant_teste.txt\"})\n#datasets = load_dataset(\"text\", data_files={\"train\": \"kant.txt\"}, split='train[:90%]')\nds = load_dataset(\"text\", data_files={\"train\": \"kant.txt\"})\n\ndatasets = ds[\"train\"].train_test_split()","metadata":{"id":"J1oYngljZeZT","outputId":"98366916-3dd6-4469-e69e-83a2eeadcdfe","execution":{"iopub.status.busy":"2022-10-31T15:43:11.636725Z","iopub.execute_input":"2022-10-31T15:43:11.637626Z","iopub.status.idle":"2022-10-31T15:43:12.451178Z","shell.execute_reply.started":"2022-10-31T15:43:11.637573Z","shell.execute_reply":"2022-10-31T15:43:12.449912Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-27e2b3e615bfec30/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0e2edaf0690450b98c05551eac3ff83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4de20c5ebac047e48d9a45ee8b0219f2"}},"metadata":{}},{"name":"stdout","text":"Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-27e2b3e615bfec30/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4a3fe5d0394496ab4539b6d87b400c9"}},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(examples[\"text\"])","metadata":{"id":"7JiCdblobSdn","execution":{"iopub.status.busy":"2022-10-31T15:43:12.453077Z","iopub.execute_input":"2022-10-31T15:43:12.454152Z","iopub.status.idle":"2022-10-31T15:43:12.460731Z","shell.execute_reply.started":"2022-10-31T15:43:12.454099Z","shell.execute_reply":"2022-10-31T15:43:12.459021Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])","metadata":{"id":"QT8eOoqmbYV2","outputId":"f0c2ed49-ddce-409f-b78e-c8cb83d47841","execution":{"iopub.status.busy":"2022-10-31T15:43:12.462969Z","iopub.execute_input":"2022-10-31T15:43:12.463907Z","iopub.status.idle":"2022-10-31T15:43:15.532209Z","shell.execute_reply.started":"2022-10-31T15:43:12.463835Z","shell.execute_reply":"2022-10-31T15:43:15.530884Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"      ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f7857e9947e495fac9f7f10aadab8c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4148d960d74e456fa77cd702ec2522b5"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71415244416f4884b018c6514ee6fa26"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4a1f55ba041413883ae8e29bddfe12d"}},"metadata":{}},{"name":"stdout","text":"     ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e05f0726c2594171a8d12ea1cad21070"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c92a9046c0334839af166c6c0a854e97"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1babfd67ae874861b7c56a5c837df150"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbb517e422a74b47addb4dd56dbb1e4b"}},"metadata":{}}]},{"cell_type":"markdown","source":"exemplo de entrada","metadata":{"id":"ETLIt8siKjWC"}},{"cell_type":"code","source":"tokenized_datasets[\"train\"][4]","metadata":{"id":"7_umRvrQKT6g","outputId":"31557af2-70c4-4a38-a3ec-fb6a54c8fb17","execution":{"iopub.status.busy":"2022-10-31T15:43:15.534045Z","iopub.execute_input":"2022-10-31T15:43:15.534947Z","iopub.status.idle":"2022-10-31T15:43:15.547710Z","shell.execute_reply.started":"2022-10-31T15:43:15.534909Z","shell.execute_reply":"2022-10-31T15:43:15.546562Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101,\n  2010,\n  989,\n  2196,\n  117,\n  18968,\n  22278,\n  146,\n  390,\n  521,\n  11631,\n  132,\n  253,\n  2196,\n  106,\n  102],\n 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"#block_size = tokenizer.model_max_length\nblock_size = 32","metadata":{"id":"2cVk21VpKt0o","execution":{"iopub.status.busy":"2022-10-31T15:43:15.549424Z","iopub.execute_input":"2022-10-31T15:43:15.550587Z","iopub.status.idle":"2022-10-31T15:43:15.571510Z","shell.execute_reply.started":"2022-10-31T15:43:15.550542Z","shell.execute_reply":"2022-10-31T15:43:15.570048Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def group_texts(examples):\n    # Concatenate all texts.\n    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n    total_length = len(concatenated_examples[list(examples.keys())[0]])\n    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n        # customize this part to your needs.\n    total_length = (total_length // block_size) * block_size\n    # Split by chunks of max_len.\n    result = {\n        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n        for k, t in concatenated_examples.items()\n    }\n    result[\"labels\"] = result[\"input_ids\"].copy()\n    return result","metadata":{"id":"zif6EA4VcCk0","execution":{"iopub.status.busy":"2022-10-31T15:43:15.573348Z","iopub.execute_input":"2022-10-31T15:43:15.574698Z","iopub.status.idle":"2022-10-31T15:43:15.584570Z","shell.execute_reply.started":"2022-10-31T15:43:15.574653Z","shell.execute_reply":"2022-10-31T15:43:15.583060Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"lm_datasets = tokenized_datasets.map(\n    group_texts,\n    batched=True,\n    batch_size=1000,\n    num_proc=4,\n)","metadata":{"id":"4Xb0RzHtb2RJ","outputId":"1de1f00a-c9ab-4eee-bec0-79ee12ed0a35","execution":{"iopub.status.busy":"2022-10-31T15:43:15.590476Z","iopub.execute_input":"2022-10-31T15:43:15.591758Z","iopub.status.idle":"2022-10-31T15:43:20.455404Z","shell.execute_reply.started":"2022-10-31T15:43:15.591707Z","shell.execute_reply":"2022-10-31T15:43:20.453974Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"      ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b248604e98b4805a909ede5eda4f9dd"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2199d51ef7d04a7f810c5d8a1e66e873"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ddad7f66b3e4715bb4660b44d37c422"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c548dbe40984fe082ed5f038c1c83ed"}},"metadata":{}},{"name":"stdout","text":"      ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfa4f390a4f04db0a4c4a174a0025ce4"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d33a751c42c74dc6bccaf84746587d59"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"490c3b07eba1495281488ffebee2439f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f34ac3e37b64d50bdbd8ed8f0fcd649"}},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 11: Defining a Data Collator\nfrom transformers import DataCollatorForLanguageModeling\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n)","metadata":{"id":"19hRhnHFf7FF","execution":{"iopub.status.busy":"2022-10-31T15:43:20.457137Z","iopub.execute_input":"2022-10-31T15:43:20.457668Z","iopub.status.idle":"2022-10-31T15:43:20.962630Z","shell.execute_reply.started":"2022-10-31T15:43:20.457622Z","shell.execute_reply":"2022-10-31T15:43:20.961385Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric\n\nmetric = load_metric(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return {metric.compute(predictions=predictions, references=labels)}","metadata":{"id":"_cDyvFrNfa31","execution":{"iopub.status.busy":"2022-10-31T15:43:20.966234Z","iopub.execute_input":"2022-10-31T15:43:20.966694Z","iopub.status.idle":"2022-10-31T15:43:21.693216Z","shell.execute_reply.started":"2022-10-31T15:43:20.966655Z","shell.execute_reply":"2022-10-31T15:43:21.692054Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.41k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dab9f95716124a34bb0b022935dc1a5b"}},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 12: Initializing the Trainer\nfrom transformers import Trainer, TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./BERTimbau-Machado_Nobreak\",\n    overwrite_output_dir=True,\n    num_train_epochs=10,\n    per_device_train_batch_size=16,\n    save_steps=10_000,\n    save_total_limit=2,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=lm_datasets[\"train\"],\n    eval_dataset=lm_datasets[\"test\"],    \n)","metadata":{"id":"MH2dsTzhfgqI","outputId":"98b660e8-7b09-4143-8a8d-7b6552074ede","execution":{"iopub.status.busy":"2022-10-31T15:43:21.694990Z","iopub.execute_input":"2022-10-31T15:43:21.695825Z","iopub.status.idle":"2022-10-31T15:43:26.065329Z","shell.execute_reply.started":"2022-10-31T15:43:21.695756Z","shell.execute_reply":"2022-10-31T15:43:26.064115Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#@title Step 13: Pre-training the Model\ntrainer.train()","metadata":{"id":"EZxksqadfv6l","outputId":"5b6c546a-c2e2-45a1-d033-bccc36f774ea","execution":{"iopub.status.busy":"2022-10-31T15:43:26.066887Z","iopub.execute_input":"2022-10-31T15:43:26.067731Z","iopub.status.idle":"2022-10-31T15:59:22.948123Z","shell.execute_reply.started":"2022-10-31T15:43:26.067694Z","shell.execute_reply":"2022-10-31T15:59:22.946777Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 11066\n  Num Epochs = 10\n  Instantaneous batch size per device = 16\n  Total train batch size (w. parallel, distributed & accumulation) = 32\n  Gradient Accumulation steps = 1\n  Total optimization steps = 3460\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20221031_154427-tojjnz38</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/tccii/huggingface/runs/tojjnz38\" target=\"_blank\">./BERTimbau-Machado_Nobreak</a></strong> to <a href=\"https://wandb.ai/tccii/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3460' max='3460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3460/3460 14:39, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>2.554700</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>2.306200</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>2.169300</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>2.066200</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>1.985600</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.944000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3460, training_loss=2.1345553535946533, metrics={'train_runtime': 956.8325, 'train_samples_per_second': 115.652, 'train_steps_per_second': 3.616, 'total_flos': 1820374818915840.0, 'train_loss': 2.1345553535946533, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"code","source":"import math\neval_results = trainer.evaluate()\nprint(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")","metadata":{"id":"p9rpjGVyj68j","outputId":"f850e557-108d-44e0-9e96-a0789cfb4e9b","execution":{"iopub.status.busy":"2022-10-31T15:59:22.950620Z","iopub.execute_input":"2022-10-31T15:59:22.951907Z","iopub.status.idle":"2022-10-31T15:59:39.653842Z","shell.execute_reply.started":"2022-10-31T15:59:22.951825Z","shell.execute_reply":"2022-10-31T15:59:39.652260Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 3751\n  Batch size = 16\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='235' max='235' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [235/235 00:16]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Perplexity: 8.56\n","output_type":"stream"}]},{"cell_type":"code","source":"eval_results","metadata":{"id":"Ihaz7TAMAF4l","outputId":"9968d417-56a4-4425-ccf7-7f7e449dc0df","execution":{"iopub.status.busy":"2022-10-31T15:59:39.655661Z","iopub.execute_input":"2022-10-31T15:59:39.656130Z","iopub.status.idle":"2022-10-31T15:59:39.672396Z","shell.execute_reply.started":"2022-10-31T15:59:39.656087Z","shell.execute_reply":"2022-10-31T15:59:39.671217Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 2.14743709564209,\n 'eval_runtime': 16.6807,\n 'eval_samples_per_second': 224.87,\n 'eval_steps_per_second': 14.088,\n 'epoch': 10.0}"},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 14: Saving the Final Model(+tokenizer + config) to disk\ntrainer.save_model(\"./BERTimbau-Machado_Nobreak\")","metadata":{"id":"xusSgo3unkRI","outputId":"7128221d-3161-48d7-eca4-4592009cc584","execution":{"iopub.status.busy":"2022-10-31T15:59:39.674052Z","iopub.execute_input":"2022-10-31T15:59:39.675379Z","iopub.status.idle":"2022-10-31T15:59:40.927568Z","shell.execute_reply.started":"2022-10-31T15:59:39.675336Z","shell.execute_reply":"2022-10-31T15:59:40.926285Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Saving model checkpoint to ./BERTimbau-Machado_Nobreak\nConfiguration saved in ./BERTimbau-Machado_Nobreak/config.json\nModel weights saved in ./BERTimbau-Machado_Nobreak/pytorch_model.bin\n","output_type":"stream"}]},{"cell_type":"code","source":"# Saving model on Wandb\nimport wandb\nwandb.save('BERTimbau-Machado_Nobreak.h5')","metadata":{"execution":{"iopub.status.busy":"2022-10-31T15:59:40.929640Z","iopub.execute_input":"2022-10-31T15:59:40.930449Z","iopub.status.idle":"2022-10-31T15:59:40.941910Z","shell.execute_reply.started":"2022-10-31T15:59:40.930400Z","shell.execute_reply":"2022-10-31T15:59:40.940443Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 3: Configurando o pipeline fill-mask\n#@title Step 15: Language Modeling with the FillMaskPipeline\nfrom transformers import pipeline\n\nfill_mask = pipeline(\n    \"fill-mask\",\n    model=\"./BERTimbau-Machado_Nobreak\",\n    tokenizer=tokenizer\n)","metadata":{"id":"pqy7oTgYFb9Y","outputId":"82629ccc-36b7-439e-df94-7af7fdd47516","execution":{"iopub.status.busy":"2022-10-31T15:59:40.945239Z","iopub.execute_input":"2022-10-31T15:59:40.946327Z","iopub.status.idle":"2022-10-31T15:59:42.983024Z","shell.execute_reply.started":"2022-10-31T15:59:40.946276Z","shell.execute_reply":"2022-10-31T15:59:42.981676Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"loading configuration file ./BERTimbau-Machado_Nobreak/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"./BERTimbau-Machado_Nobreak\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"directionality\": \"bidi\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_past\": true,\n  \"pad_token_id\": 0,\n  \"pooler_fc_size\": 768,\n  \"pooler_num_attention_heads\": 12,\n  \"pooler_num_fc_layers\": 3,\n  \"pooler_size_per_head\": 128,\n  \"pooler_type\": \"first_token_transform\",\n  \"position_embedding_type\": \"absolute\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 29794\n}\n\nloading configuration file ./BERTimbau-Machado_Nobreak/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"./BERTimbau-Machado_Nobreak\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"directionality\": \"bidi\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_past\": true,\n  \"pad_token_id\": 0,\n  \"pooler_fc_size\": 768,\n  \"pooler_num_attention_heads\": 12,\n  \"pooler_num_fc_layers\": 3,\n  \"pooler_size_per_head\": 128,\n  \"pooler_type\": \"first_token_transform\",\n  \"position_embedding_type\": \"absolute\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 29794\n}\n\nloading weights file ./BERTimbau-Machado_Nobreak/pytorch_model.bin\nAll model checkpoint weights were used when initializing BertForMaskedLM.\n\nAll the weights of BertForMaskedLM were initialized from the model checkpoint at ./BERTimbau-Machado_Nobreak.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"fill_mask(\"O rapaz olhou para o [MASK] \")","metadata":{"id":"RRrtRPA6GRF8","outputId":"940a13ea-77ee-42eb-df7e-7d3199234cde","execution":{"iopub.status.busy":"2022-10-31T15:59:42.984833Z","iopub.execute_input":"2022-10-31T15:59:42.985550Z","iopub.status.idle":"2022-10-31T15:59:43.315831Z","shell.execute_reply.started":"2022-10-31T15:59:42.985500Z","shell.execute_reply":"2022-10-31T15:59:43.314322Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.10413004457950592,\n  'token': 119,\n  'token_str': '.',\n  'sequence': 'O rapaz olhou para o.'},\n {'score': 0.05723496899008751,\n  'token': 1341,\n  'token_str': 'lado',\n  'sequence': 'O rapaz olhou para o lado'},\n {'score': 0.05527610704302788,\n  'token': 14467,\n  'token_str': 'relógio',\n  'sequence': 'O rapaz olhou para o relógio'},\n {'score': 0.041138045489788055,\n  'token': 1342,\n  'token_str': 'outro',\n  'sequence': 'O rapaz olhou para o outro'},\n {'score': 0.036971405148506165,\n  'token': 21809,\n  'token_str': 'cachorro',\n  'sequence': 'O rapaz olhou para o cachorro'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"A moça olhou para o [MASK] \")","metadata":{"id":"56WEAY40asDv","outputId":"b70c5b72-8475-41b6-8bb7-37d7ed675fb4","execution":{"iopub.status.busy":"2022-10-31T15:59:43.317932Z","iopub.execute_input":"2022-10-31T15:59:43.318443Z","iopub.status.idle":"2022-10-31T15:59:43.507383Z","shell.execute_reply.started":"2022-10-31T15:59:43.318393Z","shell.execute_reply":"2022-10-31T15:59:43.506212Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.07597547769546509,\n  'token': 14467,\n  'token_str': 'relógio',\n  'sequence': 'A moça olhou para o relógio'},\n {'score': 0.0605371855199337,\n  'token': 1341,\n  'token_str': 'lado',\n  'sequence': 'A moça olhou para o lado'},\n {'score': 0.05134221911430359,\n  'token': 4170,\n  'token_str': 'marido',\n  'sequence': 'A moça olhou para o marido'},\n {'score': 0.044002778828144073,\n  'token': 16909,\n  'token_str': 'muro',\n  'sequence': 'A moça olhou para o muro'},\n {'score': 0.03901253268122673,\n  'token': 119,\n  'token_str': '.',\n  'sequence': 'A moça olhou para o.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Comprou uma [MASK] na loja. \")","metadata":{"id":"HiDV-v5rTyJt","outputId":"f082e061-276c-4984-b96f-26021fb3d323","execution":{"iopub.status.busy":"2022-10-31T15:59:43.509142Z","iopub.execute_input":"2022-10-31T15:59:43.510218Z","iopub.status.idle":"2022-10-31T15:59:43.701012Z","shell.execute_reply.started":"2022-10-31T15:59:43.510168Z","shell.execute_reply":"2022-10-31T15:59:43.699850Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.2826457917690277,\n  'token': 3743,\n  'token_str': 'carta',\n  'sequence': 'Comprou uma carta na loja.'},\n {'score': 0.04299076274037361,\n  'token': 9104,\n  'token_str': 'cadeira',\n  'sequence': 'Comprou uma cadeira na loja.'},\n {'score': 0.03940936550498009,\n  'token': 4428,\n  'token_str': 'nota',\n  'sequence': 'Comprou uma nota na loja.'},\n {'score': 0.03248007968068123,\n  'token': 7924,\n  'token_str': 'camisa',\n  'sequence': 'Comprou uma camisa na loja.'},\n {'score': 0.03227231279015541,\n  'token': 11064,\n  'token_str': 'cópia',\n  'sequence': 'Comprou uma cópia na loja.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"A mulher não é [MASK]. \")","metadata":{"id":"gVnhg1bxT-wK","outputId":"b3d1da07-a8f4-497e-8b6b-a5629c69831b","execution":{"iopub.status.busy":"2022-10-31T15:59:43.702611Z","iopub.execute_input":"2022-10-31T15:59:43.703532Z","iopub.status.idle":"2022-10-31T15:59:43.890227Z","shell.execute_reply.started":"2022-10-31T15:59:43.703482Z","shell.execute_reply":"2022-10-31T15:59:43.889146Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.14185231924057007,\n  'token': 1016,\n  'token_str': 'assim',\n  'sequence': 'A mulher não é assim.'},\n {'score': 0.046089041978120804,\n  'token': 19543,\n  'token_str': 'bonita',\n  'sequence': 'A mulher não é bonita.'},\n {'score': 0.03142426908016205,\n  'token': 2124,\n  'token_str': 'forte',\n  'sequence': 'A mulher não é forte.'},\n {'score': 0.030483601614832878,\n  'token': 19462,\n  'token_str': 'santa',\n  'sequence': 'A mulher não é santa.'},\n {'score': 0.030340641736984253,\n  'token': 3264,\n  'token_str': 'boa',\n  'sequence': 'A mulher não é boa.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"O homem não é [MASK]. \")","metadata":{"id":"l486NETHUFw6","outputId":"06df0abd-b2e7-4a24-885d-0739ed80d6bb","execution":{"iopub.status.busy":"2022-10-31T15:59:43.891947Z","iopub.execute_input":"2022-10-31T15:59:43.892948Z","iopub.status.idle":"2022-10-31T15:59:44.059271Z","shell.execute_reply.started":"2022-10-31T15:59:43.892904Z","shell.execute_reply":"2022-10-31T15:59:44.058184Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.08181378245353699,\n  'token': 1016,\n  'token_str': 'assim',\n  'sequence': 'O homem não é assim.'},\n {'score': 0.06949321925640106,\n  'token': 2397,\n  'token_str': 'homem',\n  'sequence': 'O homem não é homem.'},\n {'score': 0.061880793422460556,\n  'token': 11775,\n  'token_str': 'mau',\n  'sequence': 'O homem não é mau.'},\n {'score': 0.04127956181764603,\n  'token': 13380,\n  'token_str': 'perfeito',\n  'sequence': 'O homem não é perfeito.'},\n {'score': 0.025666052475571632,\n  'token': 4062,\n  'token_str': 'bom',\n  'sequence': 'O homem não é bom.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Ele é um bom [MASK]. \")","metadata":{"id":"XBxjvRGYVAxC","outputId":"bb309e59-bfe6-42b1-aa4b-0a689b84a97a","execution":{"iopub.status.busy":"2022-10-31T15:59:44.060765Z","iopub.execute_input":"2022-10-31T15:59:44.061475Z","iopub.status.idle":"2022-10-31T15:59:44.235295Z","shell.execute_reply.started":"2022-10-31T15:59:44.061427Z","shell.execute_reply":"2022-10-31T15:59:44.234177Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.30195632576942444,\n  'token': 2397,\n  'token_str': 'homem',\n  'sequence': 'Ele é um bom homem.'},\n {'score': 0.17182405292987823,\n  'token': 3695,\n  'token_str': 'amigo',\n  'sequence': 'Ele é um bom amigo.'},\n {'score': 0.07464156299829483,\n  'token': 13254,\n  'token_str': 'rapaz',\n  'sequence': 'Ele é um bom rapaz.'},\n {'score': 0.042831577360630035,\n  'token': 10110,\n  'token_str': 'companheiro',\n  'sequence': 'Ele é um bom companheiro.'},\n {'score': 0.031354039907455444,\n  'token': 21809,\n  'token_str': 'cachorro',\n  'sequence': 'Ele é um bom cachorro.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Ela é uma boa [MASK]. \")","metadata":{"id":"PBQ5HugqVPF4","outputId":"2db97d91-c29b-49e2-f2c7-2dd93400d051","execution":{"iopub.status.busy":"2022-10-31T15:59:44.237257Z","iopub.execute_input":"2022-10-31T15:59:44.237676Z","iopub.status.idle":"2022-10-31T15:59:44.404726Z","shell.execute_reply.started":"2022-10-31T15:59:44.237635Z","shell.execute_reply":"2022-10-31T15:59:44.403646Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.19099988043308258,\n  'token': 2760,\n  'token_str': 'pessoa',\n  'sequence': 'Ela é uma boa pessoa.'},\n {'score': 0.1507546752691269,\n  'token': 18073,\n  'token_str': 'moça',\n  'sequence': 'Ela é uma boa moça.'},\n {'score': 0.11485721170902252,\n  'token': 2606,\n  'token_str': 'mulher',\n  'sequence': 'Ela é uma boa mulher.'},\n {'score': 0.09198703616857529,\n  'token': 8932,\n  'token_str': 'amiga',\n  'sequence': 'Ela é uma boa amiga.'},\n {'score': 0.05999397858977318,\n  'token': 17704,\n  'token_str': 'senhora',\n  'sequence': 'Ela é uma boa senhora.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Faz de conta que ainda é [MASK]. \")","metadata":{"id":"qUBfuZBNa4_2","outputId":"dfae7051-1ffb-4787-f1d3-8fc4e28ff1a1","execution":{"iopub.status.busy":"2022-10-31T15:59:44.406500Z","iopub.execute_input":"2022-10-31T15:59:44.406932Z","iopub.status.idle":"2022-10-31T15:59:44.600996Z","shell.execute_reply.started":"2022-10-31T15:59:44.406899Z","shell.execute_reply":"2022-10-31T15:59:44.599455Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.675611674785614,\n  'token': 1373,\n  'token_str': 'tarde',\n  'sequence': 'Faz de conta que ainda é tarde.'},\n {'score': 0.09830227494239807,\n  'token': 8545,\n  'token_str': 'cedo',\n  'sequence': 'Faz de conta que ainda é cedo.'},\n {'score': 0.04518957808613777,\n  'token': 1695,\n  'token_str': 'pouco',\n  'sequence': 'Faz de conta que ainda é pouco.'},\n {'score': 0.03625005483627319,\n  'token': 596,\n  'token_str': 'tempo',\n  'sequence': 'Faz de conta que ainda é tempo.'},\n {'score': 0.015292984433472157,\n  'token': 2199,\n  'token_str': 'possível',\n  'sequence': 'Faz de conta que ainda é possível.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Depois da tempestade vem a [MASK]. \")","metadata":{"id":"u4E4MHWmbBsH","outputId":"49947f61-6226-494b-9424-e953c96363b8","execution":{"iopub.status.busy":"2022-10-31T15:59:44.607551Z","iopub.execute_input":"2022-10-31T15:59:44.608705Z","iopub.status.idle":"2022-10-31T15:59:44.795094Z","shell.execute_reply.started":"2022-10-31T15:59:44.608663Z","shell.execute_reply":"2022-10-31T15:59:44.793873Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.20319883525371552,\n  'token': 13943,\n  'token_str': 'lua',\n  'sequence': 'Depois da tempestade vem a lua.'},\n {'score': 0.11582215875387192,\n  'token': 9856,\n  'token_str': 'chuva',\n  'sequence': 'Depois da tempestade vem a chuva.'},\n {'score': 0.08336257934570312,\n  'token': 4527,\n  'token_str': 'paz',\n  'sequence': 'Depois da tempestade vem a paz.'},\n {'score': 0.07426557689905167,\n  'token': 7658,\n  'token_str': 'tempestade',\n  'sequence': 'Depois da tempestade vem a tempestade.'},\n {'score': 0.06317467242479324,\n  'token': 1386,\n  'token_str': 'morte',\n  'sequence': 'Depois da tempestade vem a morte.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Mais vale um pássaro na mão do que [MASK] voando. \")","metadata":{"id":"8bd3GbaabIn7","outputId":"3d305d34-61bf-446b-b917-2be8cc19abc4","execution":{"iopub.status.busy":"2022-10-31T15:59:44.796614Z","iopub.execute_input":"2022-10-31T15:59:44.797247Z","iopub.status.idle":"2022-10-31T15:59:45.023665Z","shell.execute_reply.started":"2022-10-31T15:59:44.797213Z","shell.execute_reply":"2022-10-31T15:59:45.022598Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.29421281814575195,\n  'token': 1342,\n  'token_str': 'outro',\n  'sequence': 'Mais vale um pássaro na mão do que outro voando.'},\n {'score': 0.11427430808544159,\n  'token': 222,\n  'token_str': 'um',\n  'sequence': 'Mais vale um pássaro na mão do que um voando.'},\n {'score': 0.09156253933906555,\n  'token': 17804,\n  'token_str': 'pássaros',\n  'sequence': 'Mais vale um pássaro na mão do que pássaros voando.'},\n {'score': 0.07606584578752518,\n  'token': 14934,\n  'token_str': 'voar',\n  'sequence': 'Mais vale um pássaro na mão do que voar voando.'},\n {'score': 0.06261930614709854,\n  'token': 368,\n  'token_str': 'ele',\n  'sequence': 'Mais vale um pássaro na mão do que ele voando.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Não tinha [MASK], mas almoçou mesmo assim. \")","metadata":{"id":"bhep3pt3bUkJ","outputId":"fd3b55ec-3923-4308-f851-707faafda30e","execution":{"iopub.status.busy":"2022-10-31T15:59:45.025536Z","iopub.execute_input":"2022-10-31T15:59:45.025970Z","iopub.status.idle":"2022-10-31T15:59:45.230094Z","shell.execute_reply.started":"2022-10-31T15:59:45.025928Z","shell.execute_reply":"2022-10-31T15:59:45.229031Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.7031448483467102,\n  'token': 11062,\n  'token_str': 'fome',\n  'sequence': 'Não tinha fome, mas almoçou mesmo assim.'},\n {'score': 0.047053754329681396,\n  'token': 11334,\n  'token_str': 'sono',\n  'sequence': 'Não tinha sono, mas almoçou mesmo assim.'},\n {'score': 0.014355580322444439,\n  'token': 12215,\n  'token_str': 'costume',\n  'sequence': 'Não tinha costume, mas almoçou mesmo assim.'},\n {'score': 0.014220478013157845,\n  'token': 3874,\n  'token_str': 'nada',\n  'sequence': 'Não tinha nada, mas almoçou mesmo assim.'},\n {'score': 0.013541623018682003,\n  'token': 7672,\n  'token_str': 'medo',\n  'sequence': 'Não tinha medo, mas almoçou mesmo assim.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Bebeu um copo d'água, pois tinha [MASK]. \")","metadata":{"id":"Vpn7cJREbj_Y","outputId":"c5a60b8a-9923-4ed3-da44-e478d2bd0954","execution":{"iopub.status.busy":"2022-10-31T15:59:45.232024Z","iopub.execute_input":"2022-10-31T15:59:45.232442Z","iopub.status.idle":"2022-10-31T15:59:45.475015Z","shell.execute_reply.started":"2022-10-31T15:59:45.232398Z","shell.execute_reply":"2022-10-31T15:59:45.473953Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.4648318886756897,\n  'token': 11062,\n  'token_str': 'fome',\n  'sequence': \"Bebeu um copo d'água, pois tinha fome.\"},\n {'score': 0.20951294898986816,\n  'token': 2496,\n  'token_str': 'sede',\n  'sequence': \"Bebeu um copo d'água, pois tinha sede.\"},\n {'score': 0.1879357248544693,\n  'token': 14594,\n  'token_str': 'febre',\n  'sequence': \"Bebeu um copo d'água, pois tinha febre.\"},\n {'score': 0.020011885091662407,\n  'token': 7672,\n  'token_str': 'medo',\n  'sequence': \"Bebeu um copo d'água, pois tinha medo.\"},\n {'score': 0.019525859504938126,\n  'token': 11334,\n  'token_str': 'sono',\n  'sequence': \"Bebeu um copo d'água, pois tinha sono.\"}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Sem saber, ele descobriu um [MASK]. \")","metadata":{"id":"9KrDcsT2bzkl","outputId":"fde63380-d420-4e04-9b05-f330eec3ee76","execution":{"iopub.status.busy":"2022-10-31T15:59:45.476887Z","iopub.execute_input":"2022-10-31T15:59:45.477285Z","iopub.status.idle":"2022-10-31T15:59:45.663531Z","shell.execute_reply.started":"2022-10-31T15:59:45.477246Z","shell.execute_reply":"2022-10-31T15:59:45.662249Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.17505799233913422,\n  'token': 11021,\n  'token_str': 'segredo',\n  'sequence': 'Sem saber, ele descobriu um segredo.'},\n {'score': 0.05680672824382782,\n  'token': 16269,\n  'token_str': 'mistério',\n  'sequence': 'Sem saber, ele descobriu um mistério.'},\n {'score': 0.036026276648044586,\n  'token': 3204,\n  'token_str': 'plano',\n  'sequence': 'Sem saber, ele descobriu um plano.'},\n {'score': 0.03242781013250351,\n  'token': 3420,\n  'token_str': 'caminho',\n  'sequence': 'Sem saber, ele descobriu um caminho.'},\n {'score': 0.03229935094714165,\n  'token': 8332,\n  'token_str': 'negócio',\n  'sequence': 'Sem saber, ele descobriu um negócio.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Pedro fez fortuna vendendo [MASK]. \")","metadata":{"id":"FzIuM2mFb6tc","outputId":"d117842d-8035-4682-e27c-6174ee2a62e8","execution":{"iopub.status.busy":"2022-10-31T15:59:45.665360Z","iopub.execute_input":"2022-10-31T15:59:45.666113Z","iopub.status.idle":"2022-10-31T15:59:45.833152Z","shell.execute_reply.started":"2022-10-31T15:59:45.666065Z","shell.execute_reply":"2022-10-31T15:59:45.831820Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.1847214251756668,\n  'token': 5976,\n  'token_str': 'escravos',\n  'sequence': 'Pedro fez fortuna vendendo escravos.'},\n {'score': 0.13227835297584534,\n  'token': 7568,\n  'token_str': 'café',\n  'sequence': 'Pedro fez fortuna vendendo café.'},\n {'score': 0.0729813352227211,\n  'token': 2978,\n  'token_str': 'livros',\n  'sequence': 'Pedro fez fortuna vendendo livros.'},\n {'score': 0.04924408718943596,\n  'token': 9701,\n  'token_str': 'cavalos',\n  'sequence': 'Pedro fez fortuna vendendo cavalos.'},\n {'score': 0.04435919225215912,\n  'token': 6536,\n  'token_str': 'cartas',\n  'sequence': 'Pedro fez fortuna vendendo cartas.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Sem medo de ser [MASK]. \")","metadata":{"id":"4t6LS5glcZFN","outputId":"ad7fb0c9-1c4c-4884-9a37-e68bce58e77f","execution":{"iopub.status.busy":"2022-10-31T15:59:45.835176Z","iopub.execute_input":"2022-10-31T15:59:45.835616Z","iopub.status.idle":"2022-10-31T15:59:46.000661Z","shell.execute_reply.started":"2022-10-31T15:59:45.835571Z","shell.execute_reply":"2022-10-31T15:59:45.999565Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.8116620182991028,\n  'token': 8540,\n  'token_str': 'feliz',\n  'sequence': 'Sem medo de ser feliz.'},\n {'score': 0.015370883047580719,\n  'token': 3382,\n  'token_str': 'visto',\n  'sequence': 'Sem medo de ser visto.'},\n {'score': 0.01232471875846386,\n  'token': 7148,\n  'token_str': 'padre',\n  'sequence': 'Sem medo de ser padre.'},\n {'score': 0.009614771232008934,\n  'token': 1016,\n  'token_str': 'assim',\n  'sequence': 'Sem medo de ser assim.'},\n {'score': 0.006740317214280367,\n  'token': 8085,\n  'token_str': 'descoberto',\n  'sequence': 'Sem medo de ser descoberto.'}]"},"metadata":{}}]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2022-10-31T15:59:46.002281Z","iopub.execute_input":"2022-10-31T15:59:46.002694Z","iopub.status.idle":"2022-10-31T15:59:50.424109Z","shell.execute_reply.started":"2022-10-31T15:59:46.002649Z","shell.execute_reply":"2022-10-31T15:59:50.422873Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▃▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▅▆▇██</td></tr><tr><td>train/learning_rate</td><td>█▇▅▄▂▁</td></tr><tr><td>train/loss</td><td>█▅▄▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.14744</td></tr><tr><td>eval/runtime</td><td>16.6807</td></tr><tr><td>eval/samples_per_second</td><td>224.87</td></tr><tr><td>eval/steps_per_second</td><td>14.088</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>3460</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.944</td></tr><tr><td>train/total_flos</td><td>1820374818915840.0</td></tr><tr><td>train/train_loss</td><td>2.13456</td></tr><tr><td>train/train_runtime</td><td>956.8325</td></tr><tr><td>train/train_samples_per_second</td><td>115.652</td></tr><tr><td>train/train_steps_per_second</td><td>3.616</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Synced <strong style=\"color:#cdcd00\">./BERTimbau-Machado_Nobreak</strong>: <a href=\"https://wandb.ai/tccii/huggingface/runs/tojjnz38\" target=\"_blank\">https://wandb.ai/tccii/huggingface/runs/tojjnz38</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20221031_154427-tojjnz38/logs</code>"},"metadata":{}}]}]}