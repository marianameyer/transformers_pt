{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/jsansao/transformers_pt/blob/main/BERTimbau_Fine_tuning_CETENFolha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"# Inferência usando transformers pré-treinados do HuggingFace ","metadata":{"id":"hV_s2jhFIGRV"}},{"cell_type":"markdown","source":"BERTimbau\nCENTENFolha - 8 partes\nBatch size = 16\nGPU T4x2","metadata":{}},{"cell_type":"code","source":"#@title Passo 1:Instalando Hugging Face Transformers\n# We won't need TensorFlow here\n!pip uninstall -y tensorflow\n# Install `transformers` from master\n!pip install transformers datasets\n!pip list | grep -E 'transformers|tokenizers'\n# transformers version at notebook update --- 2.9.1\n# tokenizers version at notebook update --- 0.7.0","metadata":{"id":"LhI1tJBGBd3r","outputId":"6992ec79-0f86-4f41-ec7a-6d3b9e7f1848","execution":{"iopub.status.busy":"2022-10-29T00:54:58.509895Z","iopub.execute_input":"2022-10-29T00:54:58.510937Z","iopub.status.idle":"2022-10-29T00:55:34.402438Z","shell.execute_reply.started":"2022-10-29T00:54:58.510841Z","shell.execute_reply":"2022-10-29T00:55:34.401237Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Found existing installation: tensorflow 2.6.4\nUninstalling tensorflow-2.6.4:\n  Successfully uninstalled tensorflow-2.6.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.13)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.8.2)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.5.1)\nRequirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.1.1)\nRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.4.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mtokenizers                            0.12.1\ntransformers                          4.20.1\n","output_type":"stream"}]},{"cell_type":"code","source":"#@title Step 1: Loading the Dataset\n#1.Load kant.txt using the Colab file manager\n#2.Downloading the file from GitHub\n#!curl -L  https://raw.githubusercontent.com/jsansao/corpus_ptbr/main/dump_Machado_Nobreak.txt --output \"dump.txt\"\n!curl -L https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_aa --output \"dump.txt\"\n#!curl -L https://raw.githubusercontent.com/jsansao/corpus_ptbr/main/Lyrics_ChicoBuarque.txt --output \"kant.txt\"\n\n!awk NF < dump.txt > kant.txt","metadata":{"id":"KAl5BxxOgk35","outputId":"bab59eaa-60cf-462b-d681-2c89b64978e8","execution":{"iopub.status.busy":"2022-10-29T00:55:34.406688Z","iopub.execute_input":"2022-10-29T00:55:34.407052Z","iopub.status.idle":"2022-10-29T00:55:37.026953Z","shell.execute_reply.started":"2022-10-29T00:55:34.407015Z","shell.execute_reply":"2022-10-29T00:55:37.025585Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 3724k  100 3724k    0     0  7727k      0 --:--:-- --:--:-- --:--:-- 7711k\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_aa \n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ab\n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ac\n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ad\n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ae \n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_af\n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ag\n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ah","metadata":{"id":"aDPWlxTHRC7-","outputId":"86726bae-8fe1-4f30-8509-a4da74a4ed0a","execution":{"iopub.status.busy":"2022-10-29T00:55:37.029435Z","iopub.execute_input":"2022-10-29T00:55:37.029851Z","iopub.status.idle":"2022-10-29T00:55:48.432213Z","shell.execute_reply.started":"2022-10-29T00:55:37.029807Z","shell.execute_reply":"2022-10-29T00:55:48.431101Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"--2022-10-29 00:55:37--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_aa\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: ‘cetenfolha_aa’\n\ncetenfolha_aa       100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-29 00:55:38 (52.0 MB/s) - ‘cetenfolha_aa’ saved [3813899/3813899]\n\n--2022-10-29 00:55:39--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ab\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: ‘cetenfolha_ab’\n\ncetenfolha_ab       100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-29 00:55:39 (49.6 MB/s) - ‘cetenfolha_ab’ saved [3813899/3813899]\n\n--2022-10-29 00:55:40--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ac\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: ‘cetenfolha_ac’\n\ncetenfolha_ac       100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-29 00:55:41 (49.9 MB/s) - ‘cetenfolha_ac’ saved [3813899/3813899]\n\n--2022-10-29 00:55:42--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ad\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: ‘cetenfolha_ad’\n\ncetenfolha_ad       100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-29 00:55:42 (49.2 MB/s) - ‘cetenfolha_ad’ saved [3813899/3813899]\n\n--2022-10-29 00:55:43--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ae\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: ‘cetenfolha_ae’\n\ncetenfolha_ae       100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-29 00:55:44 (54.8 MB/s) - ‘cetenfolha_ae’ saved [3813899/3813899]\n\n--2022-10-29 00:55:44--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_af\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: ‘cetenfolha_af’\n\ncetenfolha_af       100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-29 00:55:45 (51.1 MB/s) - ‘cetenfolha_af’ saved [3813899/3813899]\n\n--2022-10-29 00:55:46--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ag\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: ‘cetenfolha_ag’\n\ncetenfolha_ag       100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-29 00:55:46 (50.1 MB/s) - ‘cetenfolha_ag’ saved [3813899/3813899]\n\n--2022-10-29 00:55:47--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ah\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: ‘cetenfolha_ah’\n\ncetenfolha_ah       100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-29 00:55:48 (53.1 MB/s) - ‘cetenfolha_ah’ saved [3813899/3813899]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!cat cetenfolha_aa cetenfolha_ab cetenfolha_ac cetenfolha_ad cetenfolha_ae cetenfolha_af cetenfolha_ag cetenfolha_ah>  dump.txt\n!awk NF < dump.txt > kant.txt","metadata":{"id":"kFetqxZ3RToJ","execution":{"iopub.status.busy":"2022-10-29T00:55:48.435241Z","iopub.execute_input":"2022-10-29T00:55:48.435663Z","iopub.status.idle":"2022-10-29T00:55:50.814640Z","shell.execute_reply.started":"2022-10-29T00:55:48.435627Z","shell.execute_reply":"2022-10-29T00:55:50.813072Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#@title Passo 2:Baixando e salvando BR_BERTo\n#https://huggingface.co/rdenadai/BR_BERTo\n\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM\n\n#tokenizer = AutoTokenizer.from_pretrained(\"rdenadai/BR_BERTo\")\n#model = AutoModelForMaskedLM.from_pretrained(\"rdenadai/BR_BERTo\")\n\ntokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\nmodel = AutoModelForMaskedLM.from_pretrained('neuralmind/bert-base-portuguese-cased')","metadata":{"id":"h2L_Put8Cn8S","outputId":"0e90b320-f004-490b-a683-2ef33b3dc60a","execution":{"iopub.status.busy":"2022-10-29T00:55:50.819269Z","iopub.execute_input":"2022-10-29T00:55:50.819588Z","iopub.status.idle":"2022-10-29T00:56:19.329194Z","shell.execute_reply.started":"2022-10-29T00:55:50.819553Z","shell.execute_reply":"2022-10-29T00:56:19.328111Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/43.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bddc6bbec3b4c63bd6fede0f36a6f07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/647 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d93b121951504c6182d48d073245a44e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/205k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e29913499e884abeb9ec3fac9cb64ad6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ec8ec59acc9430d8d2a11a55ad02da7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1e974052c784c7c89a5219f9730567c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/418M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3716d5b213e443d9611a87506640d79"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n#datasets = load_dataset(\"text\", data_files={\"train\": \"kant.txt\", \"validation\": \"kant_teste.txt\"})\n#datasets = load_dataset(\"text\", data_files={\"train\": \"kant.txt\"}, split='train[:90%]')\nds = load_dataset(\"text\", data_files={\"train\": \"kant.txt\"})\n\ndatasets = ds[\"train\"].train_test_split()","metadata":{"id":"J1oYngljZeZT","outputId":"98366916-3dd6-4469-e69e-83a2eeadcdfe","execution":{"iopub.status.busy":"2022-10-29T00:56:19.331535Z","iopub.execute_input":"2022-10-29T00:56:19.332273Z","iopub.status.idle":"2022-10-29T00:56:20.827013Z","shell.execute_reply.started":"2022-10-29T00:56:19.332229Z","shell.execute_reply":"2022-10-29T00:56:20.826030Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-20f1a5c3a14eeedc/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"382ae8e08df34c82b924c89ad8b5e1cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cbf4f8cd49641c483ea93cc1115e7bd"}},"metadata":{}},{"name":"stdout","text":"Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-20f1a5c3a14eeedc/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2783587b5f824e95bedc3b7a04102cce"}},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(examples[\"text\"])","metadata":{"id":"7JiCdblobSdn","execution":{"iopub.status.busy":"2022-10-29T00:56:20.828423Z","iopub.execute_input":"2022-10-29T00:56:20.829018Z","iopub.status.idle":"2022-10-29T00:56:20.833827Z","shell.execute_reply.started":"2022-10-29T00:56:20.828987Z","shell.execute_reply":"2022-10-29T00:56:20.832869Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])","metadata":{"id":"QT8eOoqmbYV2","outputId":"f0c2ed49-ddce-409f-b78e-c8cb83d47841","execution":{"iopub.status.busy":"2022-10-29T00:56:20.835822Z","iopub.execute_input":"2022-10-29T00:56:20.836500Z","iopub.status.idle":"2022-10-29T00:56:48.790400Z","shell.execute_reply.started":"2022-10-29T00:56:20.836460Z","shell.execute_reply":"2022-10-29T00:56:48.789185Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"      ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04aedc52bbb24870ade18264f5e15176"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"534d50a59121491cb9c6db2a62fec5db"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4534454905fd4754b9b28d4825ba2700"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2a8dfc0501b4ae2bf7ad3dd51c4f5a5"}},"metadata":{}},{"name":"stdout","text":"     ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e82d825fb84b4610987c3b607c2c5606"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9cdd3c40d8a48539130ae37a874c6ee"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39fdaf1c0fa444c786b45a40a3d78568"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37644c84eb7c45ce82c716f4fa1e02a7"}},"metadata":{}}]},{"cell_type":"markdown","source":"exemplo de entrada","metadata":{"id":"ETLIt8siKjWC"}},{"cell_type":"code","source":"tokenized_datasets[\"train\"][4]","metadata":{"id":"7_umRvrQKT6g","outputId":"31557af2-70c4-4a38-a3ec-fb6a54c8fb17","execution":{"iopub.status.busy":"2022-10-29T00:56:48.792560Z","iopub.execute_input":"2022-10-29T00:56:48.792991Z","iopub.status.idle":"2022-10-29T00:56:48.804108Z","shell.execute_reply.started":"2022-10-29T00:56:48.792940Z","shell.execute_reply":"2022-10-29T00:56:48.802010Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101,\n  1643,\n  131,\n  1000,\n  1448,\n  22281,\n  118,\n  21248,\n  117,\n  1000,\n  275,\n  22296,\n  3708,\n  102],\n 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"#block_size = tokenizer.model_max_length\nblock_size = 32","metadata":{"id":"2cVk21VpKt0o","execution":{"iopub.status.busy":"2022-10-29T00:56:48.805772Z","iopub.execute_input":"2022-10-29T00:56:48.806417Z","iopub.status.idle":"2022-10-29T00:56:48.841369Z","shell.execute_reply.started":"2022-10-29T00:56:48.806380Z","shell.execute_reply":"2022-10-29T00:56:48.840418Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def group_texts(examples):\n    # Concatenate all texts.\n    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n    total_length = len(concatenated_examples[list(examples.keys())[0]])\n    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n        # customize this part to your needs.\n    total_length = (total_length // block_size) * block_size\n    # Split by chunks of max_len.\n    result = {\n        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n        for k, t in concatenated_examples.items()\n    }\n    result[\"labels\"] = result[\"input_ids\"].copy()\n    return result","metadata":{"id":"zif6EA4VcCk0","execution":{"iopub.status.busy":"2022-10-29T00:56:48.844534Z","iopub.execute_input":"2022-10-29T00:56:48.844808Z","iopub.status.idle":"2022-10-29T00:56:48.853936Z","shell.execute_reply.started":"2022-10-29T00:56:48.844782Z","shell.execute_reply":"2022-10-29T00:56:48.852858Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"lm_datasets = tokenized_datasets.map(\n    group_texts,\n    batched=True,\n    batch_size=1000,\n    num_proc=4,\n)","metadata":{"id":"4Xb0RzHtb2RJ","outputId":"1de1f00a-c9ab-4eee-bec0-79ee12ed0a35","execution":{"iopub.status.busy":"2022-10-29T00:56:48.855543Z","iopub.execute_input":"2022-10-29T00:56:48.856093Z","iopub.status.idle":"2022-10-29T00:57:45.611875Z","shell.execute_reply.started":"2022-10-29T00:56:48.856054Z","shell.execute_reply":"2022-10-29T00:57:45.610704Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"      ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"025e5e7d0e904277ab00ea3306bd677a"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22997c1be83a41248e68b63ae4dd2118"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7415cdc04582404e8cfb08df2ec4627f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad1e1f1a79a94fa8baeb4157752a1170"}},"metadata":{}},{"name":"stdout","text":"      ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea977e4fdec44fbdae11e7f07f3dafe9"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb232cdbf07044349eb0962f1a6f0d96"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a81ce19295a24dee83cb0107ee7251cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b8e64fe26aa4906b2c87d7b2bc147b0"}},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 11: Defining a Data Collator\nfrom transformers import DataCollatorForLanguageModeling\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n)","metadata":{"id":"19hRhnHFf7FF","execution":{"iopub.status.busy":"2022-10-29T00:57:45.614126Z","iopub.execute_input":"2022-10-29T00:57:45.614517Z","iopub.status.idle":"2022-10-29T00:57:46.058228Z","shell.execute_reply.started":"2022-10-29T00:57:45.614477Z","shell.execute_reply":"2022-10-29T00:57:46.057124Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric\n\nmetric = load_metric(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return {metric.compute(predictions=predictions, references=labels)}","metadata":{"id":"_cDyvFrNfa31","execution":{"iopub.status.busy":"2022-10-29T00:57:46.063613Z","iopub.execute_input":"2022-10-29T00:57:46.063917Z","iopub.status.idle":"2022-10-29T00:57:46.616363Z","shell.execute_reply.started":"2022-10-29T00:57:46.063889Z","shell.execute_reply":"2022-10-29T00:57:46.615368Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.41k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0eb4bf14bfa1481e94edb9233b0ea620"}},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 12: Initializing the Trainer\nfrom transformers import Trainer, TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./BERTimbau-CENTENFolha-8_parts\",\n    overwrite_output_dir=True,\n    num_train_epochs=10,\n    per_device_train_batch_size=16,\n    save_steps=10_000,\n    save_total_limit=2,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=lm_datasets[\"train\"],\n    eval_dataset=lm_datasets[\"test\"],    \n)","metadata":{"id":"MH2dsTzhfgqI","outputId":"98b660e8-7b09-4143-8a8d-7b6552074ede","execution":{"iopub.status.busy":"2022-10-29T00:57:46.618162Z","iopub.execute_input":"2022-10-29T00:57:46.618875Z","iopub.status.idle":"2022-10-29T00:57:50.811755Z","shell.execute_reply.started":"2022-10-29T00:57:46.618833Z","shell.execute_reply":"2022-10-29T00:57:50.810443Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#@title Step 13: Pre-training the Model\ntrainer.train()","metadata":{"id":"EZxksqadfv6l","outputId":"5b6c546a-c2e2-45a1-d033-bccc36f774ea","execution":{"iopub.status.busy":"2022-10-29T00:57:50.814586Z","iopub.execute_input":"2022-10-29T00:57:50.815400Z","iopub.status.idle":"2022-10-29T04:40:47.862370Z","shell.execute_reply.started":"2022-10-29T00:57:50.815349Z","shell.execute_reply":"2022-10-29T04:40:47.861410Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 173367\n  Num Epochs = 10\n  Instantaneous batch size per device = 16\n  Total train batch size (w. parallel, distributed & accumulation) = 32\n  Gradient Accumulation steps = 1\n  Total optimization steps = 54180\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20221029_010714-t9zfjow1</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/tccii/huggingface/runs/t9zfjow1\" target=\"_blank\">./BERTimbau-CENTENFolha-8_parts</a></strong> to <a href=\"https://wandb.ai/tccii/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='54180' max='54180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [54180/54180 3:33:18, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>2.425600</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>2.361600</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>2.350600</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>2.292200</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>2.281700</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>2.280300</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>2.262900</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>2.261400</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>2.234800</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>2.240400</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>2.221300</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>2.172100</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>2.160700</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>2.139000</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>2.172500</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>2.152800</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>2.128400</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>2.157400</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>2.145000</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>2.145500</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>2.130700</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>2.126600</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>2.075400</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>2.063700</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>2.083300</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>2.060000</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>2.051900</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>2.050900</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>2.058000</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>2.055300</td>\n    </tr>\n    <tr>\n      <td>15500</td>\n      <td>2.077500</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>2.065800</td>\n    </tr>\n    <tr>\n      <td>16500</td>\n      <td>2.044600</td>\n    </tr>\n    <tr>\n      <td>17000</td>\n      <td>2.005100</td>\n    </tr>\n    <tr>\n      <td>17500</td>\n      <td>2.018600</td>\n    </tr>\n    <tr>\n      <td>18000</td>\n      <td>2.002500</td>\n    </tr>\n    <tr>\n      <td>18500</td>\n      <td>2.013800</td>\n    </tr>\n    <tr>\n      <td>19000</td>\n      <td>2.012800</td>\n    </tr>\n    <tr>\n      <td>19500</td>\n      <td>2.019800</td>\n    </tr>\n    <tr>\n      <td>20000</td>\n      <td>2.007400</td>\n    </tr>\n    <tr>\n      <td>20500</td>\n      <td>1.991300</td>\n    </tr>\n    <tr>\n      <td>21000</td>\n      <td>1.984900</td>\n    </tr>\n    <tr>\n      <td>21500</td>\n      <td>1.990500</td>\n    </tr>\n    <tr>\n      <td>22000</td>\n      <td>1.957200</td>\n    </tr>\n    <tr>\n      <td>22500</td>\n      <td>1.935700</td>\n    </tr>\n    <tr>\n      <td>23000</td>\n      <td>1.972600</td>\n    </tr>\n    <tr>\n      <td>23500</td>\n      <td>1.932900</td>\n    </tr>\n    <tr>\n      <td>24000</td>\n      <td>1.948000</td>\n    </tr>\n    <tr>\n      <td>24500</td>\n      <td>1.965500</td>\n    </tr>\n    <tr>\n      <td>25000</td>\n      <td>1.951100</td>\n    </tr>\n    <tr>\n      <td>25500</td>\n      <td>1.939800</td>\n    </tr>\n    <tr>\n      <td>26000</td>\n      <td>1.956500</td>\n    </tr>\n    <tr>\n      <td>26500</td>\n      <td>1.931200</td>\n    </tr>\n    <tr>\n      <td>27000</td>\n      <td>1.926100</td>\n    </tr>\n    <tr>\n      <td>27500</td>\n      <td>1.895700</td>\n    </tr>\n    <tr>\n      <td>28000</td>\n      <td>1.886400</td>\n    </tr>\n    <tr>\n      <td>28500</td>\n      <td>1.887200</td>\n    </tr>\n    <tr>\n      <td>29000</td>\n      <td>1.883100</td>\n    </tr>\n    <tr>\n      <td>29500</td>\n      <td>1.934800</td>\n    </tr>\n    <tr>\n      <td>30000</td>\n      <td>1.893000</td>\n    </tr>\n    <tr>\n      <td>30500</td>\n      <td>1.899200</td>\n    </tr>\n    <tr>\n      <td>31000</td>\n      <td>1.883700</td>\n    </tr>\n    <tr>\n      <td>31500</td>\n      <td>1.896400</td>\n    </tr>\n    <tr>\n      <td>32000</td>\n      <td>1.898800</td>\n    </tr>\n    <tr>\n      <td>32500</td>\n      <td>1.901800</td>\n    </tr>\n    <tr>\n      <td>33000</td>\n      <td>1.837500</td>\n    </tr>\n    <tr>\n      <td>33500</td>\n      <td>1.839600</td>\n    </tr>\n    <tr>\n      <td>34000</td>\n      <td>1.855400</td>\n    </tr>\n    <tr>\n      <td>34500</td>\n      <td>1.846400</td>\n    </tr>\n    <tr>\n      <td>35000</td>\n      <td>1.831000</td>\n    </tr>\n    <tr>\n      <td>35500</td>\n      <td>1.850900</td>\n    </tr>\n    <tr>\n      <td>36000</td>\n      <td>1.851200</td>\n    </tr>\n    <tr>\n      <td>36500</td>\n      <td>1.870200</td>\n    </tr>\n    <tr>\n      <td>37000</td>\n      <td>1.840000</td>\n    </tr>\n    <tr>\n      <td>37500</td>\n      <td>1.842800</td>\n    </tr>\n    <tr>\n      <td>38000</td>\n      <td>1.843800</td>\n    </tr>\n    <tr>\n      <td>38500</td>\n      <td>1.826800</td>\n    </tr>\n    <tr>\n      <td>39000</td>\n      <td>1.803200</td>\n    </tr>\n    <tr>\n      <td>39500</td>\n      <td>1.799700</td>\n    </tr>\n    <tr>\n      <td>40000</td>\n      <td>1.819800</td>\n    </tr>\n    <tr>\n      <td>40500</td>\n      <td>1.803700</td>\n    </tr>\n    <tr>\n      <td>41000</td>\n      <td>1.800300</td>\n    </tr>\n    <tr>\n      <td>41500</td>\n      <td>1.798900</td>\n    </tr>\n    <tr>\n      <td>42000</td>\n      <td>1.796100</td>\n    </tr>\n    <tr>\n      <td>42500</td>\n      <td>1.798500</td>\n    </tr>\n    <tr>\n      <td>43000</td>\n      <td>1.798700</td>\n    </tr>\n    <tr>\n      <td>43500</td>\n      <td>1.770100</td>\n    </tr>\n    <tr>\n      <td>44000</td>\n      <td>1.803700</td>\n    </tr>\n    <tr>\n      <td>44500</td>\n      <td>1.764000</td>\n    </tr>\n    <tr>\n      <td>45000</td>\n      <td>1.768800</td>\n    </tr>\n    <tr>\n      <td>45500</td>\n      <td>1.768100</td>\n    </tr>\n    <tr>\n      <td>46000</td>\n      <td>1.765900</td>\n    </tr>\n    <tr>\n      <td>46500</td>\n      <td>1.784600</td>\n    </tr>\n    <tr>\n      <td>47000</td>\n      <td>1.770600</td>\n    </tr>\n    <tr>\n      <td>47500</td>\n      <td>1.784700</td>\n    </tr>\n    <tr>\n      <td>48000</td>\n      <td>1.758400</td>\n    </tr>\n    <tr>\n      <td>48500</td>\n      <td>1.776600</td>\n    </tr>\n    <tr>\n      <td>49000</td>\n      <td>1.750200</td>\n    </tr>\n    <tr>\n      <td>49500</td>\n      <td>1.738000</td>\n    </tr>\n    <tr>\n      <td>50000</td>\n      <td>1.749600</td>\n    </tr>\n    <tr>\n      <td>50500</td>\n      <td>1.727200</td>\n    </tr>\n    <tr>\n      <td>51000</td>\n      <td>1.753500</td>\n    </tr>\n    <tr>\n      <td>51500</td>\n      <td>1.745000</td>\n    </tr>\n    <tr>\n      <td>52000</td>\n      <td>1.744600</td>\n    </tr>\n    <tr>\n      <td>52500</td>\n      <td>1.733000</td>\n    </tr>\n    <tr>\n      <td>53000</td>\n      <td>1.755800</td>\n    </tr>\n    <tr>\n      <td>53500</td>\n      <td>1.740600</td>\n    </tr>\n    <tr>\n      <td>54000</td>\n      <td>1.765400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to ./BERTimbau-CENTENFolha-8_parts/checkpoint-10000\nConfiguration saved in ./BERTimbau-CENTENFolha-8_parts/checkpoint-10000/config.json\nModel weights saved in ./BERTimbau-CENTENFolha-8_parts/checkpoint-10000/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./BERTimbau-CENTENFolha-8_parts/checkpoint-20000\nConfiguration saved in ./BERTimbau-CENTENFolha-8_parts/checkpoint-20000/config.json\nModel weights saved in ./BERTimbau-CENTENFolha-8_parts/checkpoint-20000/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./BERTimbau-CENTENFolha-8_parts/checkpoint-30000\nConfiguration saved in ./BERTimbau-CENTENFolha-8_parts/checkpoint-30000/config.json\nModel weights saved in ./BERTimbau-CENTENFolha-8_parts/checkpoint-30000/pytorch_model.bin\nDeleting older checkpoint [BERTimbau-CENTENFolha-8_parts/checkpoint-10000] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./BERTimbau-CENTENFolha-8_parts/checkpoint-40000\nConfiguration saved in ./BERTimbau-CENTENFolha-8_parts/checkpoint-40000/config.json\nModel weights saved in ./BERTimbau-CENTENFolha-8_parts/checkpoint-40000/pytorch_model.bin\nDeleting older checkpoint [BERTimbau-CENTENFolha-8_parts/checkpoint-20000] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./BERTimbau-CENTENFolha-8_parts/checkpoint-50000\nConfiguration saved in ./BERTimbau-CENTENFolha-8_parts/checkpoint-50000/config.json\nModel weights saved in ./BERTimbau-CENTENFolha-8_parts/checkpoint-50000/pytorch_model.bin\nDeleting older checkpoint [BERTimbau-CENTENFolha-8_parts/checkpoint-30000] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=54180, training_loss=1.9523954738590188, metrics={'train_runtime': 13377.0031, 'train_samples_per_second': 129.601, 'train_steps_per_second': 4.05, 'total_flos': 2.851915066247808e+16, 'train_loss': 1.9523954738590188, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"code","source":"import math\neval_results = trainer.evaluate()\nprint(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")","metadata":{"id":"p9rpjGVyj68j","outputId":"f850e557-108d-44e0-9e96-a0789cfb4e9b","execution":{"iopub.status.busy":"2022-10-29T04:40:47.864225Z","iopub.execute_input":"2022-10-29T04:40:47.865133Z","iopub.status.idle":"2022-10-29T04:44:21.475358Z","shell.execute_reply.started":"2022-10-29T04:40:47.865094Z","shell.execute_reply":"2022-10-29T04:44:21.474350Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 57683\n  Batch size = 16\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3606' max='3606' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3606/3606 03:33]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Perplexity: 6.33\n","output_type":"stream"}]},{"cell_type":"code","source":"eval_results","metadata":{"id":"Ihaz7TAMAF4l","outputId":"9968d417-56a4-4425-ccf7-7f7e449dc0df","execution":{"iopub.status.busy":"2022-10-29T04:44:21.480508Z","iopub.execute_input":"2022-10-29T04:44:21.480905Z","iopub.status.idle":"2022-10-29T04:44:21.493159Z","shell.execute_reply.started":"2022-10-29T04:44:21.480868Z","shell.execute_reply":"2022-10-29T04:44:21.491277Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 1.8451666831970215,\n 'eval_runtime': 213.596,\n 'eval_samples_per_second': 270.057,\n 'eval_steps_per_second': 16.882,\n 'epoch': 10.0}"},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 14: Saving the Final Model(+tokenizer + config) to disk\ntrainer.save_model(\"./BERTimbau-CENTENFolha-8_parts\")","metadata":{"id":"xusSgo3unkRI","outputId":"7128221d-3161-48d7-eca4-4592009cc584","execution":{"iopub.status.busy":"2022-10-29T04:44:21.494918Z","iopub.execute_input":"2022-10-29T04:44:21.495547Z","iopub.status.idle":"2022-10-29T04:44:22.276245Z","shell.execute_reply.started":"2022-10-29T04:44:21.495508Z","shell.execute_reply":"2022-10-29T04:44:22.275236Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Saving model checkpoint to ./BERTimbau-CENTENFolha-8_parts\nConfiguration saved in ./BERTimbau-CENTENFolha-8_parts/config.json\nModel weights saved in ./BERTimbau-CENTENFolha-8_parts/pytorch_model.bin\n","output_type":"stream"}]},{"cell_type":"code","source":"# Saving model on Wandb\nimport wandb\nwandb.save('BERTimbau-CENTENFolha-8_parts.h5')","metadata":{"execution":{"iopub.status.busy":"2022-10-29T04:44:22.278253Z","iopub.execute_input":"2022-10-29T04:44:22.278638Z","iopub.status.idle":"2022-10-29T04:44:22.287069Z","shell.execute_reply.started":"2022-10-29T04:44:22.278600Z","shell.execute_reply":"2022-10-29T04:44:22.285845Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 3: Configurando o pipeline fill-mask\n#@title Step 15: Language Modeling with the FillMaskPipeline\nfrom transformers import pipeline\n\nfill_mask = pipeline(\n    \"fill-mask\",\n    model=\"./BERTimbau-CENTENFolha-8_parts\",\n    tokenizer=tokenizer\n)","metadata":{"id":"pqy7oTgYFb9Y","outputId":"82629ccc-36b7-439e-df94-7af7fdd47516","execution":{"iopub.status.busy":"2022-10-29T04:44:22.288844Z","iopub.execute_input":"2022-10-29T04:44:22.289382Z","iopub.status.idle":"2022-10-29T04:44:24.034894Z","shell.execute_reply.started":"2022-10-29T04:44:22.289324Z","shell.execute_reply":"2022-10-29T04:44:24.033989Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"loading configuration file ./BERTimbau-CENTENFolha-8_parts/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"./BERTimbau-CENTENFolha-8_parts\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"directionality\": \"bidi\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_past\": true,\n  \"pad_token_id\": 0,\n  \"pooler_fc_size\": 768,\n  \"pooler_num_attention_heads\": 12,\n  \"pooler_num_fc_layers\": 3,\n  \"pooler_size_per_head\": 128,\n  \"pooler_type\": \"first_token_transform\",\n  \"position_embedding_type\": \"absolute\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 29794\n}\n\nloading configuration file ./BERTimbau-CENTENFolha-8_parts/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"./BERTimbau-CENTENFolha-8_parts\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"directionality\": \"bidi\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_past\": true,\n  \"pad_token_id\": 0,\n  \"pooler_fc_size\": 768,\n  \"pooler_num_attention_heads\": 12,\n  \"pooler_num_fc_layers\": 3,\n  \"pooler_size_per_head\": 128,\n  \"pooler_type\": \"first_token_transform\",\n  \"position_embedding_type\": \"absolute\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 29794\n}\n\nloading weights file ./BERTimbau-CENTENFolha-8_parts/pytorch_model.bin\nAll model checkpoint weights were used when initializing BertForMaskedLM.\n\nAll the weights of BertForMaskedLM were initialized from the model checkpoint at ./BERTimbau-CENTENFolha-8_parts.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"fill_mask(\"O rapaz olhou para o [MASK] \")","metadata":{"id":"RRrtRPA6GRF8","outputId":"940a13ea-77ee-42eb-df7e-7d3199234cde","execution":{"iopub.status.busy":"2022-10-29T04:44:24.036497Z","iopub.execute_input":"2022-10-29T04:44:24.037158Z","iopub.status.idle":"2022-10-29T04:44:24.338188Z","shell.execute_reply.started":"2022-10-29T04:44:24.037113Z","shell.execute_reply":"2022-10-29T04:44:24.337288Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.16590942442417145,\n  'token': 2979,\n  'token_str': 'alto',\n  'sequence': 'O rapaz olhou para o alto'},\n {'score': 0.15819883346557617,\n  'token': 8242,\n  'token_str': 'céu',\n  'sequence': 'O rapaz olhou para o céu'},\n {'score': 0.07594423741102219,\n  'token': 17664,\n  'token_str': 'espelho',\n  'sequence': 'O rapaz olhou para o espelho'},\n {'score': 0.05604296550154686,\n  'token': 119,\n  'token_str': '.',\n  'sequence': 'O rapaz olhou para o.'},\n {'score': 0.05529683828353882,\n  'token': 1341,\n  'token_str': 'lado',\n  'sequence': 'O rapaz olhou para o lado'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"A moça olhou para o [MASK] \")","metadata":{"id":"56WEAY40asDv","outputId":"b70c5b72-8475-41b6-8bb7-37d7ed675fb4","execution":{"iopub.status.busy":"2022-10-29T04:44:24.339750Z","iopub.execute_input":"2022-10-29T04:44:24.340100Z","iopub.status.idle":"2022-10-29T04:44:24.499944Z","shell.execute_reply.started":"2022-10-29T04:44:24.340064Z","shell.execute_reply":"2022-10-29T04:44:24.499000Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.1990056186914444,\n  'token': 8242,\n  'token_str': 'céu',\n  'sequence': 'A moça olhou para o céu'},\n {'score': 0.12300949543714523,\n  'token': 2979,\n  'token_str': 'alto',\n  'sequence': 'A moça olhou para o alto'},\n {'score': 0.09690188616514206,\n  'token': 17664,\n  'token_str': 'espelho',\n  'sequence': 'A moça olhou para o espelho'},\n {'score': 0.07133549451828003,\n  'token': 1341,\n  'token_str': 'lado',\n  'sequence': 'A moça olhou para o lado'},\n {'score': 0.05967789515852928,\n  'token': 528,\n  'token_str': 'mar',\n  'sequence': 'A moça olhou para o mar'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Comprou uma [MASK] na loja. \")","metadata":{"id":"HiDV-v5rTyJt","outputId":"f082e061-276c-4984-b96f-26021fb3d323","execution":{"iopub.status.busy":"2022-10-29T04:44:24.501445Z","iopub.execute_input":"2022-10-29T04:44:24.501785Z","iopub.status.idle":"2022-10-29T04:44:24.655939Z","shell.execute_reply.started":"2022-10-29T04:44:24.501751Z","shell.execute_reply":"2022-10-29T04:44:24.655002Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.1183428093791008,\n  'token': 18099,\n  'token_str': 'cerveja',\n  'sequence': 'Comprou uma cerveja na loja.'},\n {'score': 0.05258983373641968,\n  'token': 6997,\n  'token_str': 'máquina',\n  'sequence': 'Comprou uma máquina na loja.'},\n {'score': 0.043195273727178574,\n  'token': 576,\n  'token_str': 'vez',\n  'sequence': 'Comprou uma vez na loja.'},\n {'score': 0.029871679842472076,\n  'token': 7924,\n  'token_str': 'camisa',\n  'sequence': 'Comprou uma camisa na loja.'},\n {'score': 0.025105634704232216,\n  'token': 4320,\n  'token_str': 'peça',\n  'sequence': 'Comprou uma peça na loja.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"A mulher não é [MASK]. \")","metadata":{"id":"gVnhg1bxT-wK","outputId":"b3d1da07-a8f4-497e-8b6b-a5629c69831b","execution":{"iopub.status.busy":"2022-10-29T04:44:24.657504Z","iopub.execute_input":"2022-10-29T04:44:24.657862Z","iopub.status.idle":"2022-10-29T04:44:24.799901Z","shell.execute_reply.started":"2022-10-29T04:44:24.657826Z","shell.execute_reply":"2022-10-29T04:44:24.798989Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.05108920857310295,\n  'token': 12222,\n  'token_str': 'casada',\n  'sequence': 'A mulher não é casada.'},\n {'score': 0.02863135002553463,\n  'token': 13420,\n  'token_str': 'perfeita',\n  'sequence': 'A mulher não é perfeita.'},\n {'score': 0.026146886870265007,\n  'token': 1016,\n  'token_str': 'assim',\n  'sequence': 'A mulher não é assim.'},\n {'score': 0.02392844669520855,\n  'token': 1848,\n  'token_str': 'importante',\n  'sequence': 'A mulher não é importante.'},\n {'score': 0.021442610770463943,\n  'token': 2606,\n  'token_str': 'mulher',\n  'sequence': 'A mulher não é mulher.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"O homem não é [MASK]. \")","metadata":{"id":"l486NETHUFw6","outputId":"06df0abd-b2e7-4a24-885d-0739ed80d6bb","execution":{"iopub.status.busy":"2022-10-29T04:44:24.801435Z","iopub.execute_input":"2022-10-29T04:44:24.801778Z","iopub.status.idle":"2022-10-29T04:44:24.955622Z","shell.execute_reply.started":"2022-10-29T04:44:24.801744Z","shell.execute_reply":"2022-10-29T04:44:24.954717Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.13655108213424683,\n  'token': 13380,\n  'token_str': 'perfeito',\n  'sequence': 'O homem não é perfeito.'},\n {'score': 0.035791195929050446,\n  'token': 4209,\n  'token_str': 'igual',\n  'sequence': 'O homem não é igual.'},\n {'score': 0.027270695194602013,\n  'token': 3874,\n  'token_str': 'nada',\n  'sequence': 'O homem não é nada.'},\n {'score': 0.023961257189512253,\n  'token': 1016,\n  'token_str': 'assim',\n  'sequence': 'O homem não é assim.'},\n {'score': 0.02120654098689556,\n  'token': 4481,\n  'token_str': 'humano',\n  'sequence': 'O homem não é humano.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Ele é um bom [MASK]. \")","metadata":{"id":"XBxjvRGYVAxC","outputId":"bb309e59-bfe6-42b1-aa4b-0a689b84a97a","execution":{"iopub.status.busy":"2022-10-29T04:44:24.957008Z","iopub.execute_input":"2022-10-29T04:44:24.957804Z","iopub.status.idle":"2022-10-29T04:44:25.107218Z","shell.execute_reply.started":"2022-10-29T04:44:24.957767Z","shell.execute_reply":"2022-10-29T04:44:25.106290Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.12060219049453735,\n  'token': 2357,\n  'token_str': 'jogador',\n  'sequence': 'Ele é um bom jogador.'},\n {'score': 0.11693714559078217,\n  'token': 1416,\n  'token_str': 'exemplo',\n  'sequence': 'Ele é um bom exemplo.'},\n {'score': 0.04785142466425896,\n  'token': 4022,\n  'token_str': 'técnico',\n  'sequence': 'Ele é um bom técnico.'},\n {'score': 0.04118023067712784,\n  'token': 3620,\n  'token_str': 'ator',\n  'sequence': 'Ele é um bom ator.'},\n {'score': 0.025413991883397102,\n  'token': 6325,\n  'token_str': 'empresário',\n  'sequence': 'Ele é um bom empresário.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Ela é uma boa [MASK]. \")","metadata":{"id":"PBQ5HugqVPF4","outputId":"2db97d91-c29b-49e2-f2c7-2dd93400d051","execution":{"iopub.status.busy":"2022-10-29T04:44:25.108607Z","iopub.execute_input":"2022-10-29T04:44:25.109276Z","iopub.status.idle":"2022-10-29T04:44:25.254646Z","shell.execute_reply.started":"2022-10-29T04:44:25.109236Z","shell.execute_reply":"2022-10-29T04:44:25.253550Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.162946879863739,\n  'token': 3557,\n  'token_str': 'atriz',\n  'sequence': 'Ela é uma boa atriz.'},\n {'score': 0.13586226105690002,\n  'token': 2760,\n  'token_str': 'pessoa',\n  'sequence': 'Ela é uma boa pessoa.'},\n {'score': 0.056161317974328995,\n  'token': 8932,\n  'token_str': 'amiga',\n  'sequence': 'Ela é uma boa amiga.'},\n {'score': 0.034564364701509476,\n  'token': 8208,\n  'token_str': 'opção',\n  'sequence': 'Ela é uma boa opção.'},\n {'score': 0.026774127036333084,\n  'token': 2196,\n  'token_str': 'mãe',\n  'sequence': 'Ela é uma boa mãe.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Faz de conta que ainda é [MASK]. \")","metadata":{"id":"qUBfuZBNa4_2","outputId":"dfae7051-1ffb-4787-f1d3-8fc4e28ff1a1","execution":{"iopub.status.busy":"2022-10-29T04:44:25.256155Z","iopub.execute_input":"2022-10-29T04:44:25.256529Z","iopub.status.idle":"2022-10-29T04:44:25.422228Z","shell.execute_reply.started":"2022-10-29T04:44:25.256493Z","shell.execute_reply":"2022-10-29T04:44:25.421200Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.18625508248806,\n  'token': 8545,\n  'token_str': 'cedo',\n  'sequence': 'Faz de conta que ainda é cedo.'},\n {'score': 0.14176622033119202,\n  'token': 1695,\n  'token_str': 'pouco',\n  'sequence': 'Faz de conta que ainda é pouco.'},\n {'score': 0.08024295419454575,\n  'token': 4931,\n  'token_str': 'candidato',\n  'sequence': 'Faz de conta que ainda é candidato.'},\n {'score': 0.06291192024946213,\n  'token': 1373,\n  'token_str': 'tarde',\n  'sequence': 'Faz de conta que ainda é tarde.'},\n {'score': 0.061192095279693604,\n  'token': 2656,\n  'token_str': 'jovem',\n  'sequence': 'Faz de conta que ainda é jovem.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Depois da tempestade vem a [MASK]. \")","metadata":{"id":"u4E4MHWmbBsH","outputId":"49947f61-6226-494b-9424-e953c96363b8","execution":{"iopub.status.busy":"2022-10-29T04:44:25.423728Z","iopub.execute_input":"2022-10-29T04:44:25.424098Z","iopub.status.idle":"2022-10-29T04:44:25.575945Z","shell.execute_reply.started":"2022-10-29T04:44:25.424061Z","shell.execute_reply":"2022-10-29T04:44:25.574921Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.20495471358299255,\n  'token': 12299,\n  'token_str': 'neve',\n  'sequence': 'Depois da tempestade vem a neve.'},\n {'score': 0.2026919424533844,\n  'token': 8742,\n  'token_str': 'seca',\n  'sequence': 'Depois da tempestade vem a seca.'},\n {'score': 0.05817798152565956,\n  'token': 11062,\n  'token_str': 'fome',\n  'sequence': 'Depois da tempestade vem a fome.'},\n {'score': 0.0526474192738533,\n  'token': 9856,\n  'token_str': 'chuva',\n  'sequence': 'Depois da tempestade vem a chuva.'},\n {'score': 0.04578608274459839,\n  'token': 13943,\n  'token_str': 'lua',\n  'sequence': 'Depois da tempestade vem a lua.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Mais vale um pássaro na mão do que [MASK] voando. \")","metadata":{"id":"8bd3GbaabIn7","outputId":"3d305d34-61bf-446b-b917-2be8cc19abc4","execution":{"iopub.status.busy":"2022-10-29T04:44:25.577440Z","iopub.execute_input":"2022-10-29T04:44:25.577780Z","iopub.status.idle":"2022-10-29T04:44:25.779809Z","shell.execute_reply.started":"2022-10-29T04:44:25.577744Z","shell.execute_reply":"2022-10-29T04:44:25.778859Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.3619248867034912,\n  'token': 222,\n  'token_str': 'um',\n  'sequence': 'Mais vale um pássaro na mão do que um voando.'},\n {'score': 0.14355412125587463,\n  'token': 6384,\n  'token_str': 'alguém',\n  'sequence': 'Mais vale um pássaro na mão do que alguém voando.'},\n {'score': 0.059984248131513596,\n  'token': 1342,\n  'token_str': 'outro',\n  'sequence': 'Mais vale um pássaro na mão do que outro voando.'},\n {'score': 0.025123020634055138,\n  'token': 14934,\n  'token_str': 'voar',\n  'sequence': 'Mais vale um pássaro na mão do que voar voando.'},\n {'score': 0.020025081932544708,\n  'token': 2765,\n  'token_str': 'estar',\n  'sequence': 'Mais vale um pássaro na mão do que estar voando.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Não tinha [MASK], mas almoçou mesmo assim. \")","metadata":{"id":"bhep3pt3bUkJ","outputId":"fd3b55ec-3923-4308-f851-707faafda30e","execution":{"iopub.status.busy":"2022-10-29T04:44:25.781389Z","iopub.execute_input":"2022-10-29T04:44:25.781755Z","iopub.status.idle":"2022-10-29T04:44:25.962120Z","shell.execute_reply.started":"2022-10-29T04:44:25.781718Z","shell.execute_reply":"2022-10-29T04:44:25.961226Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.05779163911938667,\n  'token': 596,\n  'token_str': 'tempo',\n  'sequence': 'Não tinha tempo, mas almoçou mesmo assim.'},\n {'score': 0.03968477621674538,\n  'token': 3382,\n  'token_str': 'visto',\n  'sequence': 'Não tinha visto, mas almoçou mesmo assim.'},\n {'score': 0.03311473876237869,\n  'token': 13746,\n  'token_str': 'namorado',\n  'sequence': 'Não tinha namorado, mas almoçou mesmo assim.'},\n {'score': 0.032572563737630844,\n  'token': 11062,\n  'token_str': 'fome',\n  'sequence': 'Não tinha fome, mas almoçou mesmo assim.'},\n {'score': 0.03244439885020256,\n  'token': 3495,\n  'token_str': 'dinheiro',\n  'sequence': 'Não tinha dinheiro, mas almoçou mesmo assim.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Bebeu um copo d'água, pois tinha [MASK]. \")","metadata":{"id":"Vpn7cJREbj_Y","outputId":"c5a60b8a-9923-4ed3-da44-e478d2bd0954","execution":{"iopub.status.busy":"2022-10-29T04:44:25.963797Z","iopub.execute_input":"2022-10-29T04:44:25.964313Z","iopub.status.idle":"2022-10-29T04:44:26.269579Z","shell.execute_reply.started":"2022-10-29T04:44:25.964259Z","shell.execute_reply":"2022-10-29T04:44:26.268561Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.21553871035575867,\n  'token': 11062,\n  'token_str': 'fome',\n  'sequence': \"Bebeu um copo d'água, pois tinha fome.\"},\n {'score': 0.17282640933990479,\n  'token': 7672,\n  'token_str': 'medo',\n  'sequence': \"Bebeu um copo d'água, pois tinha medo.\"},\n {'score': 0.09888448566198349,\n  'token': 14594,\n  'token_str': 'febre',\n  'sequence': \"Bebeu um copo d'água, pois tinha febre.\"},\n {'score': 0.0951802134513855,\n  'token': 4145,\n  'token_str': 'razão',\n  'sequence': \"Bebeu um copo d'água, pois tinha razão.\"},\n {'score': 0.07313451170921326,\n  'token': 11334,\n  'token_str': 'sono',\n  'sequence': \"Bebeu um copo d'água, pois tinha sono.\"}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Sem saber, ele descobriu um [MASK]. \")","metadata":{"id":"9KrDcsT2bzkl","outputId":"fde63380-d420-4e04-9b05-f330eec3ee76","execution":{"iopub.status.busy":"2022-10-29T04:44:26.274060Z","iopub.execute_input":"2022-10-29T04:44:26.276332Z","iopub.status.idle":"2022-10-29T04:44:26.486866Z","shell.execute_reply.started":"2022-10-29T04:44:26.276290Z","shell.execute_reply":"2022-10-29T04:44:26.485930Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.1456645429134369,\n  'token': 11021,\n  'token_str': 'segredo',\n  'sequence': 'Sem saber, ele descobriu um segredo.'},\n {'score': 0.07130926102399826,\n  'token': 16269,\n  'token_str': 'mistério',\n  'sequence': 'Sem saber, ele descobriu um mistério.'},\n {'score': 0.05286533758044243,\n  'token': 7441,\n  'token_str': 'erro',\n  'sequence': 'Sem saber, ele descobriu um erro.'},\n {'score': 0.03616425022482872,\n  'token': 3420,\n  'token_str': 'caminho',\n  'sequence': 'Sem saber, ele descobriu um caminho.'},\n {'score': 0.024344172328710556,\n  'token': 3204,\n  'token_str': 'plano',\n  'sequence': 'Sem saber, ele descobriu um plano.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Pedro fez fortuna vendendo [MASK]. \")","metadata":{"id":"FzIuM2mFb6tc","outputId":"d117842d-8035-4682-e27c-6174ee2a62e8","execution":{"iopub.status.busy":"2022-10-29T04:44:26.491048Z","iopub.execute_input":"2022-10-29T04:44:26.493163Z","iopub.status.idle":"2022-10-29T04:44:26.682652Z","shell.execute_reply.started":"2022-10-29T04:44:26.493126Z","shell.execute_reply":"2022-10-29T04:44:26.681615Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.1373293548822403,\n  'token': 9701,\n  'token_str': 'cavalos',\n  'sequence': 'Pedro fez fortuna vendendo cavalos.'},\n {'score': 0.07332227379083633,\n  'token': 7309,\n  'token_str': 'drogas',\n  'sequence': 'Pedro fez fortuna vendendo drogas.'},\n {'score': 0.07214704900979996,\n  'token': 2978,\n  'token_str': 'livros',\n  'sequence': 'Pedro fez fortuna vendendo livros.'},\n {'score': 0.04423225298523903,\n  'token': 6346,\n  'token_str': 'discos',\n  'sequence': 'Pedro fez fortuna vendendo discos.'},\n {'score': 0.03852641209959984,\n  'token': 6401,\n  'token_str': 'carros',\n  'sequence': 'Pedro fez fortuna vendendo carros.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Sem medo de ser [MASK]. \")","metadata":{"id":"4t6LS5glcZFN","outputId":"ad7fb0c9-1c4c-4884-9a37-e68bce58e77f","execution":{"iopub.status.busy":"2022-10-29T04:44:26.683926Z","iopub.execute_input":"2022-10-29T04:44:26.684567Z","iopub.status.idle":"2022-10-29T04:44:26.835888Z","shell.execute_reply.started":"2022-10-29T04:44:26.684527Z","shell.execute_reply":"2022-10-29T04:44:26.834258Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.0936732366681099,\n  'token': 8540,\n  'token_str': 'feliz',\n  'sequence': 'Sem medo de ser feliz.'},\n {'score': 0.053517743945121765,\n  'token': 5139,\n  'token_str': 'preso',\n  'sequence': 'Sem medo de ser preso.'},\n {'score': 0.04083995893597603,\n  'token': 4807,\n  'token_str': 'morto',\n  'sequence': 'Sem medo de ser morto.'},\n {'score': 0.03177829459309578,\n  'token': 13205,\n  'token_str': 'demitido',\n  'sequence': 'Sem medo de ser demitido.'},\n {'score': 0.02574366144835949,\n  'token': 13571,\n  'token_str': 'criticado',\n  'sequence': 'Sem medo de ser criticado.'}]"},"metadata":{}}]}]}