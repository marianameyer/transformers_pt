{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/jsansao/transformers_pt/blob/main/BERTimbau_Fine_tuning_CETENFolha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"# Inferência usando transformers pré-treinados do HuggingFace ","metadata":{"id":"hV_s2jhFIGRV"}},{"cell_type":"markdown","source":"BERTimbau\n\nCENTENFolha - 8 partes\n\nBatch size = 16\n\nGPU T4x2","metadata":{}},{"cell_type":"code","source":"#@title Passo 1:Instalando Hugging Face Transformers\n# We won't need TensorFlow here\n!pip uninstall -y tensorflow\n# Install `transformers` from master\n!pip install transformers datasets\n!pip list | grep -E 'transformers|tokenizers'\n# transformers version at notebook update --- 2.9.1\n# tokenizers version at notebook update --- 0.7.0","metadata":{"id":"LhI1tJBGBd3r","outputId":"6992ec79-0f86-4f41-ec7a-6d3b9e7f1848","execution":{"iopub.status.busy":"2022-10-30T15:31:50.051419Z","iopub.execute_input":"2022-10-30T15:31:50.051800Z","iopub.status.idle":"2022-10-30T15:32:42.503986Z","shell.execute_reply.started":"2022-10-30T15:31:50.051767Z","shell.execute_reply":"2022-10-30T15:32:42.502787Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found existing installation: tensorflow 2.6.4\nUninstalling tensorflow-2.6.4:\n  Successfully uninstalled tensorflow-2.6.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.13)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.5.1)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.8.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mtokenizers                            0.12.1\ntransformers                          4.20.1\n","output_type":"stream"}]},{"cell_type":"code","source":"#@title Step 1: Loading the Dataset\n#1.Load kant.txt using the Colab file manager\n#2.Downloading the file from GitHub\n#!curl -L  https://raw.githubusercontent.com/jsansao/corpus_ptbr/main/dump_Machado_Nobreak.txt --output \"dump.txt\"\n!curl -L https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_aa --output \"dump.txt\"\n#!curl -L https://raw.githubusercontent.com/jsansao/corpus_ptbr/main/Lyrics_ChicoBuarque.txt --output \"kant.txt\"\n\n!awk NF < dump.txt > kant.txt","metadata":{"id":"KAl5BxxOgk35","outputId":"bab59eaa-60cf-462b-d681-2c89b64978e8","execution":{"iopub.status.busy":"2022-10-30T15:32:42.509752Z","iopub.execute_input":"2022-10-30T15:32:42.512041Z","iopub.status.idle":"2022-10-30T15:32:45.473366Z","shell.execute_reply.started":"2022-10-30T15:32:42.512001Z","shell.execute_reply":"2022-10-30T15:32:45.471977Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 3724k  100 3724k    0     0  10.0M      0 --:--:-- --:--:-- --:--:-- 10.0M\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_aa \n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ab\n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ac\n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ad\n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ae \n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_af\n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ag\n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ah","metadata":{"id":"aDPWlxTHRC7-","outputId":"86726bae-8fe1-4f30-8509-a4da74a4ed0a","execution":{"iopub.status.busy":"2022-10-30T15:32:45.475039Z","iopub.execute_input":"2022-10-30T15:32:45.475504Z","iopub.status.idle":"2022-10-30T15:32:55.807395Z","shell.execute_reply.started":"2022-10-30T15:32:45.475462Z","shell.execute_reply":"2022-10-30T15:32:55.806147Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"--2022-10-30 15:32:46--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_aa\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: ‘cetenfolha_aa’\n\ncetenfolha_aa       100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-30 15:32:46 (49.4 MB/s) - ‘cetenfolha_aa’ saved [3813899/3813899]\n\n--2022-10-30 15:32:47--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ab\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: ‘cetenfolha_ab’\n\ncetenfolha_ab       100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-30 15:32:47 (50.0 MB/s) - ‘cetenfolha_ab’ saved [3813899/3813899]\n\n--2022-10-30 15:32:48--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ac\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: ‘cetenfolha_ac’\n\ncetenfolha_ac       100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-30 15:32:49 (50.9 MB/s) - ‘cetenfolha_ac’ saved [3813899/3813899]\n\n--2022-10-30 15:32:50--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ad\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: ‘cetenfolha_ad’\n\ncetenfolha_ad       100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-30 15:32:50 (51.5 MB/s) - ‘cetenfolha_ad’ saved [3813899/3813899]\n\n--2022-10-30 15:32:51--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ae\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: ‘cetenfolha_ae’\n\ncetenfolha_ae       100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-30 15:32:51 (49.9 MB/s) - ‘cetenfolha_ae’ saved [3813899/3813899]\n\n--2022-10-30 15:32:52--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_af\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: ‘cetenfolha_af’\n\ncetenfolha_af       100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-30 15:32:52 (50.1 MB/s) - ‘cetenfolha_af’ saved [3813899/3813899]\n\n--2022-10-30 15:32:54--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ag\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: ‘cetenfolha_ag’\n\ncetenfolha_ag       100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-30 15:32:54 (51.6 MB/s) - ‘cetenfolha_ag’ saved [3813899/3813899]\n\n--2022-10-30 15:32:55--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ah\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: ‘cetenfolha_ah’\n\ncetenfolha_ah       100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-30 15:32:55 (49.7 MB/s) - ‘cetenfolha_ah’ saved [3813899/3813899]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!cat cetenfolha_aa cetenfolha_ab cetenfolha_ac cetenfolha_ad cetenfolha_ae cetenfolha_af cetenfolha_ag cetenfolha_ah>  dump.txt\n!awk NF < dump.txt > kant.txt","metadata":{"id":"kFetqxZ3RToJ","execution":{"iopub.status.busy":"2022-10-30T15:32:55.809864Z","iopub.execute_input":"2022-10-30T15:32:55.810314Z","iopub.status.idle":"2022-10-30T15:32:58.098060Z","shell.execute_reply.started":"2022-10-30T15:32:55.810273Z","shell.execute_reply":"2022-10-30T15:32:58.096578Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#@title Passo 2:Baixando e salvando BR_BERTo\n#https://huggingface.co/rdenadai/BR_BERTo\n\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM\n\n#tokenizer = AutoTokenizer.from_pretrained(\"rdenadai/BR_BERTo\")\n#model = AutoModelForMaskedLM.from_pretrained(\"rdenadai/BR_BERTo\")\n\ntokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\nmodel = AutoModelForMaskedLM.from_pretrained('neuralmind/bert-base-portuguese-cased')","metadata":{"id":"h2L_Put8Cn8S","outputId":"0e90b320-f004-490b-a683-2ef33b3dc60a","execution":{"iopub.status.busy":"2022-10-30T15:32:58.102415Z","iopub.execute_input":"2022-10-30T15:32:58.102784Z","iopub.status.idle":"2022-10-30T15:33:28.256823Z","shell.execute_reply.started":"2022-10-30T15:32:58.102754Z","shell.execute_reply":"2022-10-30T15:33:28.255747Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/43.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12a31e12a56e4435bca88849fb008450"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/647 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9e831d17cf54c679e79525121fd0282"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/205k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c69ae6c14494455e9e778a85c4dab4de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbc1599341154fbb8ab987688341ecf5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c68479ce22d84e5994bd3ad499cbb05d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/418M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df59497c79404611988307c0b4edd392"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n#datasets = load_dataset(\"text\", data_files={\"train\": \"kant.txt\", \"validation\": \"kant_teste.txt\"})\n#datasets = load_dataset(\"text\", data_files={\"train\": \"kant.txt\"}, split='train[:90%]')\nds = load_dataset(\"text\", data_files={\"train\": \"kant.txt\"})\n\ndatasets = ds[\"train\"].train_test_split()","metadata":{"id":"J1oYngljZeZT","outputId":"98366916-3dd6-4469-e69e-83a2eeadcdfe","execution":{"iopub.status.busy":"2022-10-30T15:33:28.258753Z","iopub.execute_input":"2022-10-30T15:33:28.259298Z","iopub.status.idle":"2022-10-30T15:33:29.784257Z","shell.execute_reply.started":"2022-10-30T15:33:28.259249Z","shell.execute_reply":"2022-10-30T15:33:29.783259Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-ffd5e8c10adfedb2/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8ee2d27e52b42c29851ced7d30a0eb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d1e3e7674a0444bad577f4ee08474bb"}},"metadata":{}},{"name":"stdout","text":"Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-ffd5e8c10adfedb2/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30739cc3a3c443dbaad8e1a3fac858d9"}},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(examples[\"text\"])","metadata":{"id":"7JiCdblobSdn","execution":{"iopub.status.busy":"2022-10-30T15:33:29.785668Z","iopub.execute_input":"2022-10-30T15:33:29.786385Z","iopub.status.idle":"2022-10-30T15:33:29.791568Z","shell.execute_reply.started":"2022-10-30T15:33:29.786348Z","shell.execute_reply":"2022-10-30T15:33:29.790549Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])","metadata":{"id":"QT8eOoqmbYV2","outputId":"f0c2ed49-ddce-409f-b78e-c8cb83d47841","execution":{"iopub.status.busy":"2022-10-30T15:33:29.792982Z","iopub.execute_input":"2022-10-30T15:33:29.794870Z","iopub.status.idle":"2022-10-30T15:33:58.362598Z","shell.execute_reply.started":"2022-10-30T15:33:29.794832Z","shell.execute_reply":"2022-10-30T15:33:58.361344Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"     ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9da17c1e769247ecad13d29a589b4b1a"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7bd35c9ef8a4ef99600aac66c21d573"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30bbc0f032134908a5ec2238698e5588"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1256553ceb854ea8b3d1d0d3553d6bda"}},"metadata":{}},{"name":"stdout","text":"       ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3cbea12f4794848aa1fbad543305c56"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"116a386aea0647cfa71be08899e4dfa7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a024be9daa149c680a77a7030ced8b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fb6b7b7b4484c60a53ba14e71b476c7"}},"metadata":{}}]},{"cell_type":"markdown","source":"exemplo de entrada","metadata":{"id":"ETLIt8siKjWC"}},{"cell_type":"code","source":"tokenized_datasets[\"train\"][4]","metadata":{"id":"7_umRvrQKT6g","outputId":"31557af2-70c4-4a38-a3ec-fb6a54c8fb17","execution":{"iopub.status.busy":"2022-10-30T15:33:58.365448Z","iopub.execute_input":"2022-10-30T15:33:58.366262Z","iopub.status.idle":"2022-10-30T15:33:58.377570Z","shell.execute_reply.started":"2022-10-30T15:33:58.366221Z","shell.execute_reply":"2022-10-30T15:33:58.376597Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101,\n  530,\n  7119,\n  117,\n  2230,\n  14007,\n  3554,\n  11076,\n  151,\n  347,\n  655,\n  125,\n  2230,\n  14007,\n  6356,\n  5257,\n  22286,\n  119,\n  102],\n 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"#block_size = tokenizer.model_max_length\nblock_size = 32","metadata":{"id":"2cVk21VpKt0o","execution":{"iopub.status.busy":"2022-10-30T15:33:58.378844Z","iopub.execute_input":"2022-10-30T15:33:58.379241Z","iopub.status.idle":"2022-10-30T15:33:58.408515Z","shell.execute_reply.started":"2022-10-30T15:33:58.379181Z","shell.execute_reply":"2022-10-30T15:33:58.407506Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def group_texts(examples):\n    # Concatenate all texts.\n    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n    total_length = len(concatenated_examples[list(examples.keys())[0]])\n    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n        # customize this part to your needs.\n    total_length = (total_length // block_size) * block_size\n    # Split by chunks of max_len.\n    result = {\n        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n        for k, t in concatenated_examples.items()\n    }\n    result[\"labels\"] = result[\"input_ids\"].copy()\n    return result","metadata":{"id":"zif6EA4VcCk0","execution":{"iopub.status.busy":"2022-10-30T15:33:58.410069Z","iopub.execute_input":"2022-10-30T15:33:58.410589Z","iopub.status.idle":"2022-10-30T15:33:58.419338Z","shell.execute_reply.started":"2022-10-30T15:33:58.410553Z","shell.execute_reply":"2022-10-30T15:33:58.418261Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"lm_datasets = tokenized_datasets.map(\n    group_texts,\n    batched=True,\n    batch_size=1000,\n    num_proc=4,\n)","metadata":{"id":"4Xb0RzHtb2RJ","outputId":"1de1f00a-c9ab-4eee-bec0-79ee12ed0a35","execution":{"iopub.status.busy":"2022-10-30T15:33:58.420796Z","iopub.execute_input":"2022-10-30T15:33:58.421416Z","iopub.status.idle":"2022-10-30T15:34:55.249317Z","shell.execute_reply.started":"2022-10-30T15:33:58.421379Z","shell.execute_reply":"2022-10-30T15:34:55.248118Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"      ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73fa9bab812548abae3c893c7e824f3f"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b29a6e33863e4231a4759e2d6b658108"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25c579313f7c4472b46124f82442b2ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bfe21a0182c4265b15e134e97462118"}},"metadata":{}},{"name":"stdout","text":"      ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17afcecdeb0741d899d261e9d3de8442"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5525fd8dbdda4a60896e3ceebb31984f"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eae20ec63da74bea9d0365a16aa524c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"609b66ef2dad47189dd620b7ee7f62dd"}},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 11: Defining a Data Collator\nfrom transformers import DataCollatorForLanguageModeling\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n)","metadata":{"id":"19hRhnHFf7FF","execution":{"iopub.status.busy":"2022-10-30T15:34:55.251058Z","iopub.execute_input":"2022-10-30T15:34:55.252105Z","iopub.status.idle":"2022-10-30T15:34:55.911801Z","shell.execute_reply.started":"2022-10-30T15:34:55.252068Z","shell.execute_reply":"2022-10-30T15:34:55.910755Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric\n\nmetric = load_metric(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return {metric.compute(predictions=predictions, references=labels)}","metadata":{"id":"_cDyvFrNfa31","execution":{"iopub.status.busy":"2022-10-30T15:34:55.920261Z","iopub.execute_input":"2022-10-30T15:34:55.920554Z","iopub.status.idle":"2022-10-30T15:34:56.430561Z","shell.execute_reply.started":"2022-10-30T15:34:55.920527Z","shell.execute_reply":"2022-10-30T15:34:56.429593Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.41k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d84b5ce4f05d42c484eaf1124319151e"}},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 12: Initializing the Trainer\nfrom transformers import Trainer, TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./BERTimbau-CENTENFolha-8_parts\",\n    overwrite_output_dir=True,\n    num_train_epochs=10,\n    per_device_train_batch_size=16,\n    save_steps=10_000,\n    save_total_limit=2,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=lm_datasets[\"train\"],\n    eval_dataset=lm_datasets[\"test\"],    \n)","metadata":{"id":"MH2dsTzhfgqI","outputId":"98b660e8-7b09-4143-8a8d-7b6552074ede","execution":{"iopub.status.busy":"2022-10-30T15:34:56.432160Z","iopub.execute_input":"2022-10-30T15:34:56.432600Z","iopub.status.idle":"2022-10-30T15:35:01.830290Z","shell.execute_reply.started":"2022-10-30T15:34:56.432561Z","shell.execute_reply":"2022-10-30T15:35:01.829166Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#@title Step 13: Pre-training the Model\ntrainer.train()","metadata":{"id":"EZxksqadfv6l","outputId":"5b6c546a-c2e2-45a1-d033-bccc36f774ea","execution":{"iopub.status.busy":"2022-10-30T15:35:01.831842Z","iopub.execute_input":"2022-10-30T15:35:01.834431Z","iopub.status.idle":"2022-10-30T19:07:19.939937Z","shell.execute_reply.started":"2022-10-30T15:35:01.834391Z","shell.execute_reply":"2022-10-30T19:07:19.939027Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 173177\n  Num Epochs = 10\n  Instantaneous batch size per device = 16\n  Total train batch size (w. parallel, distributed & accumulation) = 32\n  Gradient Accumulation steps = 1\n  Total optimization steps = 54120\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20221030_153513-39sa2n6s</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/tccii/huggingface/runs/39sa2n6s\" target=\"_blank\">./BERTimbau-CENTENFolha-8_parts</a></strong> to <a href=\"https://wandb.ai/tccii/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='54120' max='54120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [54120/54120 3:31:50, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>2.451300</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>2.361700</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>2.325200</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>2.326800</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>2.300700</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>2.282000</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>2.263800</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>2.264800</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>2.232700</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>2.252000</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>2.238300</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>2.153800</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>2.142600</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>2.163300</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>2.156300</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>2.146300</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>2.156900</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>2.165900</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>2.158100</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>2.124800</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>2.114700</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>2.112000</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>2.085100</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>2.074000</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>2.064500</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>2.077600</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>2.071000</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>2.076200</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>2.071800</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>2.057200</td>\n    </tr>\n    <tr>\n      <td>15500</td>\n      <td>2.043200</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>2.052800</td>\n    </tr>\n    <tr>\n      <td>16500</td>\n      <td>2.022700</td>\n    </tr>\n    <tr>\n      <td>17000</td>\n      <td>2.004600</td>\n    </tr>\n    <tr>\n      <td>17500</td>\n      <td>2.001600</td>\n    </tr>\n    <tr>\n      <td>18000</td>\n      <td>2.006500</td>\n    </tr>\n    <tr>\n      <td>18500</td>\n      <td>2.009700</td>\n    </tr>\n    <tr>\n      <td>19000</td>\n      <td>2.011600</td>\n    </tr>\n    <tr>\n      <td>19500</td>\n      <td>1.992900</td>\n    </tr>\n    <tr>\n      <td>20000</td>\n      <td>2.015900</td>\n    </tr>\n    <tr>\n      <td>20500</td>\n      <td>2.004600</td>\n    </tr>\n    <tr>\n      <td>21000</td>\n      <td>1.994900</td>\n    </tr>\n    <tr>\n      <td>21500</td>\n      <td>2.008600</td>\n    </tr>\n    <tr>\n      <td>22000</td>\n      <td>1.957900</td>\n    </tr>\n    <tr>\n      <td>22500</td>\n      <td>1.950900</td>\n    </tr>\n    <tr>\n      <td>23000</td>\n      <td>1.965200</td>\n    </tr>\n    <tr>\n      <td>23500</td>\n      <td>1.945700</td>\n    </tr>\n    <tr>\n      <td>24000</td>\n      <td>1.956300</td>\n    </tr>\n    <tr>\n      <td>24500</td>\n      <td>1.975800</td>\n    </tr>\n    <tr>\n      <td>25000</td>\n      <td>1.957000</td>\n    </tr>\n    <tr>\n      <td>25500</td>\n      <td>1.924400</td>\n    </tr>\n    <tr>\n      <td>26000</td>\n      <td>1.921900</td>\n    </tr>\n    <tr>\n      <td>26500</td>\n      <td>1.933700</td>\n    </tr>\n    <tr>\n      <td>27000</td>\n      <td>1.924300</td>\n    </tr>\n    <tr>\n      <td>27500</td>\n      <td>1.903400</td>\n    </tr>\n    <tr>\n      <td>28000</td>\n      <td>1.901700</td>\n    </tr>\n    <tr>\n      <td>28500</td>\n      <td>1.875900</td>\n    </tr>\n    <tr>\n      <td>29000</td>\n      <td>1.902900</td>\n    </tr>\n    <tr>\n      <td>29500</td>\n      <td>1.906100</td>\n    </tr>\n    <tr>\n      <td>30000</td>\n      <td>1.904300</td>\n    </tr>\n    <tr>\n      <td>30500</td>\n      <td>1.916900</td>\n    </tr>\n    <tr>\n      <td>31000</td>\n      <td>1.880200</td>\n    </tr>\n    <tr>\n      <td>31500</td>\n      <td>1.899300</td>\n    </tr>\n    <tr>\n      <td>32000</td>\n      <td>1.877300</td>\n    </tr>\n    <tr>\n      <td>32500</td>\n      <td>1.886300</td>\n    </tr>\n    <tr>\n      <td>33000</td>\n      <td>1.829200</td>\n    </tr>\n    <tr>\n      <td>33500</td>\n      <td>1.843600</td>\n    </tr>\n    <tr>\n      <td>34000</td>\n      <td>1.846800</td>\n    </tr>\n    <tr>\n      <td>34500</td>\n      <td>1.858700</td>\n    </tr>\n    <tr>\n      <td>35000</td>\n      <td>1.843200</td>\n    </tr>\n    <tr>\n      <td>35500</td>\n      <td>1.863600</td>\n    </tr>\n    <tr>\n      <td>36000</td>\n      <td>1.856100</td>\n    </tr>\n    <tr>\n      <td>36500</td>\n      <td>1.853200</td>\n    </tr>\n    <tr>\n      <td>37000</td>\n      <td>1.823700</td>\n    </tr>\n    <tr>\n      <td>37500</td>\n      <td>1.840900</td>\n    </tr>\n    <tr>\n      <td>38000</td>\n      <td>1.814900</td>\n    </tr>\n    <tr>\n      <td>38500</td>\n      <td>1.820900</td>\n    </tr>\n    <tr>\n      <td>39000</td>\n      <td>1.811400</td>\n    </tr>\n    <tr>\n      <td>39500</td>\n      <td>1.790500</td>\n    </tr>\n    <tr>\n      <td>40000</td>\n      <td>1.810100</td>\n    </tr>\n    <tr>\n      <td>40500</td>\n      <td>1.809300</td>\n    </tr>\n    <tr>\n      <td>41000</td>\n      <td>1.794400</td>\n    </tr>\n    <tr>\n      <td>41500</td>\n      <td>1.784100</td>\n    </tr>\n    <tr>\n      <td>42000</td>\n      <td>1.793800</td>\n    </tr>\n    <tr>\n      <td>42500</td>\n      <td>1.811200</td>\n    </tr>\n    <tr>\n      <td>43000</td>\n      <td>1.816100</td>\n    </tr>\n    <tr>\n      <td>43500</td>\n      <td>1.783000</td>\n    </tr>\n    <tr>\n      <td>44000</td>\n      <td>1.777600</td>\n    </tr>\n    <tr>\n      <td>44500</td>\n      <td>1.748000</td>\n    </tr>\n    <tr>\n      <td>45000</td>\n      <td>1.771800</td>\n    </tr>\n    <tr>\n      <td>45500</td>\n      <td>1.790700</td>\n    </tr>\n    <tr>\n      <td>46000</td>\n      <td>1.758200</td>\n    </tr>\n    <tr>\n      <td>46500</td>\n      <td>1.781500</td>\n    </tr>\n    <tr>\n      <td>47000</td>\n      <td>1.775300</td>\n    </tr>\n    <tr>\n      <td>47500</td>\n      <td>1.761700</td>\n    </tr>\n    <tr>\n      <td>48000</td>\n      <td>1.769600</td>\n    </tr>\n    <tr>\n      <td>48500</td>\n      <td>1.768800</td>\n    </tr>\n    <tr>\n      <td>49000</td>\n      <td>1.762900</td>\n    </tr>\n    <tr>\n      <td>49500</td>\n      <td>1.747600</td>\n    </tr>\n    <tr>\n      <td>50000</td>\n      <td>1.750200</td>\n    </tr>\n    <tr>\n      <td>50500</td>\n      <td>1.747100</td>\n    </tr>\n    <tr>\n      <td>51000</td>\n      <td>1.758100</td>\n    </tr>\n    <tr>\n      <td>51500</td>\n      <td>1.761200</td>\n    </tr>\n    <tr>\n      <td>52000</td>\n      <td>1.759600</td>\n    </tr>\n    <tr>\n      <td>52500</td>\n      <td>1.745500</td>\n    </tr>\n    <tr>\n      <td>53000</td>\n      <td>1.735500</td>\n    </tr>\n    <tr>\n      <td>53500</td>\n      <td>1.749600</td>\n    </tr>\n    <tr>\n      <td>54000</td>\n      <td>1.754700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to ./BERTimbau-CENTENFolha-8_parts/checkpoint-10000\nConfiguration saved in ./BERTimbau-CENTENFolha-8_parts/checkpoint-10000/config.json\nModel weights saved in ./BERTimbau-CENTENFolha-8_parts/checkpoint-10000/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./BERTimbau-CENTENFolha-8_parts/checkpoint-20000\nConfiguration saved in ./BERTimbau-CENTENFolha-8_parts/checkpoint-20000/config.json\nModel weights saved in ./BERTimbau-CENTENFolha-8_parts/checkpoint-20000/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./BERTimbau-CENTENFolha-8_parts/checkpoint-30000\nConfiguration saved in ./BERTimbau-CENTENFolha-8_parts/checkpoint-30000/config.json\nModel weights saved in ./BERTimbau-CENTENFolha-8_parts/checkpoint-30000/pytorch_model.bin\nDeleting older checkpoint [BERTimbau-CENTENFolha-8_parts/checkpoint-10000] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./BERTimbau-CENTENFolha-8_parts/checkpoint-40000\nConfiguration saved in ./BERTimbau-CENTENFolha-8_parts/checkpoint-40000/config.json\nModel weights saved in ./BERTimbau-CENTENFolha-8_parts/checkpoint-40000/pytorch_model.bin\nDeleting older checkpoint [BERTimbau-CENTENFolha-8_parts/checkpoint-20000] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./BERTimbau-CENTENFolha-8_parts/checkpoint-50000\nConfiguration saved in ./BERTimbau-CENTENFolha-8_parts/checkpoint-50000/config.json\nModel weights saved in ./BERTimbau-CENTENFolha-8_parts/checkpoint-50000/pytorch_model.bin\nDeleting older checkpoint [BERTimbau-CENTENFolha-8_parts/checkpoint-30000] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=54120, training_loss=1.9531073046541179, metrics={'train_runtime': 12738.0585, 'train_samples_per_second': 135.952, 'train_steps_per_second': 4.249, 'total_flos': 2.848789535653248e+16, 'train_loss': 1.9531073046541179, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"code","source":"import math\neval_results = trainer.evaluate()\nprint(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")","metadata":{"id":"p9rpjGVyj68j","outputId":"f850e557-108d-44e0-9e96-a0789cfb4e9b","execution":{"iopub.status.busy":"2022-10-30T19:07:19.941995Z","iopub.execute_input":"2022-10-30T19:07:19.942981Z","iopub.status.idle":"2022-10-30T19:10:55.719257Z","shell.execute_reply.started":"2022-10-30T19:07:19.942941Z","shell.execute_reply":"2022-10-30T19:10:55.718375Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 57875\n  Batch size = 16\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3618' max='3618' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3618/3618 03:35]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Perplexity: 6.39\n","output_type":"stream"}]},{"cell_type":"code","source":"eval_results","metadata":{"id":"Ihaz7TAMAF4l","outputId":"9968d417-56a4-4425-ccf7-7f7e449dc0df","execution":{"iopub.status.busy":"2022-10-30T19:10:55.720847Z","iopub.execute_input":"2022-10-30T19:10:55.721175Z","iopub.status.idle":"2022-10-30T19:10:55.734385Z","shell.execute_reply.started":"2022-10-30T19:10:55.721143Z","shell.execute_reply":"2022-10-30T19:10:55.733495Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 1.8548541069030762,\n 'eval_runtime': 215.7597,\n 'eval_samples_per_second': 268.238,\n 'eval_steps_per_second': 16.769,\n 'epoch': 10.0}"},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 14: Saving the Final Model(+tokenizer + config) to disk\ntrainer.save_model(\"./BERTimbau-CENTENFolha-8_parts\")","metadata":{"id":"xusSgo3unkRI","outputId":"7128221d-3161-48d7-eca4-4592009cc584","execution":{"iopub.status.busy":"2022-10-30T19:10:55.735992Z","iopub.execute_input":"2022-10-30T19:10:55.737089Z","iopub.status.idle":"2022-10-30T19:10:56.522459Z","shell.execute_reply.started":"2022-10-30T19:10:55.737054Z","shell.execute_reply":"2022-10-30T19:10:56.521548Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Saving model checkpoint to ./BERTimbau-CENTENFolha-8_parts\nConfiguration saved in ./BERTimbau-CENTENFolha-8_parts/config.json\nModel weights saved in ./BERTimbau-CENTENFolha-8_parts/pytorch_model.bin\n","output_type":"stream"}]},{"cell_type":"code","source":"# Saving model on Wandb\nimport wandb\nwandb.save('BERTimbau-CENTENFolha-8_parts.h5')","metadata":{"execution":{"iopub.status.busy":"2022-10-30T19:10:56.525056Z","iopub.execute_input":"2022-10-30T19:10:56.526039Z","iopub.status.idle":"2022-10-30T19:10:56.534283Z","shell.execute_reply.started":"2022-10-30T19:10:56.525989Z","shell.execute_reply":"2022-10-30T19:10:56.533233Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 3: Configurando o pipeline fill-mask\n#@title Step 15: Language Modeling with the FillMaskPipeline\nfrom transformers import pipeline\n\nfill_mask = pipeline(\n    \"fill-mask\",\n    model=\"./BERTimbau-CENTENFolha-8_parts\",\n    tokenizer=tokenizer\n)","metadata":{"id":"pqy7oTgYFb9Y","outputId":"82629ccc-36b7-439e-df94-7af7fdd47516","execution":{"iopub.status.busy":"2022-10-30T19:10:56.535853Z","iopub.execute_input":"2022-10-30T19:10:56.536335Z","iopub.status.idle":"2022-10-30T19:10:58.263550Z","shell.execute_reply.started":"2022-10-30T19:10:56.536296Z","shell.execute_reply":"2022-10-30T19:10:58.262487Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"loading configuration file ./BERTimbau-CENTENFolha-8_parts/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"./BERTimbau-CENTENFolha-8_parts\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"directionality\": \"bidi\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_past\": true,\n  \"pad_token_id\": 0,\n  \"pooler_fc_size\": 768,\n  \"pooler_num_attention_heads\": 12,\n  \"pooler_num_fc_layers\": 3,\n  \"pooler_size_per_head\": 128,\n  \"pooler_type\": \"first_token_transform\",\n  \"position_embedding_type\": \"absolute\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 29794\n}\n\nloading configuration file ./BERTimbau-CENTENFolha-8_parts/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"./BERTimbau-CENTENFolha-8_parts\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"directionality\": \"bidi\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_past\": true,\n  \"pad_token_id\": 0,\n  \"pooler_fc_size\": 768,\n  \"pooler_num_attention_heads\": 12,\n  \"pooler_num_fc_layers\": 3,\n  \"pooler_size_per_head\": 128,\n  \"pooler_type\": \"first_token_transform\",\n  \"position_embedding_type\": \"absolute\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 29794\n}\n\nloading weights file ./BERTimbau-CENTENFolha-8_parts/pytorch_model.bin\nAll model checkpoint weights were used when initializing BertForMaskedLM.\n\nAll the weights of BertForMaskedLM were initialized from the model checkpoint at ./BERTimbau-CENTENFolha-8_parts.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"fill_mask(\"O rapaz olhou para o [MASK] \")","metadata":{"id":"RRrtRPA6GRF8","outputId":"940a13ea-77ee-42eb-df7e-7d3199234cde","execution":{"iopub.status.busy":"2022-10-30T19:30:12.943416Z","iopub.execute_input":"2022-10-30T19:30:12.943784Z","iopub.status.idle":"2022-10-30T19:30:13.390504Z","shell.execute_reply.started":"2022-10-30T19:30:12.943753Z","shell.execute_reply":"2022-10-30T19:30:13.389456Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.17389041185379028,\n  'token': 8242,\n  'token_str': 'céu',\n  'sequence': 'O rapaz olhou para o céu'},\n {'score': 0.09678210318088531,\n  'token': 528,\n  'token_str': 'mar',\n  'sequence': 'O rapaz olhou para o mar'},\n {'score': 0.09194570779800415,\n  'token': 2979,\n  'token_str': 'alto',\n  'sequence': 'O rapaz olhou para o alto'},\n {'score': 0.054797518998384476,\n  'token': 1341,\n  'token_str': 'lado',\n  'sequence': 'O rapaz olhou para o lado'},\n {'score': 0.03012910857796669,\n  'token': 17508,\n  'token_str': 'fotógrafo',\n  'sequence': 'O rapaz olhou para o fotógrafo'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"A moça olhou para o [MASK] \")","metadata":{"id":"56WEAY40asDv","outputId":"b70c5b72-8475-41b6-8bb7-37d7ed675fb4","execution":{"iopub.status.busy":"2022-10-30T19:30:23.294705Z","iopub.execute_input":"2022-10-30T19:30:23.295063Z","iopub.status.idle":"2022-10-30T19:30:23.447406Z","shell.execute_reply.started":"2022-10-30T19:30:23.295030Z","shell.execute_reply":"2022-10-30T19:30:23.446323Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.22396305203437805,\n  'token': 8242,\n  'token_str': 'céu',\n  'sequence': 'A moça olhou para o céu'},\n {'score': 0.1572679579257965,\n  'token': 528,\n  'token_str': 'mar',\n  'sequence': 'A moça olhou para o mar'},\n {'score': 0.0833396315574646,\n  'token': 1341,\n  'token_str': 'lado',\n  'sequence': 'A moça olhou para o lado'},\n {'score': 0.06177308037877083,\n  'token': 2979,\n  'token_str': 'alto',\n  'sequence': 'A moça olhou para o alto'},\n {'score': 0.033471353352069855,\n  'token': 8105,\n  'token_str': 'chão',\n  'sequence': 'A moça olhou para o chão'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Comprou uma [MASK] na loja. \")","metadata":{"id":"HiDV-v5rTyJt","outputId":"f082e061-276c-4984-b96f-26021fb3d323","execution":{"iopub.status.busy":"2022-10-30T19:30:53.849131Z","iopub.execute_input":"2022-10-30T19:30:53.850164Z","iopub.status.idle":"2022-10-30T19:30:54.010068Z","shell.execute_reply.started":"2022-10-30T19:30:53.850123Z","shell.execute_reply":"2022-10-30T19:30:54.009203Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.05365389585494995,\n  'token': 6997,\n  'token_str': 'máquina',\n  'sequence': 'Comprou uma máquina na loja.'},\n {'score': 0.04515117406845093,\n  'token': 7924,\n  'token_str': 'camisa',\n  'sequence': 'Comprou uma camisa na loja.'},\n {'score': 0.029280485585331917,\n  'token': 9978,\n  'token_str': 'placa',\n  'sequence': 'Comprou uma placa na loja.'},\n {'score': 0.028624143451452255,\n  'token': 11586,\n  'token_str': 'fita',\n  'sequence': 'Comprou uma fita na loja.'},\n {'score': 0.027298428118228912,\n  'token': 4320,\n  'token_str': 'peça',\n  'sequence': 'Comprou uma peça na loja.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"A mulher não é [MASK]. \")","metadata":{"id":"gVnhg1bxT-wK","outputId":"b3d1da07-a8f4-497e-8b6b-a5629c69831b","execution":{"iopub.status.busy":"2022-10-30T19:31:01.444572Z","iopub.execute_input":"2022-10-30T19:31:01.444941Z","iopub.status.idle":"2022-10-30T19:31:01.596202Z","shell.execute_reply.started":"2022-10-30T19:31:01.444908Z","shell.execute_reply":"2022-10-30T19:31:01.595248Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.03964012861251831,\n  'token': 3575,\n  'token_str': 'diferente',\n  'sequence': 'A mulher não é diferente.'},\n {'score': 0.03547123819589615,\n  'token': 6648,\n  'token_str': 'exceção',\n  'sequence': 'A mulher não é exceção.'},\n {'score': 0.034216783940792084,\n  'token': 1016,\n  'token_str': 'assim',\n  'sequence': 'A mulher não é assim.'},\n {'score': 0.03227553144097328,\n  'token': 12222,\n  'token_str': 'casada',\n  'sequence': 'A mulher não é casada.'},\n {'score': 0.03098089061677456,\n  'token': 13420,\n  'token_str': 'perfeita',\n  'sequence': 'A mulher não é perfeita.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"O homem não é [MASK]. \")","metadata":{"id":"l486NETHUFw6","outputId":"06df0abd-b2e7-4a24-885d-0739ed80d6bb","execution":{"iopub.status.busy":"2022-10-30T19:31:07.897416Z","iopub.execute_input":"2022-10-30T19:31:07.897818Z","iopub.status.idle":"2022-10-30T19:31:08.046420Z","shell.execute_reply.started":"2022-10-30T19:31:07.897784Z","shell.execute_reply":"2022-10-30T19:31:08.045439Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.05757135525345802,\n  'token': 13380,\n  'token_str': 'perfeito',\n  'sequence': 'O homem não é perfeito.'},\n {'score': 0.04005825147032738,\n  'token': 2397,\n  'token_str': 'homem',\n  'sequence': 'O homem não é homem.'},\n {'score': 0.03814077377319336,\n  'token': 2538,\n  'token_str': 'Deus',\n  'sequence': 'O homem não é Deus.'},\n {'score': 0.03666003793478012,\n  'token': 1016,\n  'token_str': 'assim',\n  'sequence': 'O homem não é assim.'},\n {'score': 0.034408535808324814,\n  'token': 3874,\n  'token_str': 'nada',\n  'sequence': 'O homem não é nada.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Ele é um bom [MASK]. \")","metadata":{"id":"XBxjvRGYVAxC","outputId":"bb309e59-bfe6-42b1-aa4b-0a689b84a97a","execution":{"iopub.status.busy":"2022-10-30T19:31:13.047857Z","iopub.execute_input":"2022-10-30T19:31:13.048260Z","iopub.status.idle":"2022-10-30T19:31:13.197479Z","shell.execute_reply.started":"2022-10-30T19:31:13.048222Z","shell.execute_reply":"2022-10-30T19:31:13.196432Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.07156675308942795,\n  'token': 3620,\n  'token_str': 'ator',\n  'sequence': 'Ele é um bom ator.'},\n {'score': 0.06061194837093353,\n  'token': 1416,\n  'token_str': 'exemplo',\n  'sequence': 'Ele é um bom exemplo.'},\n {'score': 0.05238033086061478,\n  'token': 2357,\n  'token_str': 'jogador',\n  'sequence': 'Ele é um bom jogador.'},\n {'score': 0.03550665080547333,\n  'token': 2481,\n  'token_str': 'diretor',\n  'sequence': 'Ele é um bom diretor.'},\n {'score': 0.026792114600539207,\n  'token': 13254,\n  'token_str': 'rapaz',\n  'sequence': 'Ele é um bom rapaz.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Ela é uma boa [MASK]. \")","metadata":{"id":"PBQ5HugqVPF4","outputId":"2db97d91-c29b-49e2-f2c7-2dd93400d051","execution":{"iopub.status.busy":"2022-10-30T19:31:26.567153Z","iopub.execute_input":"2022-10-30T19:31:26.567880Z","iopub.status.idle":"2022-10-30T19:31:26.723893Z","shell.execute_reply.started":"2022-10-30T19:31:26.567843Z","shell.execute_reply":"2022-10-30T19:31:26.722974Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.1693785935640335,\n  'token': 4067,\n  'token_str': 'companhia',\n  'sequence': 'Ela é uma boa companhia.'},\n {'score': 0.06881117820739746,\n  'token': 8208,\n  'token_str': 'opção',\n  'sequence': 'Ela é uma boa opção.'},\n {'score': 0.0625816285610199,\n  'token': 2760,\n  'token_str': 'pessoa',\n  'sequence': 'Ela é uma boa pessoa.'},\n {'score': 0.05718264728784561,\n  'token': 8932,\n  'token_str': 'amiga',\n  'sequence': 'Ela é uma boa amiga.'},\n {'score': 0.04817567020654678,\n  'token': 3557,\n  'token_str': 'atriz',\n  'sequence': 'Ela é uma boa atriz.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Faz de conta que ainda é [MASK]. \")","metadata":{"id":"qUBfuZBNa4_2","outputId":"dfae7051-1ffb-4787-f1d3-8fc4e28ff1a1","execution":{"iopub.status.busy":"2022-10-30T19:31:35.989009Z","iopub.execute_input":"2022-10-30T19:31:35.989383Z","iopub.status.idle":"2022-10-30T19:31:36.161748Z","shell.execute_reply.started":"2022-10-30T19:31:35.989350Z","shell.execute_reply":"2022-10-30T19:31:36.160637Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.13699284195899963,\n  'token': 8545,\n  'token_str': 'cedo',\n  'sequence': 'Faz de conta que ainda é cedo.'},\n {'score': 0.09371994435787201,\n  'token': 1695,\n  'token_str': 'pouco',\n  'sequence': 'Faz de conta que ainda é pouco.'},\n {'score': 0.07628239691257477,\n  'token': 2656,\n  'token_str': 'jovem',\n  'sequence': 'Faz de conta que ainda é jovem.'},\n {'score': 0.06331298500299454,\n  'token': 4931,\n  'token_str': 'candidato',\n  'sequence': 'Faz de conta que ainda é candidato.'},\n {'score': 0.058164678514003754,\n  'token': 1373,\n  'token_str': 'tarde',\n  'sequence': 'Faz de conta que ainda é tarde.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Depois da tempestade vem a [MASK]. \")","metadata":{"id":"u4E4MHWmbBsH","outputId":"49947f61-6226-494b-9424-e953c96363b8","execution":{"iopub.status.busy":"2022-10-30T19:31:44.619096Z","iopub.execute_input":"2022-10-30T19:31:44.619823Z","iopub.status.idle":"2022-10-30T19:31:44.800099Z","shell.execute_reply.started":"2022-10-30T19:31:44.619784Z","shell.execute_reply":"2022-10-30T19:31:44.799186Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.2662242650985718,\n  'token': 8742,\n  'token_str': 'seca',\n  'sequence': 'Depois da tempestade vem a seca.'},\n {'score': 0.05305907130241394,\n  'token': 1386,\n  'token_str': 'morte',\n  'sequence': 'Depois da tempestade vem a morte.'},\n {'score': 0.052535828202962875,\n  'token': 12299,\n  'token_str': 'neve',\n  'sequence': 'Depois da tempestade vem a neve.'},\n {'score': 0.03662586212158203,\n  'token': 10186,\n  'token_str': 'primavera',\n  'sequence': 'Depois da tempestade vem a primavera.'},\n {'score': 0.03568654507398605,\n  'token': 9856,\n  'token_str': 'chuva',\n  'sequence': 'Depois da tempestade vem a chuva.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Mais vale um pássaro na mão do que [MASK] voando. \")","metadata":{"id":"8bd3GbaabIn7","outputId":"3d305d34-61bf-446b-b917-2be8cc19abc4","execution":{"iopub.status.busy":"2022-10-30T19:31:53.466568Z","iopub.execute_input":"2022-10-30T19:31:53.466923Z","iopub.status.idle":"2022-10-30T19:31:53.669849Z","shell.execute_reply.started":"2022-10-30T19:31:53.466892Z","shell.execute_reply":"2022-10-30T19:31:53.668921Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.35812652111053467,\n  'token': 222,\n  'token_str': 'um',\n  'sequence': 'Mais vale um pássaro na mão do que um voando.'},\n {'score': 0.09153059870004654,\n  'token': 1342,\n  'token_str': 'outro',\n  'sequence': 'Mais vale um pássaro na mão do que outro voando.'},\n {'score': 0.07664812356233597,\n  'token': 14934,\n  'token_str': 'voar',\n  'sequence': 'Mais vale um pássaro na mão do que voar voando.'},\n {'score': 0.048725761473178864,\n  'token': 6384,\n  'token_str': 'alguém',\n  'sequence': 'Mais vale um pássaro na mão do que alguém voando.'},\n {'score': 0.04480363428592682,\n  'token': 5197,\n  'token_str': 'sair',\n  'sequence': 'Mais vale um pássaro na mão do que sair voando.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Não tinha [MASK], mas almoçou mesmo assim. \")","metadata":{"id":"bhep3pt3bUkJ","outputId":"fd3b55ec-3923-4308-f851-707faafda30e","execution":{"iopub.status.busy":"2022-10-30T19:32:21.545706Z","iopub.execute_input":"2022-10-30T19:32:21.546076Z","iopub.status.idle":"2022-10-30T19:32:21.736382Z","shell.execute_reply.started":"2022-10-30T19:32:21.546043Z","shell.execute_reply":"2022-10-30T19:32:21.735392Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.08342432975769043,\n  'token': 3495,\n  'token_str': 'dinheiro',\n  'sequence': 'Não tinha dinheiro, mas almoçou mesmo assim.'},\n {'score': 0.051540203392505646,\n  'token': 11572,\n  'token_str': 'telefone',\n  'sequence': 'Não tinha telefone, mas almoçou mesmo assim.'},\n {'score': 0.035101037472486496,\n  'token': 12319,\n  'token_str': 'chegado',\n  'sequence': 'Não tinha chegado, mas almoçou mesmo assim.'},\n {'score': 0.033241044729948044,\n  'token': 13746,\n  'token_str': 'namorado',\n  'sequence': 'Não tinha namorado, mas almoçou mesmo assim.'},\n {'score': 0.027934936806559563,\n  'token': 14890,\n  'token_str': 'jantar',\n  'sequence': 'Não tinha jantar, mas almoçou mesmo assim.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Bebeu um copo d'água, pois tinha [MASK]. \")","metadata":{"id":"Vpn7cJREbj_Y","outputId":"c5a60b8a-9923-4ed3-da44-e478d2bd0954","execution":{"iopub.status.busy":"2022-10-30T19:32:26.143299Z","iopub.execute_input":"2022-10-30T19:32:26.143673Z","iopub.status.idle":"2022-10-30T19:32:26.355743Z","shell.execute_reply.started":"2022-10-30T19:32:26.143641Z","shell.execute_reply":"2022-10-30T19:32:26.354823Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.22507280111312866,\n  'token': 11062,\n  'token_str': 'fome',\n  'sequence': \"Bebeu um copo d'água, pois tinha fome.\"},\n {'score': 0.15004238486289978,\n  'token': 14594,\n  'token_str': 'febre',\n  'sequence': \"Bebeu um copo d'água, pois tinha febre.\"},\n {'score': 0.12500622868537903,\n  'token': 7672,\n  'token_str': 'medo',\n  'sequence': \"Bebeu um copo d'água, pois tinha medo.\"},\n {'score': 0.043515708297491074,\n  'token': 2496,\n  'token_str': 'sede',\n  'sequence': \"Bebeu um copo d'água, pois tinha sede.\"},\n {'score': 0.0227068904787302,\n  'token': 17609,\n  'token_str': 'acabado',\n  'sequence': \"Bebeu um copo d'água, pois tinha acabado.\"}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Sem saber, ele descobriu um [MASK]. \")","metadata":{"id":"9KrDcsT2bzkl","outputId":"fde63380-d420-4e04-9b05-f330eec3ee76","execution":{"iopub.status.busy":"2022-10-30T19:32:28.768330Z","iopub.execute_input":"2022-10-30T19:32:28.769650Z","iopub.status.idle":"2022-10-30T19:32:28.946307Z","shell.execute_reply.started":"2022-10-30T19:32:28.769595Z","shell.execute_reply":"2022-10-30T19:32:28.945163Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.1839371919631958,\n  'token': 11021,\n  'token_str': 'segredo',\n  'sequence': 'Sem saber, ele descobriu um segredo.'},\n {'score': 0.13480046391487122,\n  'token': 3420,\n  'token_str': 'caminho',\n  'sequence': 'Sem saber, ele descobriu um caminho.'},\n {'score': 0.03356393426656723,\n  'token': 16269,\n  'token_str': 'mistério',\n  'sequence': 'Sem saber, ele descobriu um mistério.'},\n {'score': 0.018778884783387184,\n  'token': 3350,\n  'token_str': 'problema',\n  'sequence': 'Sem saber, ele descobriu um problema.'},\n {'score': 0.016541659832000732,\n  'token': 3204,\n  'token_str': 'plano',\n  'sequence': 'Sem saber, ele descobriu um plano.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Pedro fez fortuna vendendo [MASK]. \")","metadata":{"id":"FzIuM2mFb6tc","outputId":"d117842d-8035-4682-e27c-6174ee2a62e8","execution":{"iopub.status.busy":"2022-10-30T19:32:31.487047Z","iopub.execute_input":"2022-10-30T19:32:31.487612Z","iopub.status.idle":"2022-10-30T19:32:31.633068Z","shell.execute_reply.started":"2022-10-30T19:32:31.487576Z","shell.execute_reply":"2022-10-30T19:32:31.632124Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.07013530284166336,\n  'token': 2978,\n  'token_str': 'livros',\n  'sequence': 'Pedro fez fortuna vendendo livros.'},\n {'score': 0.06996648758649826,\n  'token': 3191,\n  'token_str': 'armas',\n  'sequence': 'Pedro fez fortuna vendendo armas.'},\n {'score': 0.05868770554661751,\n  'token': 9701,\n  'token_str': 'cavalos',\n  'sequence': 'Pedro fez fortuna vendendo cavalos.'},\n {'score': 0.05046388506889343,\n  'token': 2987,\n  'token_str': 'ouro',\n  'sequence': 'Pedro fez fortuna vendendo ouro.'},\n {'score': 0.03814943507313728,\n  'token': 5976,\n  'token_str': 'escravos',\n  'sequence': 'Pedro fez fortuna vendendo escravos.'}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Sem medo de ser [MASK]. \")","metadata":{"id":"4t6LS5glcZFN","outputId":"ad7fb0c9-1c4c-4884-9a37-e68bce58e77f","execution":{"iopub.status.busy":"2022-10-30T19:32:47.362477Z","iopub.execute_input":"2022-10-30T19:32:47.362847Z","iopub.status.idle":"2022-10-30T19:32:47.506384Z","shell.execute_reply.started":"2022-10-30T19:32:47.362814Z","shell.execute_reply":"2022-10-30T19:32:47.505466Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.11592359840869904,\n  'token': 5139,\n  'token_str': 'preso',\n  'sequence': 'Sem medo de ser preso.'},\n {'score': 0.07185672223567963,\n  'token': 8540,\n  'token_str': 'feliz',\n  'sequence': 'Sem medo de ser feliz.'},\n {'score': 0.04520270973443985,\n  'token': 13205,\n  'token_str': 'demitido',\n  'sequence': 'Sem medo de ser demitido.'},\n {'score': 0.03822215273976326,\n  'token': 14133,\n  'token_str': 'expulso',\n  'sequence': 'Sem medo de ser expulso.'},\n {'score': 0.03504673019051552,\n  'token': 15854,\n  'token_str': 'pega',\n  'sequence': 'Sem medo de ser pega.'}]"},"metadata":{}}]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2022-10-30T19:32:53.897279Z","iopub.execute_input":"2022-10-30T19:32:53.897727Z","iopub.status.idle":"2022-10-30T19:32:57.574811Z","shell.execute_reply.started":"2022-10-30T19:32:53.897686Z","shell.execute_reply":"2022-10-30T19:32:57.573783Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.85485</td></tr><tr><td>eval/runtime</td><td>215.7597</td></tr><tr><td>eval/samples_per_second</td><td>268.238</td></tr><tr><td>eval/steps_per_second</td><td>16.769</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>54120</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.7547</td></tr><tr><td>train/total_flos</td><td>2.848789535653248e+16</td></tr><tr><td>train/train_loss</td><td>1.95311</td></tr><tr><td>train/train_runtime</td><td>12738.0585</td></tr><tr><td>train/train_samples_per_second</td><td>135.952</td></tr><tr><td>train/train_steps_per_second</td><td>4.249</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Synced <strong style=\"color:#cdcd00\">./BERTimbau-CENTENFolha-8_parts</strong>: <a href=\"https://wandb.ai/tccii/huggingface/runs/39sa2n6s\" target=\"_blank\">https://wandb.ai/tccii/huggingface/runs/39sa2n6s</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20221030_153513-39sa2n6s/logs</code>"},"metadata":{}}]}]}