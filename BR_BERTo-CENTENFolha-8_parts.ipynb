{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/marianameyerf/notebook40af724143?scriptVersionId=109429558\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/jsansao/transformers_pt/blob/main/BR_BERTo_Fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"# InferÃªncia usando transformers prÃ©-treinados do HuggingFace ","metadata":{"id":"hV_s2jhFIGRV"}},{"cell_type":"markdown","source":"BR_BERTo\n\nCENTENFolha - 8 partes\n\nBatch size = 16\n\nGPU T4x2\n\n(07h:21m)","metadata":{}},{"cell_type":"code","source":"#@title Passo 1:Instalando Hugging Face Transformers\n# We won't need TensorFlow here\n!pip uninstall -y tensorflow\n# Install `transformers` from master\n!pip install git+https://github.com/huggingface/transformers\n!pip list | grep -E 'transformers|tokenizers'\n# transformers version at notebook update --- 2.9.1\n# tokenizers version at notebook update --- 0.7.0","metadata":{"id":"LhI1tJBGBd3r","outputId":"7b6abfac-a01a-4cf0-85a5-7fa6a55e20db","execution":{"iopub.status.busy":"2022-10-28T17:15:36.61445Z","iopub.execute_input":"2022-10-28T17:15:36.61481Z","iopub.status.idle":"2022-10-28T17:16:47.45331Z","shell.execute_reply.started":"2022-10-28T17:15:36.614779Z","shell.execute_reply":"2022-10-28T17:16:47.451944Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found existing installation: tensorflow 2.6.4\nUninstalling tensorflow-2.6.4:\n  Successfully uninstalled tensorflow-2.6.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting git+https://github.com/huggingface/transformers\n  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-cjv7y01t\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-cjv7y01t\n  Resolved https://github.com/huggingface/transformers to commit 98c9c5add92aa66d9f09af192139b4cb502aa9fb\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.24.0.dev0) (0.12.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.24.0.dev0) (21.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.24.0.dev0) (2021.11.10)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.24.0.dev0) (3.7.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.24.0.dev0) (4.13.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.24.0.dev0) (1.21.6)\nRequirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.24.0.dev0) (0.10.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.24.0.dev0) (2.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.24.0.dev0) (6.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.24.0.dev0) (4.64.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.24.0.dev0) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers==4.24.0.dev0) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.24.0.dev0) (3.8.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.24.0.dev0) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.24.0.dev0) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.24.0.dev0) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.24.0.dev0) (2022.9.24)\nBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers: filename=transformers-4.24.0.dev0-py3-none-any.whl size=5429247 sha256=9693e66f7b4c1a3da43f751b857eaaab4296459d016b6ed36709b2869a03f74f\n  Stored in directory: /tmp/pip-ephem-wheel-cache-nrpqnajt/wheels/35/2e/a7/d819e3310040329f0f47e57c9e3e7a7338aa5e74c49acfe522\nSuccessfully built transformers\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.20.1\n    Uninstalling transformers-4.20.1:\n      Successfully uninstalled transformers-4.20.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nallennlp 2.10.1 requires transformers<4.21,>=4.1, but you have transformers 4.24.0.dev0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed transformers-4.24.0.dev0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mtokenizers                            0.12.1\ntransformers                          4.24.0.dev0\n","output_type":"stream"}]},{"cell_type":"code","source":"#@title Step 1: Loading the Dataset\n#1.Load kant.txt using the Colab file manager\n#2.Downloading the file from GitHub\n#!curl -L  https://raw.githubusercontent.com/jsansao/corpus_ptbr/main/dump_Machado_Nobreak.txt --output \"dump.txt\"\n!curl -L https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_aa --output \"dump.txt\"\n#!curl -L https://raw.githubusercontent.com/jsansao/corpus_ptbr/main/Lyrics_ChicoBuarque.txt --output \"kant.txt\"\n\n!awk NF < dump.txt > kant.txt","metadata":{"id":"KAl5BxxOgk35","outputId":"56349dd7-aa74-4896-c8c2-11223ee35227","execution":{"iopub.status.busy":"2022-10-28T17:16:47.459664Z","iopub.execute_input":"2022-10-28T17:16:47.462652Z","iopub.status.idle":"2022-10-28T17:16:49.775504Z","shell.execute_reply.started":"2022-10-28T17:16:47.462604Z","shell.execute_reply":"2022-10-28T17:16:49.774063Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 3724k  100 3724k    0     0  23.1M      0 --:--:-- --:--:-- --:--:-- 23.1M\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_aa \n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ab\n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ac\n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ad\n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ae \n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_af\n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ag\n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ah","metadata":{"execution":{"iopub.status.busy":"2022-10-28T17:16:49.778298Z","iopub.execute_input":"2022-10-28T17:16:49.778696Z","iopub.status.idle":"2022-10-28T17:16:59.347817Z","shell.execute_reply.started":"2022-10-28T17:16:49.778655Z","shell.execute_reply":"2022-10-28T17:16:59.346645Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"--2022-10-28 17:16:50--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_aa\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: â€˜cetenfolha_aa.2â€™\n\ncetenfolha_aa.2     100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-28 17:16:50 (54.6 MB/s) - â€˜cetenfolha_aa.2â€™ saved [3813899/3813899]\n\n--2022-10-28 17:16:51--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ab\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: â€˜cetenfolha_ab.2â€™\n\ncetenfolha_ab.2     100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-28 17:16:51 (49.7 MB/s) - â€˜cetenfolha_ab.2â€™ saved [3813899/3813899]\n\n--2022-10-28 17:16:52--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ac\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: â€˜cetenfolha_ac.2â€™\n\ncetenfolha_ac.2     100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-28 17:16:53 (51.8 MB/s) - â€˜cetenfolha_ac.2â€™ saved [3813899/3813899]\n\n--2022-10-28 17:16:54--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ad\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: â€˜cetenfolha_ad.2â€™\n\ncetenfolha_ad.2     100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-28 17:16:54 (54.7 MB/s) - â€˜cetenfolha_ad.2â€™ saved [3813899/3813899]\n\n--2022-10-28 17:16:55--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ae\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: â€˜cetenfolha_ae.2â€™\n\ncetenfolha_ae.2     100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-28 17:16:55 (49.8 MB/s) - â€˜cetenfolha_ae.2â€™ saved [3813899/3813899]\n\n--2022-10-28 17:16:56--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_af\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: â€˜cetenfolha_af.2â€™\n\ncetenfolha_af.2     100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-28 17:16:56 (52.9 MB/s) - â€˜cetenfolha_af.2â€™ saved [3813899/3813899]\n\n--2022-10-28 17:16:57--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ag\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: â€˜cetenfolha_ag.2â€™\n\ncetenfolha_ag.2     100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-28 17:16:57 (52.5 MB/s) - â€˜cetenfolha_ag.2â€™ saved [3813899/3813899]\n\n--2022-10-28 17:16:58--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ah\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: â€˜cetenfolha_ah.1â€™\n\ncetenfolha_ah.1     100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-10-28 17:16:59 (54.4 MB/s) - â€˜cetenfolha_ah.1â€™ saved [3813899/3813899]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!cat cetenfolha_aa cetenfolha_ab cetenfolha_ac cetenfolha_ad cetenfolha_ae cetenfolha_af cetenfolha_ag cetenfolha_ah>  dump.txt\n!awk NF < dump.txt > kant.txt","metadata":{"execution":{"iopub.status.busy":"2022-10-28T17:16:59.349813Z","iopub.execute_input":"2022-10-28T17:16:59.350226Z","iopub.status.idle":"2022-10-28T17:17:01.791672Z","shell.execute_reply.started":"2022-10-28T17:16:59.350188Z","shell.execute_reply":"2022-10-28T17:17:01.790453Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#@title Passo 2:Baixando e salvando BR_BERTo\n#https://huggingface.co/rdenadai/BR_BERTo\n\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"rdenadai/BR_BERTo\")\n\nmodel = AutoModelForMaskedLM.from_pretrained(\"rdenadai/BR_BERTo\")","metadata":{"id":"h2L_Put8Cn8S","outputId":"7a1f401d-e360-4973-cc95-9f16a6f5bcbd","execution":{"iopub.status.busy":"2022-10-28T17:17:01.796139Z","iopub.execute_input":"2022-10-28T17:17:01.796461Z","iopub.status.idle":"2022-10-28T17:17:42.983018Z","shell.execute_reply.started":"2022-10-28T17:17:01.796431Z","shell.execute_reply":"2022-10-28T17:17:42.981801Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/516 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6ffec081a5541e7a165e69ffdac72f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.77M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"488656113f3e460e85f651c6f51ca48f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.68M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b8c01dc4a4e43f98856941d2d2caacd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/695M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0afed71aa6644917a362f42c6d9d0164"}},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset\n#datasets = load_dataset(\"text\", data_files={\"train\": \"kant.txt\", \"validation\": \"kant_teste.txt\"})\n#datasets = load_dataset(\"text\", data_files={\"train\": \"kant.txt\"}, split='train[:90%]')\nds = load_dataset(\"text\", data_files={\"train\": \"kant.txt\"})\n\ndatasets = ds[\"train\"].train_test_split()","metadata":{"execution":{"iopub.status.busy":"2022-10-28T17:17:42.984816Z","iopub.execute_input":"2022-10-28T17:17:42.985811Z","iopub.status.idle":"2022-10-28T17:17:44.303064Z","shell.execute_reply.started":"2022-10-28T17:17:42.985772Z","shell.execute_reply":"2022-10-28T17:17:44.30201Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-fc54e5dd0afbe4cd/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c62e2931e2464b43b06f16d5557a2426"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37cd161b35634c5cb813372282be9626"}},"metadata":{}},{"name":"stdout","text":"Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-fc54e5dd0afbe4cd/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4029229b648442a0b571a22b62885c26"}},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 10: Building the Dataset\nfrom transformers import LineByLineTextDataset\n\ndataset = LineByLineTextDataset(\n    tokenizer=tokenizer,\n    file_path=\"./kant.txt\",\n    block_size=32,\n)","metadata":{"id":"ZyWFU4dNhjtI","outputId":"b926c17c-bfff-4320-91b7-ba06dcebdf9e","execution":{"iopub.status.busy":"2022-10-28T17:17:44.304444Z","iopub.execute_input":"2022-10-28T17:17:44.30519Z","iopub.status.idle":"2022-10-28T17:18:14.214147Z","shell.execute_reply.started":"2022-10-28T17:17:44.305146Z","shell.execute_reply":"2022-10-28T17:18:14.212968Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/data/datasets/language_modeling.py:125: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(examples[\"text\"])","metadata":{"execution":{"iopub.status.busy":"2022-10-28T17:18:14.2159Z","iopub.execute_input":"2022-10-28T17:18:14.21639Z","iopub.status.idle":"2022-10-28T17:18:14.221767Z","shell.execute_reply.started":"2022-10-28T17:18:14.216331Z","shell.execute_reply":"2022-10-28T17:18:14.220562Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])","metadata":{"execution":{"iopub.status.busy":"2022-10-28T17:18:14.223471Z","iopub.execute_input":"2022-10-28T17:18:14.224085Z","iopub.status.idle":"2022-10-28T17:18:51.905043Z","shell.execute_reply.started":"2022-10-28T17:18:14.224029Z","shell.execute_reply":"2022-10-28T17:18:51.903823Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"        ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b289e2c6b5a84a40b4ff08b1b1766ce5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71ade473714940738e6b4b3d8706f785"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31ca987fcfa94bfe88e73599ca66e2d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d65e225ff58456fab701201c7e69307"}},"metadata":{}},{"name":"stdout","text":"        ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2335bd526c1477cb08947be830e1b95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"065302931c284c0dbf01e9ea459e4847"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e97b6cb60824b7d9d8c881e3c20c211"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08114cb6f5d14854be0c258efeb19cb5"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets[\"train\"][4]","metadata":{"execution":{"iopub.status.busy":"2022-10-28T17:18:51.908507Z","iopub.execute_input":"2022-10-28T17:18:51.909241Z","iopub.status.idle":"2022-10-28T17:18:51.920238Z","shell.execute_reply.started":"2022-10-28T17:18:51.909201Z","shell.execute_reply":"2022-10-28T17:18:51.918209Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [0,\n  225,\n  41,\n  269,\n  271,\n  1075,\n  16,\n  262,\n  6120,\n  268,\n  45211,\n  4745,\n  469,\n  2781,\n  935,\n  639,\n  225,\n  18,\n  225,\n  2],\n 'attention_mask': [1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1]}"},"metadata":{}}]},{"cell_type":"code","source":"#block_size = tokenizer.model_max_length\nblock_size = 32","metadata":{"execution":{"iopub.status.busy":"2022-10-28T17:18:51.921925Z","iopub.execute_input":"2022-10-28T17:18:51.922309Z","iopub.status.idle":"2022-10-28T17:18:51.957977Z","shell.execute_reply.started":"2022-10-28T17:18:51.92227Z","shell.execute_reply":"2022-10-28T17:18:51.956724Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def group_texts(examples):\n    # Concatenate all texts.\n    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n    total_length = len(concatenated_examples[list(examples.keys())[0]])\n    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n        # customize this part to your needs.\n    total_length = (total_length // block_size) * block_size\n    # Split by chunks of max_len.\n    result = {\n        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n        for k, t in concatenated_examples.items()\n    }\n    result[\"labels\"] = result[\"input_ids\"].copy()\n    return result","metadata":{"execution":{"iopub.status.busy":"2022-10-28T17:18:51.959553Z","iopub.execute_input":"2022-10-28T17:18:51.960271Z","iopub.status.idle":"2022-10-28T17:18:51.97192Z","shell.execute_reply.started":"2022-10-28T17:18:51.960233Z","shell.execute_reply":"2022-10-28T17:18:51.971003Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"lm_datasets = tokenized_datasets.map(\n    group_texts,\n    batched=True,\n    batch_size=1000,\n    num_proc=4,\n)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T17:18:51.973602Z","iopub.execute_input":"2022-10-28T17:18:51.974316Z","iopub.status.idle":"2022-10-28T17:19:39.250538Z","shell.execute_reply.started":"2022-10-28T17:18:51.974282Z","shell.execute_reply":"2022-10-28T17:19:39.249383Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"      ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd9e05ab6476463087d287a3b2d2f07c"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"617a5b03806c4868b417452f05f2c420"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"134cc94100b54914b6986de68b73ba71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65e4827fb22a418b9a6787994e5a5bf5"}},"metadata":{}},{"name":"stdout","text":"     ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92ba09927e1043598bf1a398976162ef"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90a97ed60e5b476e8df3918a59f630fc"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8994619334454b9288c4b4964de9803e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ccca7326f9d4913be94f150941e029b"}},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 11: Defining a Data Collator\nfrom transformers import DataCollatorForLanguageModeling\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n)","metadata":{"id":"19hRhnHFf7FF","execution":{"iopub.status.busy":"2022-10-28T17:19:39.256628Z","iopub.execute_input":"2022-10-28T17:19:39.256939Z","iopub.status.idle":"2022-10-28T17:19:39.264656Z","shell.execute_reply.started":"2022-10-28T17:19:39.25691Z","shell.execute_reply":"2022-10-28T17:19:39.26133Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric\n\nmetric = load_metric(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return {metric.compute(predictions=predictions, references=labels)}","metadata":{"execution":{"iopub.status.busy":"2022-10-28T17:19:39.266449Z","iopub.execute_input":"2022-10-28T17:19:39.266828Z","iopub.status.idle":"2022-10-28T17:19:39.838807Z","shell.execute_reply.started":"2022-10-28T17:19:39.266786Z","shell.execute_reply":"2022-10-28T17:19:39.83792Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.41k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3861e846d21e4f0b9e645ae0a24ab104"}},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 12: Initializing the Trainer\nfrom transformers import Trainer, TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./BR_BERTo-CENTENFolha-8_parts\",\n    overwrite_output_dir=True,\n    num_train_epochs=10,\n    per_device_train_batch_size=16,\n    save_steps=10_000,\n    save_total_limit=2,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=lm_datasets[\"train\"],\n    eval_dataset=lm_datasets[\"test\"],\n)","metadata":{"id":"MH2dsTzhfgqI","execution":{"iopub.status.busy":"2022-10-28T17:19:39.840326Z","iopub.execute_input":"2022-10-28T17:19:39.840799Z","iopub.status.idle":"2022-10-28T17:19:44.314234Z","shell.execute_reply.started":"2022-10-28T17:19:39.84076Z","shell.execute_reply":"2022-10-28T17:19:44.313228Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#@title Step 13: Pre-training the Model\ntrainer.train()","metadata":{"id":"EZxksqadfv6l","outputId":"b4f753c3-de85-40f9-84ae-5e3fb08a6283","execution":{"iopub.status.busy":"2022-10-28T17:19:44.315671Z","iopub.execute_input":"2022-10-28T17:19:44.316519Z","iopub.status.idle":"2022-10-29T00:27:34.315421Z","shell.execute_reply.started":"2022-10-28T17:19:44.316477Z","shell.execute_reply":"2022-10-29T00:27:34.313874Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 219241\n  Num Epochs = 10\n  Instantaneous batch size per device = 16\n  Total train batch size (w. parallel, distributed & accumulation) = 32\n  Gradient Accumulation steps = 1\n  Total optimization steps = 68520\n  Number of trainable parameters = 173042160\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20221028_172055-2uujgccf</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/tccii/huggingface/runs/2uujgccf\" target=\"_blank\">./BR_BERTo-CENTENFolha-8_parts</a></strong> to <a href=\"https://wandb.ai/tccii/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"name":"stderr","text":"You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='68520' max='68520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [68520/68520 7:06:26, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>4.226600</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>3.832400</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>3.550500</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>3.450500</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>3.313500</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>3.260000</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>3.197100</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>3.129300</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>3.097800</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>3.040700</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>2.970700</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>2.990000</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>2.911000</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>2.900900</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>2.834400</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>2.802200</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>2.771800</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>2.757300</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>2.755000</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>2.766800</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>2.720500</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>2.719900</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>2.684900</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>2.683200</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>2.673300</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>2.676800</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>2.629500</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>2.612000</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>2.586600</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>2.577300</td>\n    </tr>\n    <tr>\n      <td>15500</td>\n      <td>2.569200</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>2.527400</td>\n    </tr>\n    <tr>\n      <td>16500</td>\n      <td>2.552400</td>\n    </tr>\n    <tr>\n      <td>17000</td>\n      <td>2.533600</td>\n    </tr>\n    <tr>\n      <td>17500</td>\n      <td>2.524500</td>\n    </tr>\n    <tr>\n      <td>18000</td>\n      <td>2.545600</td>\n    </tr>\n    <tr>\n      <td>18500</td>\n      <td>2.498500</td>\n    </tr>\n    <tr>\n      <td>19000</td>\n      <td>2.539100</td>\n    </tr>\n    <tr>\n      <td>19500</td>\n      <td>2.498900</td>\n    </tr>\n    <tr>\n      <td>20000</td>\n      <td>2.494400</td>\n    </tr>\n    <tr>\n      <td>20500</td>\n      <td>2.548400</td>\n    </tr>\n    <tr>\n      <td>21000</td>\n      <td>2.478400</td>\n    </tr>\n    <tr>\n      <td>21500</td>\n      <td>2.438800</td>\n    </tr>\n    <tr>\n      <td>22000</td>\n      <td>2.479200</td>\n    </tr>\n    <tr>\n      <td>22500</td>\n      <td>2.525300</td>\n    </tr>\n    <tr>\n      <td>23000</td>\n      <td>2.525800</td>\n    </tr>\n    <tr>\n      <td>23500</td>\n      <td>2.434200</td>\n    </tr>\n    <tr>\n      <td>24000</td>\n      <td>2.438400</td>\n    </tr>\n    <tr>\n      <td>24500</td>\n      <td>2.421700</td>\n    </tr>\n    <tr>\n      <td>25000</td>\n      <td>2.420800</td>\n    </tr>\n    <tr>\n      <td>25500</td>\n      <td>2.410300</td>\n    </tr>\n    <tr>\n      <td>26000</td>\n      <td>2.554400</td>\n    </tr>\n    <tr>\n      <td>26500</td>\n      <td>2.430100</td>\n    </tr>\n    <tr>\n      <td>27000</td>\n      <td>2.483400</td>\n    </tr>\n    <tr>\n      <td>27500</td>\n      <td>2.397500</td>\n    </tr>\n    <tr>\n      <td>28000</td>\n      <td>2.378500</td>\n    </tr>\n    <tr>\n      <td>28500</td>\n      <td>2.327600</td>\n    </tr>\n    <tr>\n      <td>29000</td>\n      <td>2.339900</td>\n    </tr>\n    <tr>\n      <td>29500</td>\n      <td>2.395600</td>\n    </tr>\n    <tr>\n      <td>30000</td>\n      <td>2.351600</td>\n    </tr>\n    <tr>\n      <td>30500</td>\n      <td>2.326100</td>\n    </tr>\n    <tr>\n      <td>31000</td>\n      <td>2.353200</td>\n    </tr>\n    <tr>\n      <td>31500</td>\n      <td>2.318000</td>\n    </tr>\n    <tr>\n      <td>32000</td>\n      <td>2.380100</td>\n    </tr>\n    <tr>\n      <td>32500</td>\n      <td>2.346800</td>\n    </tr>\n    <tr>\n      <td>33000</td>\n      <td>2.356800</td>\n    </tr>\n    <tr>\n      <td>33500</td>\n      <td>2.541700</td>\n    </tr>\n    <tr>\n      <td>34000</td>\n      <td>2.435000</td>\n    </tr>\n    <tr>\n      <td>34500</td>\n      <td>2.468800</td>\n    </tr>\n    <tr>\n      <td>35000</td>\n      <td>2.710900</td>\n    </tr>\n    <tr>\n      <td>35500</td>\n      <td>3.502400</td>\n    </tr>\n    <tr>\n      <td>36000</td>\n      <td>3.756300</td>\n    </tr>\n    <tr>\n      <td>36500</td>\n      <td>3.405800</td>\n    </tr>\n    <tr>\n      <td>37000</td>\n      <td>3.956400</td>\n    </tr>\n    <tr>\n      <td>37500</td>\n      <td>4.308600</td>\n    </tr>\n    <tr>\n      <td>38000</td>\n      <td>4.065800</td>\n    </tr>\n    <tr>\n      <td>38500</td>\n      <td>4.305200</td>\n    </tr>\n    <tr>\n      <td>39000</td>\n      <td>4.403600</td>\n    </tr>\n    <tr>\n      <td>39500</td>\n      <td>4.315100</td>\n    </tr>\n    <tr>\n      <td>40000</td>\n      <td>4.169900</td>\n    </tr>\n    <tr>\n      <td>40500</td>\n      <td>4.491400</td>\n    </tr>\n    <tr>\n      <td>41000</td>\n      <td>4.489800</td>\n    </tr>\n    <tr>\n      <td>41500</td>\n      <td>4.405000</td>\n    </tr>\n    <tr>\n      <td>42000</td>\n      <td>4.533200</td>\n    </tr>\n    <tr>\n      <td>42500</td>\n      <td>4.513100</td>\n    </tr>\n    <tr>\n      <td>43000</td>\n      <td>4.485600</td>\n    </tr>\n    <tr>\n      <td>43500</td>\n      <td>4.449700</td>\n    </tr>\n    <tr>\n      <td>44000</td>\n      <td>4.462600</td>\n    </tr>\n    <tr>\n      <td>44500</td>\n      <td>4.372100</td>\n    </tr>\n    <tr>\n      <td>45000</td>\n      <td>4.283400</td>\n    </tr>\n    <tr>\n      <td>45500</td>\n      <td>4.397400</td>\n    </tr>\n    <tr>\n      <td>46000</td>\n      <td>4.414700</td>\n    </tr>\n    <tr>\n      <td>46500</td>\n      <td>4.440500</td>\n    </tr>\n    <tr>\n      <td>47000</td>\n      <td>4.307100</td>\n    </tr>\n    <tr>\n      <td>47500</td>\n      <td>4.418300</td>\n    </tr>\n    <tr>\n      <td>48000</td>\n      <td>4.398800</td>\n    </tr>\n    <tr>\n      <td>48500</td>\n      <td>4.401900</td>\n    </tr>\n    <tr>\n      <td>49000</td>\n      <td>4.382800</td>\n    </tr>\n    <tr>\n      <td>49500</td>\n      <td>4.364900</td>\n    </tr>\n    <tr>\n      <td>50000</td>\n      <td>4.339500</td>\n    </tr>\n    <tr>\n      <td>50500</td>\n      <td>4.270600</td>\n    </tr>\n    <tr>\n      <td>51000</td>\n      <td>4.355000</td>\n    </tr>\n    <tr>\n      <td>51500</td>\n      <td>4.374100</td>\n    </tr>\n    <tr>\n      <td>52000</td>\n      <td>4.365500</td>\n    </tr>\n    <tr>\n      <td>52500</td>\n      <td>4.326100</td>\n    </tr>\n    <tr>\n      <td>53000</td>\n      <td>4.374200</td>\n    </tr>\n    <tr>\n      <td>53500</td>\n      <td>4.297800</td>\n    </tr>\n    <tr>\n      <td>54000</td>\n      <td>4.293500</td>\n    </tr>\n    <tr>\n      <td>54500</td>\n      <td>4.304700</td>\n    </tr>\n    <tr>\n      <td>55000</td>\n      <td>4.292900</td>\n    </tr>\n    <tr>\n      <td>55500</td>\n      <td>4.290100</td>\n    </tr>\n    <tr>\n      <td>56000</td>\n      <td>4.278900</td>\n    </tr>\n    <tr>\n      <td>56500</td>\n      <td>4.262800</td>\n    </tr>\n    <tr>\n      <td>57000</td>\n      <td>4.232000</td>\n    </tr>\n    <tr>\n      <td>57500</td>\n      <td>4.207200</td>\n    </tr>\n    <tr>\n      <td>58000</td>\n      <td>4.196100</td>\n    </tr>\n    <tr>\n      <td>58500</td>\n      <td>4.256100</td>\n    </tr>\n    <tr>\n      <td>59000</td>\n      <td>4.269000</td>\n    </tr>\n    <tr>\n      <td>59500</td>\n      <td>4.167000</td>\n    </tr>\n    <tr>\n      <td>60000</td>\n      <td>4.147800</td>\n    </tr>\n    <tr>\n      <td>60500</td>\n      <td>4.181100</td>\n    </tr>\n    <tr>\n      <td>61000</td>\n      <td>4.199500</td>\n    </tr>\n    <tr>\n      <td>61500</td>\n      <td>4.151700</td>\n    </tr>\n    <tr>\n      <td>62000</td>\n      <td>4.152600</td>\n    </tr>\n    <tr>\n      <td>62500</td>\n      <td>4.165900</td>\n    </tr>\n    <tr>\n      <td>63000</td>\n      <td>4.160100</td>\n    </tr>\n    <tr>\n      <td>63500</td>\n      <td>4.157200</td>\n    </tr>\n    <tr>\n      <td>64000</td>\n      <td>4.203700</td>\n    </tr>\n    <tr>\n      <td>64500</td>\n      <td>4.181300</td>\n    </tr>\n    <tr>\n      <td>65000</td>\n      <td>4.175500</td>\n    </tr>\n    <tr>\n      <td>65500</td>\n      <td>4.152100</td>\n    </tr>\n    <tr>\n      <td>66000</td>\n      <td>4.153700</td>\n    </tr>\n    <tr>\n      <td>66500</td>\n      <td>4.174200</td>\n    </tr>\n    <tr>\n      <td>67000</td>\n      <td>4.180600</td>\n    </tr>\n    <tr>\n      <td>67500</td>\n      <td>4.185300</td>\n    </tr>\n    <tr>\n      <td>68000</td>\n      <td>4.169800</td>\n    </tr>\n    <tr>\n      <td>68500</td>\n      <td>4.151200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to ./BR_BERTo-CENTENFolha-8_parts/checkpoint-10000\nConfiguration saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-10000/config.json\nModel weights saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-10000/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./BR_BERTo-CENTENFolha-8_parts/checkpoint-20000\nConfiguration saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-20000/config.json\nModel weights saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-20000/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./BR_BERTo-CENTENFolha-8_parts/checkpoint-30000\nConfiguration saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-30000/config.json\nModel weights saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-30000/pytorch_model.bin\nDeleting older checkpoint [BR_BERTo-CENTENFolha-8_parts/checkpoint-10000] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./BR_BERTo-CENTENFolha-8_parts/checkpoint-40000\nConfiguration saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-40000/config.json\nModel weights saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-40000/pytorch_model.bin\nDeleting older checkpoint [BR_BERTo-CENTENFolha-8_parts/checkpoint-20000] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./BR_BERTo-CENTENFolha-8_parts/checkpoint-50000\nConfiguration saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-50000/config.json\nModel weights saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-50000/pytorch_model.bin\nDeleting older checkpoint [BR_BERTo-CENTENFolha-8_parts/checkpoint-30000] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./BR_BERTo-CENTENFolha-8_parts/checkpoint-60000\nConfiguration saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-60000/config.json\nModel weights saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-60000/pytorch_model.bin\nDeleting older checkpoint [BR_BERTo-CENTENFolha-8_parts/checkpoint-40000] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=68520, training_loss=3.448556746924334, metrics={'train_runtime': 25669.9352, 'train_samples_per_second': 85.408, 'train_steps_per_second': 2.669, 'total_flos': 2.41817448964608e+16, 'train_loss': 3.448556746924334, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 14: Saving the Final Model(+tokenizer + config) to disk\n#trainer.save_model(\"./KantaiBERT\")\ntrainer.save_model('./BR_BERTo-CENTENFolha-8_parts')","metadata":{"id":"xusSgo3unkRI","outputId":"6440dbe7-e4f0-47f0-a2dc-25a6f77ec1da","execution":{"iopub.status.busy":"2022-10-29T00:27:34.316608Z","iopub.execute_input":"2022-10-29T00:27:34.316925Z","iopub.status.idle":"2022-10-29T00:27:36.731669Z","shell.execute_reply.started":"2022-10-29T00:27:34.316893Z","shell.execute_reply":"2022-10-29T00:27:36.730693Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Saving model checkpoint to ./BR_BERTo-CENTENFolha-8_parts\nConfiguration saved in ./BR_BERTo-CENTENFolha-8_parts/config.json\nModel weights saved in ./BR_BERTo-CENTENFolha-8_parts/pytorch_model.bin\n","output_type":"stream"}]},{"cell_type":"code","source":"# Saving model on Wandb\nimport wandb\nwandb.save('BR_BERTo-CENTENFolha-8_parts.h5')","metadata":{"execution":{"iopub.status.busy":"2022-10-29T00:27:36.733169Z","iopub.execute_input":"2022-10-29T00:27:36.733531Z","iopub.status.idle":"2022-10-29T00:27:36.742354Z","shell.execute_reply.started":"2022-10-29T00:27:36.733493Z","shell.execute_reply":"2022-10-29T00:27:36.741317Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 3: Configurando o pipeline fill-mask\n#@title Step 15: Language Modeling with the FillMaskPipeline\nfrom transformers import pipeline\n\nfill_mask = pipeline(\n    \"fill-mask\",\n    model=\"./BR_BERTo-CENTENFolha-8_parts\",\n    tokenizer=tokenizer\n)","metadata":{"id":"pqy7oTgYFb9Y","outputId":"1421ceb4-3690-43e7-82be-02eef10565c0","execution":{"iopub.status.busy":"2022-10-29T00:27:36.743913Z","iopub.execute_input":"2022-10-29T00:27:36.744519Z","iopub.status.idle":"2022-10-29T00:27:40.370378Z","shell.execute_reply.started":"2022-10-29T00:27:36.744483Z","shell.execute_reply":"2022-10-29T00:27:40.369414Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"loading configuration file ./BR_BERTo-CENTENFolha-8_parts/config.json\nModel config RobertaConfig {\n  \"_name_or_path\": \"./BR_BERTo-CENTENFolha-8_parts\",\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 8,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.24.0.dev0\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 150000\n}\n\nloading configuration file ./BR_BERTo-CENTENFolha-8_parts/config.json\nModel config RobertaConfig {\n  \"_name_or_path\": \"./BR_BERTo-CENTENFolha-8_parts\",\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 8,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.24.0.dev0\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 150000\n}\n\nloading weights file ./BR_BERTo-CENTENFolha-8_parts/pytorch_model.bin\nAll model checkpoint weights were used when initializing RobertaForMaskedLM.\n\nAll the weights of RobertaForMaskedLM were initialized from the model checkpoint at ./BR_BERTo-CENTENFolha-8_parts.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForMaskedLM for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"import math\neval_results = trainer.evaluate()\nprint(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")","metadata":{"execution":{"iopub.status.busy":"2022-10-29T00:27:40.372184Z","iopub.execute_input":"2022-10-29T00:27:40.372559Z","iopub.status.idle":"2022-10-29T00:35:44.930477Z","shell.execute_reply.started":"2022-10-29T00:27:40.372521Z","shell.execute_reply":"2022-10-29T00:35:44.929157Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 73252\n  Batch size = 16\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4579' max='4579' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4579/4579 08:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Perplexity: 60.33\n","output_type":"stream"}]},{"cell_type":"code","source":"eval_results","metadata":{"execution":{"iopub.status.busy":"2022-10-29T00:35:44.931823Z","iopub.execute_input":"2022-10-29T00:35:44.935718Z","iopub.status.idle":"2022-10-29T00:35:44.945235Z","shell.execute_reply.started":"2022-10-29T00:35:44.935679Z","shell.execute_reply":"2022-10-29T00:35:44.944211Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 4.099853038787842,\n 'eval_runtime': 484.5416,\n 'eval_samples_per_second': 151.178,\n 'eval_steps_per_second': 9.45,\n 'epoch': 10.0}"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"O rapaz olhou para o <mask> \")","metadata":{"id":"RRrtRPA6GRF8","outputId":"a2c6b7bf-a3f6-4f63-a8b2-f80f5e559773","execution":{"iopub.status.busy":"2022-10-29T00:35:44.949683Z","iopub.execute_input":"2022-10-29T00:35:44.951012Z","iopub.status.idle":"2022-10-29T00:35:45.35194Z","shell.execute_reply.started":"2022-10-29T00:35:44.950976Z","shell.execute_reply":"2022-10-29T00:35:45.35099Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.38669583201408386,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'O rapaz olhou para o  '},\n {'score': 0.24862034618854523,\n  'token': 18,\n  'token_str': '.',\n  'sequence': 'O rapaz olhou para o. '},\n {'score': 0.10848167538642883,\n  'token': 35,\n  'token_str': '?',\n  'sequence': 'O rapaz olhou para o? '},\n {'score': 0.021669907495379448,\n  'token': 5,\n  'token_str': '!',\n  'sequence': 'O rapaz olhou para o! '},\n {'score': 0.010248017497360706,\n  'token': 23430,\n  'token_str': 'Â»',\n  'sequence': 'O rapaz olhou para oÂ» '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"A moÃ§a olhou para o <mask> \")","metadata":{"execution":{"iopub.status.busy":"2022-10-29T00:35:45.353494Z","iopub.execute_input":"2022-10-29T00:35:45.353839Z","iopub.status.idle":"2022-10-29T00:35:45.587235Z","shell.execute_reply.started":"2022-10-29T00:35:45.353801Z","shell.execute_reply":"2022-10-29T00:35:45.586306Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.378112256526947,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'A moÃ§a olhou para o  '},\n {'score': 0.24172565340995789,\n  'token': 18,\n  'token_str': '.',\n  'sequence': 'A moÃ§a olhou para o. '},\n {'score': 0.10514548420906067,\n  'token': 35,\n  'token_str': '?',\n  'sequence': 'A moÃ§a olhou para o? '},\n {'score': 0.01929977536201477,\n  'token': 5,\n  'token_str': '!',\n  'sequence': 'A moÃ§a olhou para o! '},\n {'score': 0.010475827381014824,\n  'token': 23430,\n  'token_str': 'Â»',\n  'sequence': 'A moÃ§a olhou para oÂ» '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Comprou uma <mask> na loja. \")","metadata":{"execution":{"iopub.status.busy":"2022-10-29T00:35:45.588627Z","iopub.execute_input":"2022-10-29T00:35:45.589501Z","iopub.status.idle":"2022-10-29T00:35:45.914959Z","shell.execute_reply.started":"2022-10-29T00:35:45.58946Z","shell.execute_reply":"2022-10-29T00:35:45.913995Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.34191733598709106,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'Comprou uma  na loja. '},\n {'score': 0.08656112104654312,\n  'token': 3404,\n  'token_str': ' loja',\n  'sequence': 'Comprou uma loja na loja. '},\n {'score': 0.025564001873135567,\n  'token': 1933,\n  'token_str': ' foto',\n  'sequence': 'Comprou uma foto na loja. '},\n {'score': 0.02493678219616413,\n  'token': 4194,\n  'token_str': ' peÃ§a',\n  'sequence': 'Comprou uma peÃ§a na loja. '},\n {'score': 0.01081919576972723,\n  'token': 3117,\n  'token_str': ' venda',\n  'sequence': 'Comprou uma venda na loja. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"A mulher nÃ£o Ã© <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-10-29T00:35:45.91653Z","iopub.execute_input":"2022-10-29T00:35:45.917179Z","iopub.status.idle":"2022-10-29T00:35:46.149427Z","shell.execute_reply.started":"2022-10-29T00:35:45.917139Z","shell.execute_reply":"2022-10-29T00:35:46.148405Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.9603817462921143,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'A mulher nÃ£o Ã©. '},\n {'score': 0.015548727475106716,\n  'token': 3639,\n  'token_str': ' Â«',\n  'sequence': 'A mulher nÃ£o Ã© Â«. '},\n {'score': 0.0008894373313523829,\n  'token': 23430,\n  'token_str': 'Â»',\n  'sequence': 'A mulher nÃ£o Ã©Â». '},\n {'score': 0.0007877573953010142,\n  'token': 35,\n  'token_str': '?',\n  'sequence': 'A mulher nÃ£o Ã©?. '},\n {'score': 0.0006621446809731424,\n  'token': 18,\n  'token_str': '.',\n  'sequence': 'A mulher nÃ£o Ã©.. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"O homem nÃ£o Ã© <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-10-29T00:35:46.15112Z","iopub.execute_input":"2022-10-29T00:35:46.151479Z","iopub.status.idle":"2022-10-29T00:35:46.410014Z","shell.execute_reply.started":"2022-10-29T00:35:46.15144Z","shell.execute_reply":"2022-10-29T00:35:46.409014Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.9436227679252625,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'O homem nÃ£o Ã©. '},\n {'score': 0.024407250806689262,\n  'token': 3639,\n  'token_str': ' Â«',\n  'sequence': 'O homem nÃ£o Ã© Â«. '},\n {'score': 0.00109079759567976,\n  'token': 35,\n  'token_str': '?',\n  'sequence': 'O homem nÃ£o Ã©?. '},\n {'score': 0.0010504191741347313,\n  'token': 23430,\n  'token_str': 'Â»',\n  'sequence': 'O homem nÃ£o Ã©Â». '},\n {'score': 0.0010156186763197184,\n  'token': 18,\n  'token_str': '.',\n  'sequence': 'O homem nÃ£o Ã©.. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Ele Ã© um bom <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-10-29T00:35:46.411483Z","iopub.execute_input":"2022-10-29T00:35:46.411801Z","iopub.status.idle":"2022-10-29T00:35:46.689328Z","shell.execute_reply.started":"2022-10-29T00:35:46.411774Z","shell.execute_reply":"2022-10-29T00:35:46.688351Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.9600668549537659,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'Ele Ã© um bom. '},\n {'score': 0.0231776162981987,\n  'token': 3639,\n  'token_str': ' Â«',\n  'sequence': 'Ele Ã© um bom Â«. '},\n {'score': 0.001503376173786819,\n  'token': 23430,\n  'token_str': 'Â»',\n  'sequence': 'Ele Ã© um bomÂ». '},\n {'score': 0.00033725512912496924,\n  'token': 16,\n  'token_str': ',',\n  'sequence': 'Ele Ã© um bom,. '},\n {'score': 0.0003097472945228219,\n  'token': 373,\n  'token_str': ' nÃ£o',\n  'sequence': 'Ele Ã© um bom nÃ£o. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Ela Ã© uma boa <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-10-29T00:35:46.690642Z","iopub.execute_input":"2022-10-29T00:35:46.691091Z","iopub.status.idle":"2022-10-29T00:35:47.023838Z","shell.execute_reply.started":"2022-10-29T00:35:46.691036Z","shell.execute_reply":"2022-10-29T00:35:47.022774Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.9358880519866943,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'Ela Ã© uma boa. '},\n {'score': 0.02805684693157673,\n  'token': 3639,\n  'token_str': ' Â«',\n  'sequence': 'Ela Ã© uma boa Â«. '},\n {'score': 0.0021303596440702677,\n  'token': 1663,\n  'token_str': ' coisa',\n  'sequence': 'Ela Ã© uma boa coisa. '},\n {'score': 0.0019621001556515694,\n  'token': 23430,\n  'token_str': 'Â»',\n  'sequence': 'Ela Ã© uma boaÂ». '},\n {'score': 0.00042498187394812703,\n  'token': 1955,\n  'token_str': ' mÃºsica',\n  'sequence': 'Ela Ã© uma boa mÃºsica. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Faz de conta que ainda Ã© <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-10-29T00:35:47.0282Z","iopub.execute_input":"2022-10-29T00:35:47.030747Z","iopub.status.idle":"2022-10-29T00:35:47.391511Z","shell.execute_reply.started":"2022-10-29T00:35:47.030705Z","shell.execute_reply":"2022-10-29T00:35:47.390263Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.936142086982727,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'Faz de conta que ainda Ã©. '},\n {'score': 0.006818974856287241,\n  'token': 3639,\n  'token_str': ' Â«',\n  'sequence': 'Faz de conta que ainda Ã© Â«. '},\n {'score': 0.0019941481295973063,\n  'token': 1208,\n  'token_str': ' bom',\n  'sequence': 'Faz de conta que ainda Ã© bom. '},\n {'score': 0.0016038106987252831,\n  'token': 373,\n  'token_str': ' nÃ£o',\n  'sequence': 'Faz de conta que ainda Ã© nÃ£o. '},\n {'score': 0.001420637359842658,\n  'token': 1428,\n  'token_str': ' nada',\n  'sequence': 'Faz de conta que ainda Ã© nada. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Depois da tempestade vem a <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-10-29T00:35:47.392851Z","iopub.execute_input":"2022-10-29T00:35:47.39368Z","iopub.status.idle":"2022-10-29T00:35:47.691163Z","shell.execute_reply.started":"2022-10-29T00:35:47.393639Z","shell.execute_reply":"2022-10-29T00:35:47.690292Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.7687026858329773,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'Depois da tempestade vem a. '},\n {'score': 0.01661275327205658,\n  'token': 5244,\n  'token_str': ' chuva',\n  'sequence': 'Depois da tempestade vem a chuva. '},\n {'score': 0.010111875832080841,\n  'token': 3639,\n  'token_str': ' Â«',\n  'sequence': 'Depois da tempestade vem a Â«. '},\n {'score': 0.00932687520980835,\n  'token': 1424,\n  'token_str': ' Ã¡gua',\n  'sequence': 'Depois da tempestade vem a Ã¡gua. '},\n {'score': 0.0041083223186433315,\n  'token': 3656,\n  'token_str': ' temperatura',\n  'sequence': 'Depois da tempestade vem a temperatura. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Mais vale um pÃ¡ssaro na mÃ£o do que <mask> voando. \")","metadata":{"execution":{"iopub.status.busy":"2022-10-29T00:35:47.692522Z","iopub.execute_input":"2022-10-29T00:35:47.692873Z","iopub.status.idle":"2022-10-29T00:35:48.059397Z","shell.execute_reply.started":"2022-10-29T00:35:47.692833Z","shell.execute_reply":"2022-10-29T00:35:48.058415Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.18515491485595703,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'Mais vale um pÃ¡ssaro na mÃ£o do que  voando. '},\n {'score': 0.04191816225647926,\n  'token': 405,\n  'token_str': ' mais',\n  'sequence': 'Mais vale um pÃ¡ssaro na mÃ£o do que mais voando. '},\n {'score': 0.032877855002880096,\n  'token': 603,\n  'token_str': ' estÃ¡',\n  'sequence': 'Mais vale um pÃ¡ssaro na mÃ£o do que estÃ¡ voando. '},\n {'score': 0.029668239876627922,\n  'token': 3639,\n  'token_str': ' Â«',\n  'sequence': 'Mais vale um pÃ¡ssaro na mÃ£o do que Â« voando. '},\n {'score': 0.027036333456635475,\n  'token': 1021,\n  'token_str': ' seja',\n  'sequence': 'Mais vale um pÃ¡ssaro na mÃ£o do que seja voando. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"NÃ£o tinha <mask>, mas almoÃ§ou mesmo assim. \")","metadata":{"execution":{"iopub.status.busy":"2022-10-29T00:35:48.061077Z","iopub.execute_input":"2022-10-29T00:35:48.061476Z","iopub.status.idle":"2022-10-29T00:35:48.392878Z","shell.execute_reply.started":"2022-10-29T00:35:48.061435Z","shell.execute_reply":"2022-10-29T00:35:48.391986Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.10223205387592316,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'NÃ£o tinha, mas almoÃ§ou mesmo assim. '},\n {'score': 0.06879472732543945,\n  'token': 1428,\n  'token_str': ' nada',\n  'sequence': 'NÃ£o tinha nada, mas almoÃ§ou mesmo assim. '},\n {'score': 0.013728772290050983,\n  'token': 702,\n  'token_str': ' isso',\n  'sequence': 'NÃ£o tinha isso, mas almoÃ§ou mesmo assim. '},\n {'score': 0.013108884915709496,\n  'token': 942,\n  'token_str': ' tudo',\n  'sequence': 'NÃ£o tinha tudo, mas almoÃ§ou mesmo assim. '},\n {'score': 0.01261900831013918,\n  'token': 1918,\n  'token_str': ' problema',\n  'sequence': 'NÃ£o tinha problema, mas almoÃ§ou mesmo assim. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Bebeu um copo d'Ã¡gua, pois tinha <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-10-29T00:35:48.394584Z","iopub.execute_input":"2022-10-29T00:35:48.394949Z","iopub.status.idle":"2022-10-29T00:35:48.569292Z","shell.execute_reply.started":"2022-10-29T00:35:48.39491Z","shell.execute_reply":"2022-10-29T00:35:48.568353Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.9809194207191467,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': \"Bebeu um copo d'Ã¡gua, pois tinha. \"},\n {'score': 0.006993266753852367,\n  'token': 3639,\n  'token_str': ' Â«',\n  'sequence': \"Bebeu um copo d'Ã¡gua, pois tinha Â«. \"},\n {'score': 0.0009519975865259767,\n  'token': 23430,\n  'token_str': 'Â»',\n  'sequence': \"Bebeu um copo d'Ã¡gua, pois tinhaÂ». \"},\n {'score': 0.0003567138919606805,\n  'token': 18,\n  'token_str': '.',\n  'sequence': \"Bebeu um copo d'Ã¡gua, pois tinha.. \"},\n {'score': 0.0002893344790209085,\n  'token': 5,\n  'token_str': '!',\n  'sequence': \"Bebeu um copo d'Ã¡gua, pois tinha!. \"}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Sem saber, ele descobriu um <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-10-29T00:35:48.570587Z","iopub.execute_input":"2022-10-29T00:35:48.571362Z","iopub.status.idle":"2022-10-29T00:35:48.87031Z","shell.execute_reply.started":"2022-10-29T00:35:48.571323Z","shell.execute_reply":"2022-10-29T00:35:48.869379Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.862694263458252,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'Sem saber, ele descobriu um. '},\n {'score': 0.029595544561743736,\n  'token': 3639,\n  'token_str': ' Â«',\n  'sequence': 'Sem saber, ele descobriu um Â«. '},\n {'score': 0.006179000250995159,\n  'token': 1139,\n  'token_str': ' outro',\n  'sequence': 'Sem saber, ele descobriu um outro. '},\n {'score': 0.0057591102086007595,\n  'token': 1449,\n  'token_str': ' tipo',\n  'sequence': 'Sem saber, ele descobriu um tipo. '},\n {'score': 0.002536940388381481,\n  'token': 1309,\n  'token_str': ' pouco',\n  'sequence': 'Sem saber, ele descobriu um pouco. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Pedro fez fortuna vendendo <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-10-29T00:35:48.87163Z","iopub.execute_input":"2022-10-29T00:35:48.872242Z","iopub.status.idle":"2022-10-29T00:35:49.14617Z","shell.execute_reply.started":"2022-10-29T00:35:48.872204Z","shell.execute_reply":"2022-10-29T00:35:49.14529Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.9651967287063599,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'Pedro fez fortuna vendendo. '},\n {'score': 0.010250731371343136,\n  'token': 3639,\n  'token_str': ' Â«',\n  'sequence': 'Pedro fez fortuna vendendo Â«. '},\n {'score': 0.003451635129749775,\n  'token': 23430,\n  'token_str': 'Â»',\n  'sequence': 'Pedro fez fortuna vendendoÂ». '},\n {'score': 0.000461291492683813,\n  'token': 17,\n  'token_str': '-',\n  'sequence': 'Pedro fez fortuna vendendo-. '},\n {'score': 0.0004227626195643097,\n  'token': 16,\n  'token_str': ',',\n  'sequence': 'Pedro fez fortuna vendendo,. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Sem medo de ser <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-10-29T00:35:49.147668Z","iopub.execute_input":"2022-10-29T00:35:49.148031Z","iopub.status.idle":"2022-10-29T00:35:49.433203Z","shell.execute_reply.started":"2022-10-29T00:35:49.147992Z","shell.execute_reply":"2022-10-29T00:35:49.432293Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.9583428502082825,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'Sem medo de ser. '},\n {'score': 0.006450172979384661,\n  'token': 3639,\n  'token_str': ' Â«',\n  'sequence': 'Sem medo de ser Â«. '},\n {'score': 0.0016045953379943967,\n  'token': 315,\n  'token_str': ' um',\n  'sequence': 'Sem medo de ser um. '},\n {'score': 0.0010848623933270574,\n  'token': 268,\n  'token_str': ' de',\n  'sequence': 'Sem medo de ser de. '},\n {'score': 0.0006845065508969128,\n  'token': 1208,\n  'token_str': ' bom',\n  'sequence': 'Sem medo de ser bom. '}]"},"metadata":{}}]}]}