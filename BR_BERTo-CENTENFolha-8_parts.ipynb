{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/marianameyerf/notebook40af724143?scriptVersionId=110443342\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/jsansao/transformers_pt/blob/main/BR_BERTo_Fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"# InferÃªncia usando transformers prÃ©-treinados do HuggingFace ","metadata":{"id":"hV_s2jhFIGRV"}},{"cell_type":"markdown","source":"BR_BERTo\n\nCENTENFolha - 8 partes\n\nBatch size = 16\n\nGPU T4x2\n\n(07h:21m)","metadata":{}},{"cell_type":"code","source":"#@title Passo 1:Instalando Hugging Face Transformers\n# We won't need TensorFlow here\n!pip uninstall -y tensorflow\n# Install `transformers` from master\n!pip install git+https://github.com/huggingface/transformers\n!pip list | grep -E 'transformers|tokenizers'\n# transformers version at notebook update --- 2.9.1\n# tokenizers version at notebook update --- 0.7.0","metadata":{"id":"LhI1tJBGBd3r","outputId":"7b6abfac-a01a-4cf0-85a5-7fa6a55e20db","execution":{"iopub.status.busy":"2022-11-08T14:44:04.217109Z","iopub.execute_input":"2022-11-08T14:44:04.217853Z","iopub.status.idle":"2022-11-08T14:45:12.682198Z","shell.execute_reply.started":"2022-11-08T14:44:04.217815Z","shell.execute_reply":"2022-11-08T14:45:12.680951Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found existing installation: tensorflow 2.6.4\nUninstalling tensorflow-2.6.4:\n  Successfully uninstalled tensorflow-2.6.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting git+https://github.com/huggingface/transformers\n  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-4irw07di\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-4irw07di\n  Resolved https://github.com/huggingface/transformers to commit 258963062bc09bb412dbbdbb777632b4057a1556\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.25.0.dev0) (0.12.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.25.0.dev0) (2.28.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.25.0.dev0) (4.64.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.25.0.dev0) (4.13.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.25.0.dev0) (2021.11.10)\nRequirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.25.0.dev0) (0.10.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.25.0.dev0) (1.21.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.25.0.dev0) (3.7.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.25.0.dev0) (6.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.25.0.dev0) (21.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.0.dev0) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers==4.25.0.dev0) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.25.0.dev0) (3.8.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.25.0.dev0) (2022.9.24)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.25.0.dev0) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.25.0.dev0) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.25.0.dev0) (1.26.12)\nBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers: filename=transformers-4.25.0.dev0-py3-none-any.whl size=5554323 sha256=f39225b73f0030b1a38a1ca2769a852ddc7572feac93738b22f3bf0c56cb54b5\n  Stored in directory: /tmp/pip-ephem-wheel-cache-3hfcy0yu/wheels/35/2e/a7/d819e3310040329f0f47e57c9e3e7a7338aa5e74c49acfe522\nSuccessfully built transformers\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.20.1\n    Uninstalling transformers-4.20.1:\n      Successfully uninstalled transformers-4.20.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nallennlp 2.10.1 requires transformers<4.21,>=4.1, but you have transformers 4.25.0.dev0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed transformers-4.25.0.dev0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mtokenizers                            0.12.1\ntransformers                          4.25.0.dev0\n","output_type":"stream"}]},{"cell_type":"code","source":"#@title Step 1: Loading the Dataset\n#1.Load kant.txt using the Colab file manager\n#2.Downloading the file from GitHub\n#!curl -L  https://raw.githubusercontent.com/jsansao/corpus_ptbr/main/dump_Machado_Nobreak.txt --output \"dump.txt\"\n!curl -L https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_aa --output \"dump.txt\"\n#!curl -L https://raw.githubusercontent.com/jsansao/corpus_ptbr/main/Lyrics_ChicoBuarque.txt --output \"kant.txt\"\n\n!awk NF < dump.txt > kant.txt","metadata":{"id":"KAl5BxxOgk35","outputId":"56349dd7-aa74-4896-c8c2-11223ee35227","execution":{"iopub.status.busy":"2022-11-08T14:45:12.685261Z","iopub.execute_input":"2022-11-08T14:45:12.686125Z","iopub.status.idle":"2022-11-08T14:45:15.343536Z","shell.execute_reply.started":"2022-11-08T14:45:12.686084Z","shell.execute_reply":"2022-11-08T14:45:15.342289Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 3724k  100 3724k    0     0  7419k      0 --:--:-- --:--:-- --:--:-- 7404k\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_aa \n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ab\n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ac\n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ad\n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ae \n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_af\n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ag\n!wget https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ah","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:45:15.345961Z","iopub.execute_input":"2022-11-08T14:45:15.34682Z","iopub.status.idle":"2022-11-08T14:45:27.16753Z","shell.execute_reply.started":"2022-11-08T14:45:15.346778Z","shell.execute_reply":"2022-11-08T14:45:27.166346Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"--2022-11-08 14:45:16--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_aa\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: â€˜cetenfolha_aa.12â€™\n\ncetenfolha_aa.12    100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-11-08 14:45:16 (53.2 MB/s) - â€˜cetenfolha_aa.12â€™ saved [3813899/3813899]\n\n--2022-11-08 14:45:17--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ab\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: â€˜cetenfolha_ab.12â€™\n\ncetenfolha_ab.12    100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-11-08 14:45:18 (52.6 MB/s) - â€˜cetenfolha_ab.12â€™ saved [3813899/3813899]\n\n--2022-11-08 14:45:18--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ac\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: â€˜cetenfolha_ac.12â€™\n\ncetenfolha_ac.12    100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-11-08 14:45:19 (53.0 MB/s) - â€˜cetenfolha_ac.12â€™ saved [3813899/3813899]\n\n--2022-11-08 14:45:20--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ad\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: â€˜cetenfolha_ad.12â€™\n\ncetenfolha_ad.12    100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-11-08 14:45:20 (54.1 MB/s) - â€˜cetenfolha_ad.12â€™ saved [3813899/3813899]\n\n--2022-11-08 14:45:21--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ae\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: â€˜cetenfolha_ae.12â€™\n\ncetenfolha_ae.12    100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-11-08 14:45:22 (52.2 MB/s) - â€˜cetenfolha_ae.12â€™ saved [3813899/3813899]\n\n--2022-11-08 14:45:23--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_af\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: â€˜cetenfolha_af.12â€™\n\ncetenfolha_af.12    100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-11-08 14:45:24 (52.1 MB/s) - â€˜cetenfolha_af.12â€™ saved [3813899/3813899]\n\n--2022-11-08 14:45:25--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ag\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: â€˜cetenfolha_ag.12â€™\n\ncetenfolha_ag.12    100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-11-08 14:45:25 (54.9 MB/s) - â€˜cetenfolha_ag.12â€™ saved [3813899/3813899]\n\n--2022-11-08 14:45:26--  https://raw.githubusercontent.com/marianameyer/corpus_ptbr/main/cetenfolha_ah\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3813899 (3.6M) [text/plain]\nSaving to: â€˜cetenfolha_ah.11â€™\n\ncetenfolha_ah.11    100%[===================>]   3.64M  --.-KB/s    in 0.07s   \n\n2022-11-08 14:45:27 (55.5 MB/s) - â€˜cetenfolha_ah.11â€™ saved [3813899/3813899]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!cat cetenfolha_aa cetenfolha_ab cetenfolha_ac cetenfolha_ad cetenfolha_ae cetenfolha_af cetenfolha_ag cetenfolha_ah>  dump.txt\n!awk NF < dump.txt > kant.txt","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:45:27.170437Z","iopub.execute_input":"2022-11-08T14:45:27.171094Z","iopub.status.idle":"2022-11-08T14:45:29.779644Z","shell.execute_reply.started":"2022-11-08T14:45:27.171053Z","shell.execute_reply":"2022-11-08T14:45:29.778254Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#@title Passo 2:Baixando e salvando BR_BERTo\n#https://huggingface.co/rdenadai/BR_BERTo\n\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"rdenadai/BR_BERTo\")\nmodel = AutoModelForMaskedLM.from_pretrained(\"rdenadai/BR_BERTo\")","metadata":{"id":"h2L_Put8Cn8S","outputId":"7a1f401d-e360-4973-cc95-9f16a6f5bcbd","execution":{"iopub.status.busy":"2022-11-08T14:45:29.782721Z","iopub.execute_input":"2022-11-08T14:45:29.783189Z","iopub.status.idle":"2022-11-08T14:46:08.069234Z","shell.execute_reply.started":"2022-11-08T14:45:29.78313Z","shell.execute_reply":"2022-11-08T14:46:08.068007Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/516 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a6bdd7b46f04ba5b44ee3b986fccc39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.77M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a88d8d1764a4e3d894642e0fb4c69b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.68M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ba0bad2364041748ed853be5d1ad68e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/695M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77305df6a9c449a1b2784b7ba5b554e9"}},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset\n#datasets = load_dataset(\"text\", data_files={\"train\": \"kant.txt\", \"validation\": \"kant_teste.txt\"})\n#datasets = load_dataset(\"text\", data_files={\"train\": \"kant.txt\"}, split='train[:90%]')\nds = load_dataset(\"text\", data_files={\"train\": \"kant.txt\"})\n\ndatasets = ds[\"train\"].train_test_split()","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:46:08.071343Z","iopub.execute_input":"2022-11-08T14:46:08.072427Z","iopub.status.idle":"2022-11-08T14:46:09.441893Z","shell.execute_reply.started":"2022-11-08T14:46:08.072384Z","shell.execute_reply":"2022-11-08T14:46:09.440868Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-e454ccb8a36a9604/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1263eb6a22d14f46918920f1919e9758"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5536a223bb948e3837db549343840d1"}},"metadata":{}},{"name":"stdout","text":"Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-e454ccb8a36a9604/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c0d05ec48b84b07b71f0dd40364f912"}},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 10: Building the Dataset\nfrom transformers import LineByLineTextDataset\n\ndataset = LineByLineTextDataset(\n    tokenizer=tokenizer,\n    file_path=\"./kant.txt\",\n    block_size=32,\n)","metadata":{"id":"ZyWFU4dNhjtI","outputId":"b926c17c-bfff-4320-91b7-ba06dcebdf9e","execution":{"iopub.status.busy":"2022-11-08T14:46:09.443256Z","iopub.execute_input":"2022-11-08T14:46:09.445598Z","iopub.status.idle":"2022-11-08T14:46:39.101662Z","shell.execute_reply.started":"2022-11-08T14:46:09.445567Z","shell.execute_reply":"2022-11-08T14:46:39.100562Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/data/datasets/language_modeling.py:125: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(examples[\"text\"])","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:46:39.103565Z","iopub.execute_input":"2022-11-08T14:46:39.104004Z","iopub.status.idle":"2022-11-08T14:46:39.109502Z","shell.execute_reply.started":"2022-11-08T14:46:39.103954Z","shell.execute_reply":"2022-11-08T14:46:39.108285Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:46:39.111537Z","iopub.execute_input":"2022-11-08T14:46:39.112357Z","iopub.status.idle":"2022-11-08T14:47:16.651024Z","shell.execute_reply.started":"2022-11-08T14:46:39.112317Z","shell.execute_reply":"2022-11-08T14:47:16.649775Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"        ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7957673cb7c46d0ab22d21f02c9426d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97b9e05eca514d9b810010e59fb725c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d47baf93e034c90a8a63127d354211e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88c7c7eca2ee4995ab9e3cf120c0d153"}},"metadata":{}},{"name":"stdout","text":"       ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae68f3977c254d5da1c1745a9e28e567"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cdde744ad974dd8a81ce254a2d0364d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6c42440696c40c2b67b4727daba93e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0f739b92e56406f85c2d34deb5ec287"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets[\"train\"][4]","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:47:16.6566Z","iopub.execute_input":"2022-11-08T14:47:16.656936Z","iopub.status.idle":"2022-11-08T14:47:16.668905Z","shell.execute_reply.started":"2022-11-08T14:47:16.656906Z","shell.execute_reply":"2022-11-08T14:47:16.667883Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [0,\n  225,\n  51,\n  1479,\n  321,\n  225,\n  39,\n  83,\n  1264,\n  357,\n  1050,\n  57714,\n  560,\n  13220,\n  1199,\n  355,\n  1473,\n  268,\n  3976,\n  225,\n  12,\n  5914,\n  21628,\n  16,\n  10865,\n  425,\n  9250,\n  13,\n  268,\n  806,\n  301,\n  5600,\n  268,\n  2601,\n  2166,\n  920,\n  2771,\n  328,\n  1356,\n  439,\n  695,\n  734,\n  16,\n  318,\n  683,\n  268,\n  5237,\n  495,\n  683,\n  16,\n  301,\n  346,\n  276,\n  301,\n  1560,\n  328,\n  1356,\n  4476,\n  225,\n  18,\n  225,\n  2],\n 'attention_mask': [1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1]}"},"metadata":{}}]},{"cell_type":"code","source":"#block_size = tokenizer.model_max_length\nblock_size = 32","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:47:16.67047Z","iopub.execute_input":"2022-11-08T14:47:16.671607Z","iopub.status.idle":"2022-11-08T14:47:16.705575Z","shell.execute_reply.started":"2022-11-08T14:47:16.671568Z","shell.execute_reply":"2022-11-08T14:47:16.704567Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def group_texts(examples):\n    # Concatenate all texts.\n    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n    total_length = len(concatenated_examples[list(examples.keys())[0]])\n    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n        # customize this part to your needs.\n    total_length = (total_length // block_size) * block_size\n    # Split by chunks of max_len.\n    result = {\n        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n        for k, t in concatenated_examples.items()\n    }\n    result[\"labels\"] = result[\"input_ids\"].copy()\n    return result","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:47:16.70878Z","iopub.execute_input":"2022-11-08T14:47:16.710898Z","iopub.status.idle":"2022-11-08T14:47:16.71848Z","shell.execute_reply.started":"2022-11-08T14:47:16.709352Z","shell.execute_reply":"2022-11-08T14:47:16.717319Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"lm_datasets = tokenized_datasets.map(\n    group_texts,\n    batched=True,\n    batch_size=1000,\n    num_proc=4,\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:47:16.720049Z","iopub.execute_input":"2022-11-08T14:47:16.720547Z","iopub.status.idle":"2022-11-08T14:48:05.763045Z","shell.execute_reply.started":"2022-11-08T14:47:16.720501Z","shell.execute_reply":"2022-11-08T14:48:05.761879Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"     ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbdf3c3fa1924d859efe1c7e5a3594ba"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a050d76120d94504b3d1c6230d45a155"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b82bda222b44e34ad5e909cf137f128"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/60 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15b71219813f418891c9d704e540646b"}},"metadata":{}},{"name":"stdout","text":"     ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be58109042e644db8fa8ae23eb6a708e"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"786c5db386cd45e9b358e9717bdd6672"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64faf17dd7ad46279e147990906bc89c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a432441513814a27bfb58dcd61811099"}},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 11: Defining a Data Collator\nfrom transformers import DataCollatorForLanguageModeling\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n)","metadata":{"id":"19hRhnHFf7FF","execution":{"iopub.status.busy":"2022-11-08T14:48:05.765432Z","iopub.execute_input":"2022-11-08T14:48:05.765838Z","iopub.status.idle":"2022-11-08T14:48:05.772715Z","shell.execute_reply.started":"2022-11-08T14:48:05.765797Z","shell.execute_reply":"2022-11-08T14:48:05.771423Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric\n\nmetric = load_metric(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return {metric.compute(predictions=predictions, references=labels)}","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:48:05.774344Z","iopub.execute_input":"2022-11-08T14:48:05.775007Z","iopub.status.idle":"2022-11-08T14:48:06.350477Z","shell.execute_reply.started":"2022-11-08T14:48:05.774971Z","shell.execute_reply":"2022-11-08T14:48:06.349553Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.41k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"297c39e326504fc193b27771c1762b64"}},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 12: Initializing the Trainer\nfrom transformers import Trainer, TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./BR_BERTo-CENTENFolha-8_parts\",\n    overwrite_output_dir=True,\n    num_train_epochs=10,\n    per_device_train_batch_size=16,\n    save_steps=10_000,\n    save_total_limit=2,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=lm_datasets[\"train\"],\n    eval_dataset=lm_datasets[\"test\"],\n)","metadata":{"id":"MH2dsTzhfgqI","execution":{"iopub.status.busy":"2022-11-08T14:48:06.352252Z","iopub.execute_input":"2022-11-08T14:48:06.352637Z","iopub.status.idle":"2022-11-08T14:48:10.686081Z","shell.execute_reply.started":"2022-11-08T14:48:06.3526Z","shell.execute_reply":"2022-11-08T14:48:10.684623Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#@title Step 13: Pre-training the Model\ntrainer.train()","metadata":{"id":"EZxksqadfv6l","outputId":"b4f753c3-de85-40f9-84ae-5e3fb08a6283","execution":{"iopub.status.busy":"2022-11-08T14:48:10.687709Z","iopub.execute_input":"2022-11-08T14:48:10.688695Z","iopub.status.idle":"2022-11-08T21:51:51.680215Z","shell.execute_reply.started":"2022-11-08T14:48:10.688648Z","shell.execute_reply":"2022-11-08T21:51:51.679306Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 219622\n  Num Epochs = 10\n  Instantaneous batch size per device = 16\n  Total train batch size (w. parallel, distributed & accumulation) = 32\n  Gradient Accumulation steps = 1\n  Total optimization steps = 68640\n  Number of trainable parameters = 173042160\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20221108_144820-1d5ymncq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/tccii/huggingface/runs/1d5ymncq\" target=\"_blank\">./BR_BERTo-CENTENFolha-8_parts</a></strong> to <a href=\"https://wandb.ai/tccii/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"name":"stderr","text":"You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='68640' max='68640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [68640/68640 7:03:18, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>4.335200</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>3.845400</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>3.699900</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>3.483400</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>3.333500</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>3.260100</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>3.191800</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>3.127000</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>3.108600</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>3.060500</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>2.998400</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>2.972100</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>2.918200</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>2.894600</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>2.825900</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>2.825500</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>2.785800</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>2.763800</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>2.762700</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>2.748700</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>2.732800</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>2.696600</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>2.679000</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>2.700500</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>2.666900</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>2.646600</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>2.627300</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>2.578500</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>2.583800</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>2.571600</td>\n    </tr>\n    <tr>\n      <td>15500</td>\n      <td>2.547500</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>2.549400</td>\n    </tr>\n    <tr>\n      <td>16500</td>\n      <td>2.561200</td>\n    </tr>\n    <tr>\n      <td>17000</td>\n      <td>2.565700</td>\n    </tr>\n    <tr>\n      <td>17500</td>\n      <td>3.149300</td>\n    </tr>\n    <tr>\n      <td>18000</td>\n      <td>2.550200</td>\n    </tr>\n    <tr>\n      <td>18500</td>\n      <td>2.498300</td>\n    </tr>\n    <tr>\n      <td>19000</td>\n      <td>2.489500</td>\n    </tr>\n    <tr>\n      <td>19500</td>\n      <td>2.517200</td>\n    </tr>\n    <tr>\n      <td>20000</td>\n      <td>2.489700</td>\n    </tr>\n    <tr>\n      <td>20500</td>\n      <td>2.494300</td>\n    </tr>\n    <tr>\n      <td>21000</td>\n      <td>2.431900</td>\n    </tr>\n    <tr>\n      <td>21500</td>\n      <td>2.440800</td>\n    </tr>\n    <tr>\n      <td>22000</td>\n      <td>2.439100</td>\n    </tr>\n    <tr>\n      <td>22500</td>\n      <td>2.447800</td>\n    </tr>\n    <tr>\n      <td>23000</td>\n      <td>2.426000</td>\n    </tr>\n    <tr>\n      <td>23500</td>\n      <td>2.431800</td>\n    </tr>\n    <tr>\n      <td>24000</td>\n      <td>2.411600</td>\n    </tr>\n    <tr>\n      <td>24500</td>\n      <td>2.410700</td>\n    </tr>\n    <tr>\n      <td>25000</td>\n      <td>2.431300</td>\n    </tr>\n    <tr>\n      <td>25500</td>\n      <td>2.413000</td>\n    </tr>\n    <tr>\n      <td>26000</td>\n      <td>2.403000</td>\n    </tr>\n    <tr>\n      <td>26500</td>\n      <td>2.396500</td>\n    </tr>\n    <tr>\n      <td>27000</td>\n      <td>2.402100</td>\n    </tr>\n    <tr>\n      <td>27500</td>\n      <td>2.368900</td>\n    </tr>\n    <tr>\n      <td>28000</td>\n      <td>2.370100</td>\n    </tr>\n    <tr>\n      <td>28500</td>\n      <td>2.356700</td>\n    </tr>\n    <tr>\n      <td>29000</td>\n      <td>2.368100</td>\n    </tr>\n    <tr>\n      <td>29500</td>\n      <td>2.342500</td>\n    </tr>\n    <tr>\n      <td>30000</td>\n      <td>2.333000</td>\n    </tr>\n    <tr>\n      <td>30500</td>\n      <td>2.335900</td>\n    </tr>\n    <tr>\n      <td>31000</td>\n      <td>2.343800</td>\n    </tr>\n    <tr>\n      <td>31500</td>\n      <td>2.337900</td>\n    </tr>\n    <tr>\n      <td>32000</td>\n      <td>2.313500</td>\n    </tr>\n    <tr>\n      <td>32500</td>\n      <td>2.309100</td>\n    </tr>\n    <tr>\n      <td>33000</td>\n      <td>2.308100</td>\n    </tr>\n    <tr>\n      <td>33500</td>\n      <td>2.320900</td>\n    </tr>\n    <tr>\n      <td>34000</td>\n      <td>2.290600</td>\n    </tr>\n    <tr>\n      <td>34500</td>\n      <td>2.302200</td>\n    </tr>\n    <tr>\n      <td>35000</td>\n      <td>2.277600</td>\n    </tr>\n    <tr>\n      <td>35500</td>\n      <td>2.270000</td>\n    </tr>\n    <tr>\n      <td>36000</td>\n      <td>2.245300</td>\n    </tr>\n    <tr>\n      <td>36500</td>\n      <td>2.271800</td>\n    </tr>\n    <tr>\n      <td>37000</td>\n      <td>2.274300</td>\n    </tr>\n    <tr>\n      <td>37500</td>\n      <td>2.243600</td>\n    </tr>\n    <tr>\n      <td>38000</td>\n      <td>2.252700</td>\n    </tr>\n    <tr>\n      <td>38500</td>\n      <td>2.262100</td>\n    </tr>\n    <tr>\n      <td>39000</td>\n      <td>2.284600</td>\n    </tr>\n    <tr>\n      <td>39500</td>\n      <td>2.259200</td>\n    </tr>\n    <tr>\n      <td>40000</td>\n      <td>2.267900</td>\n    </tr>\n    <tr>\n      <td>40500</td>\n      <td>2.216400</td>\n    </tr>\n    <tr>\n      <td>41000</td>\n      <td>2.231500</td>\n    </tr>\n    <tr>\n      <td>41500</td>\n      <td>2.213600</td>\n    </tr>\n    <tr>\n      <td>42000</td>\n      <td>2.188100</td>\n    </tr>\n    <tr>\n      <td>42500</td>\n      <td>2.193000</td>\n    </tr>\n    <tr>\n      <td>43000</td>\n      <td>2.211000</td>\n    </tr>\n    <tr>\n      <td>43500</td>\n      <td>2.189600</td>\n    </tr>\n    <tr>\n      <td>44000</td>\n      <td>2.208700</td>\n    </tr>\n    <tr>\n      <td>44500</td>\n      <td>2.210100</td>\n    </tr>\n    <tr>\n      <td>45000</td>\n      <td>2.175400</td>\n    </tr>\n    <tr>\n      <td>45500</td>\n      <td>2.201300</td>\n    </tr>\n    <tr>\n      <td>46000</td>\n      <td>2.221500</td>\n    </tr>\n    <tr>\n      <td>46500</td>\n      <td>2.215100</td>\n    </tr>\n    <tr>\n      <td>47000</td>\n      <td>2.199000</td>\n    </tr>\n    <tr>\n      <td>47500</td>\n      <td>2.183200</td>\n    </tr>\n    <tr>\n      <td>48000</td>\n      <td>2.207800</td>\n    </tr>\n    <tr>\n      <td>48500</td>\n      <td>2.193900</td>\n    </tr>\n    <tr>\n      <td>49000</td>\n      <td>2.176500</td>\n    </tr>\n    <tr>\n      <td>49500</td>\n      <td>2.181400</td>\n    </tr>\n    <tr>\n      <td>50000</td>\n      <td>2.177700</td>\n    </tr>\n    <tr>\n      <td>50500</td>\n      <td>2.154100</td>\n    </tr>\n    <tr>\n      <td>51000</td>\n      <td>2.183200</td>\n    </tr>\n    <tr>\n      <td>51500</td>\n      <td>2.178700</td>\n    </tr>\n    <tr>\n      <td>52000</td>\n      <td>2.183900</td>\n    </tr>\n    <tr>\n      <td>52500</td>\n      <td>2.150400</td>\n    </tr>\n    <tr>\n      <td>53000</td>\n      <td>2.161400</td>\n    </tr>\n    <tr>\n      <td>53500</td>\n      <td>2.171700</td>\n    </tr>\n    <tr>\n      <td>54000</td>\n      <td>2.168500</td>\n    </tr>\n    <tr>\n      <td>54500</td>\n      <td>2.150300</td>\n    </tr>\n    <tr>\n      <td>55000</td>\n      <td>2.160400</td>\n    </tr>\n    <tr>\n      <td>55500</td>\n      <td>2.123200</td>\n    </tr>\n    <tr>\n      <td>56000</td>\n      <td>2.097900</td>\n    </tr>\n    <tr>\n      <td>56500</td>\n      <td>2.121000</td>\n    </tr>\n    <tr>\n      <td>57000</td>\n      <td>2.123700</td>\n    </tr>\n    <tr>\n      <td>57500</td>\n      <td>2.119600</td>\n    </tr>\n    <tr>\n      <td>58000</td>\n      <td>2.103900</td>\n    </tr>\n    <tr>\n      <td>58500</td>\n      <td>2.129100</td>\n    </tr>\n    <tr>\n      <td>59000</td>\n      <td>2.102400</td>\n    </tr>\n    <tr>\n      <td>59500</td>\n      <td>2.124000</td>\n    </tr>\n    <tr>\n      <td>60000</td>\n      <td>2.121500</td>\n    </tr>\n    <tr>\n      <td>60500</td>\n      <td>2.101200</td>\n    </tr>\n    <tr>\n      <td>61000</td>\n      <td>2.123900</td>\n    </tr>\n    <tr>\n      <td>61500</td>\n      <td>2.108500</td>\n    </tr>\n    <tr>\n      <td>62000</td>\n      <td>2.102700</td>\n    </tr>\n    <tr>\n      <td>62500</td>\n      <td>2.091500</td>\n    </tr>\n    <tr>\n      <td>63000</td>\n      <td>2.088700</td>\n    </tr>\n    <tr>\n      <td>63500</td>\n      <td>2.107800</td>\n    </tr>\n    <tr>\n      <td>64000</td>\n      <td>2.109100</td>\n    </tr>\n    <tr>\n      <td>64500</td>\n      <td>2.077800</td>\n    </tr>\n    <tr>\n      <td>65000</td>\n      <td>2.096600</td>\n    </tr>\n    <tr>\n      <td>65500</td>\n      <td>2.079800</td>\n    </tr>\n    <tr>\n      <td>66000</td>\n      <td>2.111900</td>\n    </tr>\n    <tr>\n      <td>66500</td>\n      <td>2.093900</td>\n    </tr>\n    <tr>\n      <td>67000</td>\n      <td>2.101100</td>\n    </tr>\n    <tr>\n      <td>67500</td>\n      <td>2.083900</td>\n    </tr>\n    <tr>\n      <td>68000</td>\n      <td>2.092800</td>\n    </tr>\n    <tr>\n      <td>68500</td>\n      <td>2.104300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to ./BR_BERTo-CENTENFolha-8_parts/checkpoint-10000\nConfiguration saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-10000/config.json\nModel weights saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-10000/pytorch_model.bin\nDeleting older checkpoint [BR_BERTo-CENTENFolha-8_parts/checkpoint-60000] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./BR_BERTo-CENTENFolha-8_parts/checkpoint-20000\nConfiguration saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-20000/config.json\nModel weights saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-20000/pytorch_model.bin\nDeleting older checkpoint [BR_BERTo-CENTENFolha-8_parts/checkpoint-50000] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./BR_BERTo-CENTENFolha-8_parts/checkpoint-30000\nConfiguration saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-30000/config.json\nModel weights saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-30000/pytorch_model.bin\nDeleting older checkpoint [BR_BERTo-CENTENFolha-8_parts/checkpoint-10000] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./BR_BERTo-CENTENFolha-8_parts/checkpoint-40000\nConfiguration saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-40000/config.json\nModel weights saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-40000/pytorch_model.bin\nDeleting older checkpoint [BR_BERTo-CENTENFolha-8_parts/checkpoint-20000] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to ./BR_BERTo-CENTENFolha-8_parts/checkpoint-50000\nConfiguration saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-50000/config.json\nModel weights saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-50000/pytorch_model.bin\nDeleting older checkpoint [BR_BERTo-CENTENFolha-8_parts/checkpoint-30000] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nwandb: Network error (ReadTimeout), entering retry loop.\nSaving model checkpoint to ./BR_BERTo-CENTENFolha-8_parts/checkpoint-60000\nConfiguration saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-60000/config.json\nModel weights saved in ./BR_BERTo-CENTENFolha-8_parts/checkpoint-60000/pytorch_model.bin\nDeleting older checkpoint [BR_BERTo-CENTENFolha-8_parts/checkpoint-40000] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=68640, training_loss=2.420741958884926, metrics={'train_runtime': 25420.9365, 'train_samples_per_second': 86.394, 'train_steps_per_second': 2.7, 'total_flos': 2.42237682625536e+16, 'train_loss': 2.420741958884926, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 14: Saving the Final Model(+tokenizer + config) to disk\n#trainer.save_model(\"./KantaiBERT\")\ntrainer.save_model('./BR_BERTo-CENTENFolha-8_parts')","metadata":{"id":"xusSgo3unkRI","outputId":"6440dbe7-e4f0-47f0-a2dc-25a6f77ec1da","execution":{"iopub.status.busy":"2022-11-08T21:51:51.681398Z","iopub.execute_input":"2022-11-08T21:51:51.681989Z","iopub.status.idle":"2022-11-08T21:51:54.087425Z","shell.execute_reply.started":"2022-11-08T21:51:51.68195Z","shell.execute_reply":"2022-11-08T21:51:54.08637Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Saving model checkpoint to ./BR_BERTo-CENTENFolha-8_parts\nConfiguration saved in ./BR_BERTo-CENTENFolha-8_parts/config.json\nModel weights saved in ./BR_BERTo-CENTENFolha-8_parts/pytorch_model.bin\n","output_type":"stream"}]},{"cell_type":"code","source":"# Saving model on Wandb\nimport wandb\nwandb.save('BR_BERTo-CENTENFolha-8_parts.h5')","metadata":{"execution":{"iopub.status.busy":"2022-11-08T21:51:54.089132Z","iopub.execute_input":"2022-11-08T21:51:54.089519Z","iopub.status.idle":"2022-11-08T21:51:54.105762Z","shell.execute_reply.started":"2022-11-08T21:51:54.089483Z","shell.execute_reply":"2022-11-08T21:51:54.103027Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"code","source":"#@title Step 3: Configurando o pipeline fill-mask\n#@title Step 15: Language Modeling with the FillMaskPipeline\nfrom transformers import pipeline\n\nfill_mask = pipeline(\n    \"fill-mask\",\n    model=\"./BR_BERTo-CENTENFolha-8_parts\",\n    tokenizer=tokenizer\n)","metadata":{"id":"pqy7oTgYFb9Y","outputId":"1421ceb4-3690-43e7-82be-02eef10565c0","execution":{"iopub.status.busy":"2022-11-08T21:51:54.10791Z","iopub.execute_input":"2022-11-08T21:51:54.109604Z","iopub.status.idle":"2022-11-08T21:51:57.721552Z","shell.execute_reply.started":"2022-11-08T21:51:54.109556Z","shell.execute_reply":"2022-11-08T21:51:57.720558Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"loading configuration file ./BR_BERTo-CENTENFolha-8_parts/config.json\nModel config RobertaConfig {\n  \"_name_or_path\": \"./BR_BERTo-CENTENFolha-8_parts\",\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 8,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.25.0.dev0\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 150000\n}\n\nloading configuration file ./BR_BERTo-CENTENFolha-8_parts/config.json\nModel config RobertaConfig {\n  \"_name_or_path\": \"./BR_BERTo-CENTENFolha-8_parts\",\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 8,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.25.0.dev0\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 150000\n}\n\nloading weights file ./BR_BERTo-CENTENFolha-8_parts/pytorch_model.bin\nAll model checkpoint weights were used when initializing RobertaForMaskedLM.\n\nAll the weights of RobertaForMaskedLM were initialized from the model checkpoint at ./BR_BERTo-CENTENFolha-8_parts.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForMaskedLM for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"import math\neval_results = trainer.evaluate()\nprint(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")","metadata":{"execution":{"iopub.status.busy":"2022-11-08T21:51:57.723128Z","iopub.execute_input":"2022-11-08T21:51:57.723753Z","iopub.status.idle":"2022-11-08T21:59:52.287925Z","shell.execute_reply.started":"2022-11-08T21:51:57.723712Z","shell.execute_reply":"2022-11-08T21:59:52.279448Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 72871\n  Batch size = 16\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4555' max='4555' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4555/4555 07:54]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Perplexity: 8.34\n","output_type":"stream"}]},{"cell_type":"code","source":"eval_results","metadata":{"execution":{"iopub.status.busy":"2022-11-08T21:59:52.289392Z","iopub.execute_input":"2022-11-08T21:59:52.289729Z","iopub.status.idle":"2022-11-08T21:59:52.312529Z","shell.execute_reply.started":"2022-11-08T21:59:52.289692Z","shell.execute_reply":"2022-11-08T21:59:52.310988Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 2.1214816570281982,\n 'eval_runtime': 474.5314,\n 'eval_samples_per_second': 153.564,\n 'eval_steps_per_second': 9.599,\n 'epoch': 10.0}"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"O rapaz olhou para o <mask> \")","metadata":{"id":"RRrtRPA6GRF8","outputId":"a2c6b7bf-a3f6-4f63-a8b2-f80f5e559773","execution":{"iopub.status.busy":"2022-11-08T21:59:52.313533Z","iopub.execute_input":"2022-11-08T21:59:52.313836Z","iopub.status.idle":"2022-11-08T21:59:52.933063Z","shell.execute_reply.started":"2022-11-08T21:59:52.313807Z","shell.execute_reply":"2022-11-08T21:59:52.932129Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.3879077434539795,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'O rapaz olhou para o  '},\n {'score': 0.06767208874225616,\n  'token': 6358,\n  'token_str': ' banheiro',\n  'sequence': 'O rapaz olhou para o banheiro '},\n {'score': 0.03540477156639099,\n  'token': 5,\n  'token_str': '!',\n  'sequence': 'O rapaz olhou para o! '},\n {'score': 0.028271976858377457,\n  'token': 35,\n  'token_str': '?',\n  'sequence': 'O rapaz olhou para o? '},\n {'score': 0.02615528367459774,\n  'token': 3231,\n  'token_str': ' quarto',\n  'sequence': 'O rapaz olhou para o quarto '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"A moÃ§a olhou para o <mask> \")","metadata":{"execution":{"iopub.status.busy":"2022-11-08T21:59:52.93443Z","iopub.execute_input":"2022-11-08T21:59:52.935429Z","iopub.status.idle":"2022-11-08T21:59:53.178863Z","shell.execute_reply.started":"2022-11-08T21:59:52.935372Z","shell.execute_reply":"2022-11-08T21:59:53.17751Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.377534419298172,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'A moÃ§a olhou para o  '},\n {'score': 0.06184181571006775,\n  'token': 6358,\n  'token_str': ' banheiro',\n  'sequence': 'A moÃ§a olhou para o banheiro '},\n {'score': 0.03320068493485451,\n  'token': 35,\n  'token_str': '?',\n  'sequence': 'A moÃ§a olhou para o? '},\n {'score': 0.02839978225529194,\n  'token': 5,\n  'token_str': '!',\n  'sequence': 'A moÃ§a olhou para o! '},\n {'score': 0.02712242864072323,\n  'token': 30,\n  'token_str': ':',\n  'sequence': 'A moÃ§a olhou para o: '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Comprou uma <mask> na loja. \")","metadata":{"execution":{"iopub.status.busy":"2022-11-08T21:59:53.181392Z","iopub.execute_input":"2022-11-08T21:59:53.182156Z","iopub.status.idle":"2022-11-08T21:59:53.508345Z","shell.execute_reply.started":"2022-11-08T21:59:53.182092Z","shell.execute_reply":"2022-11-08T21:59:53.507377Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.023507224395871162,\n  'token': 5305,\n  'token_str': ' pedra',\n  'sequence': 'Comprou uma pedra na loja. '},\n {'score': 0.0184037946164608,\n  'token': 7401,\n  'token_str': ' Ã¡rvore',\n  'sequence': 'Comprou uma Ã¡rvore na loja. '},\n {'score': 0.017729027196764946,\n  'token': 3363,\n  'token_str': ' nota',\n  'sequence': 'Comprou uma nota na loja. '},\n {'score': 0.016659963876008987,\n  'token': 3404,\n  'token_str': ' loja',\n  'sequence': 'Comprou uma loja na loja. '},\n {'score': 0.01600511558353901,\n  'token': 2620,\n  'token_str': ' mÃ£o',\n  'sequence': 'Comprou uma mÃ£o na loja. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"A mulher nÃ£o Ã© <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-11-08T21:59:53.509885Z","iopub.execute_input":"2022-11-08T21:59:53.510281Z","iopub.status.idle":"2022-11-08T21:59:53.738065Z","shell.execute_reply.started":"2022-11-08T21:59:53.510243Z","shell.execute_reply":"2022-11-08T21:59:53.737113Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.9998087286949158,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'A mulher nÃ£o Ã©. '},\n {'score': 3.2044121326180175e-05,\n  'token': 18,\n  'token_str': '.',\n  'sequence': 'A mulher nÃ£o Ã©.. '},\n {'score': 9.194252015731763e-06,\n  'token': 3639,\n  'token_str': ' Â«',\n  'sequence': 'A mulher nÃ£o Ã© Â«. '},\n {'score': 5.893655270483578e-06,\n  'token': 3817,\n  'token_str': ' tel',\n  'sequence': 'A mulher nÃ£o Ã© tel. '},\n {'score': 5.698397671949351e-06,\n  'token': 5,\n  'token_str': '!',\n  'sequence': 'A mulher nÃ£o Ã©!. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"O homem nÃ£o Ã© <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-11-08T21:59:53.740219Z","iopub.execute_input":"2022-11-08T21:59:53.740818Z","iopub.status.idle":"2022-11-08T21:59:53.985037Z","shell.execute_reply.started":"2022-11-08T21:59:53.740778Z","shell.execute_reply":"2022-11-08T21:59:53.98408Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.9995953440666199,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'O homem nÃ£o Ã©. '},\n {'score': 8.137679833453149e-05,\n  'token': 18,\n  'token_str': '.',\n  'sequence': 'O homem nÃ£o Ã©.. '},\n {'score': 1.6248592146439478e-05,\n  'token': 3639,\n  'token_str': ' Â«',\n  'sequence': 'O homem nÃ£o Ã© Â«. '},\n {'score': 1.2915032129967585e-05,\n  'token': 5,\n  'token_str': '!',\n  'sequence': 'O homem nÃ£o Ã©!. '},\n {'score': 1.2408900147420354e-05,\n  'token': 261,\n  'token_str': ' d',\n  'sequence': 'O homem nÃ£o Ã© d. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Ele Ã© um bom <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-11-08T21:59:53.991404Z","iopub.execute_input":"2022-11-08T21:59:53.991686Z","iopub.status.idle":"2022-11-08T21:59:54.329161Z","shell.execute_reply.started":"2022-11-08T21:59:53.991659Z","shell.execute_reply":"2022-11-08T21:59:54.328086Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.9997895359992981,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'Ele Ã© um bom. '},\n {'score': 0.00014541717246174812,\n  'token': 18,\n  'token_str': '.',\n  'sequence': 'Ele Ã© um bom.. '},\n {'score': 6.266754553507781e-06,\n  'token': 3639,\n  'token_str': ' Â«',\n  'sequence': 'Ele Ã© um bom Â«. '},\n {'score': 2.9389618703135056e-06,\n  'token': 272,\n  'token_str': ' m',\n  'sequence': 'Ele Ã© um bom m. '},\n {'score': 2.72923330157937e-06,\n  'token': 586,\n  'token_str': ' dia',\n  'sequence': 'Ele Ã© um bom dia. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Ela Ã© uma boa <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-11-08T21:59:54.33344Z","iopub.execute_input":"2022-11-08T21:59:54.334387Z","iopub.status.idle":"2022-11-08T21:59:54.766466Z","shell.execute_reply.started":"2022-11-08T21:59:54.334344Z","shell.execute_reply":"2022-11-08T21:59:54.765378Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.9998600482940674,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'Ela Ã© uma boa. '},\n {'score': 6.6301719925832e-05,\n  'token': 18,\n  'token_str': '.',\n  'sequence': 'Ela Ã© uma boa.. '},\n {'score': 7.274513791344361e-06,\n  'token': 3639,\n  'token_str': ' Â«',\n  'sequence': 'Ela Ã© uma boa Â«. '},\n {'score': 2.6879301913140807e-06,\n  'token': 5,\n  'token_str': '!',\n  'sequence': 'Ela Ã© uma boa!. '},\n {'score': 2.2841427380626556e-06,\n  'token': 2654,\n  'token_str': ' Â»',\n  'sequence': 'Ela Ã© uma boa Â». '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Faz de conta que ainda Ã© <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-11-08T21:59:54.768198Z","iopub.execute_input":"2022-11-08T21:59:54.76858Z","iopub.status.idle":"2022-11-08T21:59:55.103361Z","shell.execute_reply.started":"2022-11-08T21:59:54.76854Z","shell.execute_reply":"2022-11-08T21:59:55.102448Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.9996553659439087,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'Faz de conta que ainda Ã©. '},\n {'score': 0.00011703727795975283,\n  'token': 18,\n  'token_str': '.',\n  'sequence': 'Faz de conta que ainda Ã©.. '},\n {'score': 2.3654527467442676e-05,\n  'token': 3639,\n  'token_str': ' Â«',\n  'sequence': 'Faz de conta que ainda Ã© Â«. '},\n {'score': 1.17270055852714e-05,\n  'token': 1208,\n  'token_str': ' bom',\n  'sequence': 'Faz de conta que ainda Ã© bom. '},\n {'score': 5.484273060574196e-06,\n  'token': 5,\n  'token_str': '!',\n  'sequence': 'Faz de conta que ainda Ã©!. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Depois da tempestade vem a <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-11-08T21:59:55.104745Z","iopub.execute_input":"2022-11-08T21:59:55.105451Z","iopub.status.idle":"2022-11-08T21:59:55.415561Z","shell.execute_reply.started":"2022-11-08T21:59:55.105407Z","shell.execute_reply":"2022-11-08T21:59:55.414407Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.930250883102417,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'Depois da tempestade vem a. '},\n {'score': 0.003178785787895322,\n  'token': 3257,\n  'token_str': ' pÃ©',\n  'sequence': 'Depois da tempestade vem a pÃ©. '},\n {'score': 0.0022572630550712347,\n  'token': 18,\n  'token_str': '.',\n  'sequence': 'Depois da tempestade vem a.. '},\n {'score': 0.0016144736437126994,\n  'token': 752,\n  'token_str': ' todos',\n  'sequence': 'Depois da tempestade vem a todos. '},\n {'score': 0.0014756583841517568,\n  'token': 1489,\n  'token_str': ' fim',\n  'sequence': 'Depois da tempestade vem a fim. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Mais vale um pÃ¡ssaro na mÃ£o do que <mask> voando. \")","metadata":{"execution":{"iopub.status.busy":"2022-11-08T21:59:55.41749Z","iopub.execute_input":"2022-11-08T21:59:55.417869Z","iopub.status.idle":"2022-11-08T21:59:55.777799Z","shell.execute_reply.started":"2022-11-08T21:59:55.417833Z","shell.execute_reply":"2022-11-08T21:59:55.776804Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.047030456364154816,\n  'token': 575,\n  'token_str': ' eu',\n  'sequence': 'Mais vale um pÃ¡ssaro na mÃ£o do que eu voando. '},\n {'score': 0.04598027095198631,\n  'token': 506,\n  'token_str': ' ele',\n  'sequence': 'Mais vale um pÃ¡ssaro na mÃ£o do que ele voando. '},\n {'score': 0.027364060282707214,\n  'token': 769,\n  'token_str': ' ela',\n  'sequence': 'Mais vale um pÃ¡ssaro na mÃ£o do que ela voando. '},\n {'score': 0.011642674915492535,\n  'token': 1139,\n  'token_str': ' outro',\n  'sequence': 'Mais vale um pÃ¡ssaro na mÃ£o do que outro voando. '},\n {'score': 0.010727044194936752,\n  'token': 582,\n  'token_str': ' vocÃª',\n  'sequence': 'Mais vale um pÃ¡ssaro na mÃ£o do que vocÃª voando. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"NÃ£o tinha <mask>, mas almoÃ§ou mesmo assim. \")","metadata":{"execution":{"iopub.status.busy":"2022-11-08T21:59:55.77964Z","iopub.execute_input":"2022-11-08T21:59:55.779998Z","iopub.status.idle":"2022-11-08T21:59:56.133811Z","shell.execute_reply.started":"2022-11-08T21:59:55.779957Z","shell.execute_reply":"2022-11-08T21:59:56.132846Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.04077940806746483,\n  'token': 1976,\n  'token_str': ' dinheiro',\n  'sequence': 'NÃ£o tinha dinheiro, mas almoÃ§ou mesmo assim. '},\n {'score': 0.034136999398469925,\n  'token': 734,\n  'token_str': ' tempo',\n  'sequence': 'NÃ£o tinha tempo, mas almoÃ§ou mesmo assim. '},\n {'score': 0.017651768401265144,\n  'token': 2541,\n  'token_str': ' filhos',\n  'sequence': 'NÃ£o tinha filhos, mas almoÃ§ou mesmo assim. '},\n {'score': 0.012891470454633236,\n  'token': 1428,\n  'token_str': ' nada',\n  'sequence': 'NÃ£o tinha nada, mas almoÃ§ou mesmo assim. '},\n {'score': 0.012331949546933174,\n  'token': 4374,\n  'token_str': ' jeito',\n  'sequence': 'NÃ£o tinha jeito, mas almoÃ§ou mesmo assim. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Bebeu um copo d'Ã¡gua, pois tinha <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-11-08T21:59:56.135539Z","iopub.execute_input":"2022-11-08T21:59:56.135906Z","iopub.status.idle":"2022-11-08T21:59:56.318108Z","shell.execute_reply.started":"2022-11-08T21:59:56.135868Z","shell.execute_reply":"2022-11-08T21:59:56.317121Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.9996600151062012,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': \"Bebeu um copo d'Ã¡gua, pois tinha. \"},\n {'score': 0.00018398030078969896,\n  'token': 18,\n  'token_str': '.',\n  'sequence': \"Bebeu um copo d'Ã¡gua, pois tinha.. \"},\n {'score': 5.394807885750197e-05,\n  'token': 735,\n  'token_str': ' min',\n  'sequence': \"Bebeu um copo d'Ã¡gua, pois tinha min. \"},\n {'score': 5.774219062004704e-06,\n  'token': 3817,\n  'token_str': ' tel',\n  'sequence': \"Bebeu um copo d'Ã¡gua, pois tinha tel. \"},\n {'score': 4.859412911173422e-06,\n  'token': 261,\n  'token_str': ' d',\n  'sequence': \"Bebeu um copo d'Ã¡gua, pois tinha d. \"}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Sem saber, ele descobriu um <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-11-08T21:59:56.319571Z","iopub.execute_input":"2022-11-08T21:59:56.320175Z","iopub.status.idle":"2022-11-08T21:59:56.636467Z","shell.execute_reply.started":"2022-11-08T21:59:56.320117Z","shell.execute_reply":"2022-11-08T21:59:56.635399Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.9903740882873535,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'Sem saber, ele descobriu um. '},\n {'score': 0.0003562170313671231,\n  'token': 18,\n  'token_str': '.',\n  'sequence': 'Sem saber, ele descobriu um.. '},\n {'score': 0.00024357213987968862,\n  'token': 586,\n  'token_str': ' dia',\n  'sequence': 'Sem saber, ele descobriu um dia. '},\n {'score': 0.00016274995869025588,\n  'token': 4310,\n  'token_str': ' telefone',\n  'sequence': 'Sem saber, ele descobriu um telefone. '},\n {'score': 0.00016093242447823286,\n  'token': 3639,\n  'token_str': ' Â«',\n  'sequence': 'Sem saber, ele descobriu um Â«. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Pedro fez fortuna vendendo <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-11-08T21:59:56.637817Z","iopub.execute_input":"2022-11-08T21:59:56.63828Z","iopub.status.idle":"2022-11-08T21:59:56.927181Z","shell.execute_reply.started":"2022-11-08T21:59:56.63824Z","shell.execute_reply":"2022-11-08T21:59:56.92611Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.9995922446250916,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'Pedro fez fortuna vendendo. '},\n {'score': 0.00011580066347960383,\n  'token': 18,\n  'token_str': '.',\n  'sequence': 'Pedro fez fortuna vendendo.. '},\n {'score': 5.87530157645233e-05,\n  'token': 3639,\n  'token_str': ' Â«',\n  'sequence': 'Pedro fez fortuna vendendo Â«. '},\n {'score': 1.9351051378180273e-05,\n  'token': 2654,\n  'token_str': ' Â»',\n  'sequence': 'Pedro fez fortuna vendendo Â». '},\n {'score': 1.542612153571099e-05,\n  'token': 735,\n  'token_str': ' min',\n  'sequence': 'Pedro fez fortuna vendendo min. '}]"},"metadata":{}}]},{"cell_type":"code","source":"fill_mask(\"Sem medo de ser <mask>. \")","metadata":{"execution":{"iopub.status.busy":"2022-11-08T21:59:56.928677Z","iopub.execute_input":"2022-11-08T21:59:56.929016Z","iopub.status.idle":"2022-11-08T21:59:57.216922Z","shell.execute_reply.started":"2022-11-08T21:59:56.92898Z","shell.execute_reply":"2022-11-08T21:59:57.215979Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.9991890788078308,\n  'token': 225,\n  'token_str': ' ',\n  'sequence': 'Sem medo de ser. '},\n {'score': 8.056305523496121e-05,\n  'token': 18,\n  'token_str': '.',\n  'sequence': 'Sem medo de ser.. '},\n {'score': 5.334976958693005e-05,\n  'token': 3639,\n  'token_str': ' Â«',\n  'sequence': 'Sem medo de ser Â«. '},\n {'score': 1.8366428776062094e-05,\n  'token': 2837,\n  'token_str': ' etc',\n  'sequence': 'Sem medo de ser etc. '},\n {'score': 1.6314515960402787e-05,\n  'token': 5,\n  'token_str': '!',\n  'sequence': 'Sem medo de ser!. '}]"},"metadata":{}}]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2022-11-08T21:59:57.21821Z","iopub.execute_input":"2022-11-08T21:59:57.218567Z","iopub.status.idle":"2022-11-08T22:00:00.979999Z","shell.execute_reply.started":"2022-11-08T21:59:57.218528Z","shell.execute_reply":"2022-11-08T22:00:00.979083Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/learning_rate</td><td>â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–</td></tr><tr><td>train/loss</td><td>â–ˆâ–‡â–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.12148</td></tr><tr><td>eval/runtime</td><td>474.5314</td></tr><tr><td>eval/samples_per_second</td><td>153.564</td></tr><tr><td>eval/steps_per_second</td><td>9.599</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>68640</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.1043</td></tr><tr><td>train/total_flos</td><td>2.42237682625536e+16</td></tr><tr><td>train/train_loss</td><td>2.42074</td></tr><tr><td>train/train_runtime</td><td>25420.9365</td></tr><tr><td>train/train_samples_per_second</td><td>86.394</td></tr><tr><td>train/train_steps_per_second</td><td>2.7</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Synced <strong style=\"color:#cdcd00\">./BR_BERTo-CENTENFolha-8_parts</strong>: <a href=\"https://wandb.ai/tccii/huggingface/runs/1d5ymncq\" target=\"_blank\">https://wandb.ai/tccii/huggingface/runs/1d5ymncq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20221108_144820-1d5ymncq/logs</code>"},"metadata":{}}]}]}